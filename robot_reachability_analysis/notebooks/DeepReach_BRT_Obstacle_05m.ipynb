{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Install Dependencies"
      ],
      "metadata": {
        "id": "-dJSa8SGA3qE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO7q9J3U__wn",
        "outputId": "52482a94-4e03-4289-f5ef-43dd8c32f5e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting configargparse\n",
            "  Downloading ConfigArgParse-1.7-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: configargparse\n",
            "Successfully installed configargparse-1.7\n"
          ]
        }
      ],
      "source": [
        "! pip install configargparse"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch torchvision torchaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR_iiXcpA836",
        "outputId": "40d3e8af-f245-4134-cb4b-e7e6e3672ffb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Imports"
      ],
      "metadata": {
        "id": "87VPetxvCQlj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import time\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "from collections import OrderedDict\n",
        "\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.autograd import grad\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch import nn\n",
        "\n",
        "import wandb\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import scipy.io as spio\n",
        "\n",
        "from tqdm.autonotebook import tqdm\n",
        "from sklearn import svm\n",
        "\n",
        "import configargparse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmFWEDFvCUU5",
        "outputId": "b03ce0db-821c-4543-acd0-78191b5b1de0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-7866da687f05>:29: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vS_tv_hGREd",
        "outputId": "08d9d5f6-e9c4-4fa6-8941-20a1d17771da"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Connect to Google Drive"
      ],
      "metadata": {
        "id": "pviCCyEBCXEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\",force_remount=True)\n",
        "os.chdir(\"/content/drive/My Drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4rMTeMoDBUE",
        "outputId": "44bb37c0-c268-44c9-91b8-d4bb4d65ec99"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Utils Code"
      ],
      "metadata": {
        "id": "0Qvuw3VGCaVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# uses model input and real boundary fn\n",
        "class ReachabilityDataset(Dataset):\n",
        "    def __init__(self, dynamics, numpoints, pretrain, pretrain_iters, tMin, tMax, counter_start, counter_end, num_src_samples, num_target_samples):\n",
        "        self.dynamics = dynamics\n",
        "        self.numpoints = numpoints\n",
        "        self.pretrain = pretrain\n",
        "        self.pretrain_counter = 0\n",
        "        self.pretrain_iters = pretrain_iters\n",
        "        self.tMin = tMin\n",
        "        self.tMax = tMax\n",
        "        self.counter = counter_start\n",
        "        self.counter_end = counter_end\n",
        "        self.num_src_samples = num_src_samples\n",
        "        self.num_target_samples = num_target_samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return 1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # uniformly sample domain and include coordinates where source is non-zero\n",
        "        model_states = torch.zeros(self.numpoints, self.dynamics.state_dim).uniform_(-1, 1)\n",
        "        if self.num_target_samples > 0:\n",
        "            target_state_samples = self.dynamics.sample_target_state(self.num_target_samples)\n",
        "            model_states[-self.num_target_samples:] = self.dynamics.coord_to_input(torch.cat((torch.zeros(self.num_target_samples, 1), target_state_samples), dim=-1))[:, 1:self.dynamics.state_dim+1]\n",
        "\n",
        "        if self.pretrain:\n",
        "            # only sample in time around the initial condition\n",
        "            times = torch.full((self.numpoints, 1), self.tMin)\n",
        "        else:\n",
        "            # slowly grow time values from start time\n",
        "            times = self.tMin + torch.zeros(self.numpoints, 1).uniform_(0, (self.tMax-self.tMin) * (self.counter / self.counter_end))\n",
        "            # make sure we always have training samples at the initial time\n",
        "            times[-self.num_src_samples:, 0] = self.tMin\n",
        "        model_coords = torch.cat((times, model_states), dim=1)\n",
        "        if self.dynamics.input_dim > self.dynamics.state_dim + 1: # temporary workaround for having to deal with dynamics classes for parametrized models with extra inputs\n",
        "            model_coords = torch.cat((model_coords, torch.zeros(self.numpoints, self.dynamics.input_dim - self.dynamics.state_dim - 1)), dim=1)\n",
        "\n",
        "        boundary_values = self.dynamics.boundary_fn(self.dynamics.input_to_coord(model_coords)[..., 1:])\n",
        "        if self.dynamics.loss_type == 'brat_hjivi':\n",
        "            reach_values = self.dynamics.reach_fn(self.dynamics.input_to_coord(model_coords)[..., 1:])\n",
        "            avoid_values = self.dynamics.avoid_fn(self.dynamics.input_to_coord(model_coords)[..., 1:])\n",
        "\n",
        "        if self.pretrain:\n",
        "            dirichlet_masks = torch.ones(model_coords.shape[0]) > 0\n",
        "        else:\n",
        "            # only enforce initial conditions around self.tMin\n",
        "            dirichlet_masks = (model_coords[:, 0] == self.tMin)\n",
        "\n",
        "        if self.pretrain:\n",
        "            self.pretrain_counter += 1\n",
        "        elif self.counter < self.counter_end:\n",
        "            self.counter += 1\n",
        "\n",
        "        if self.pretrain and self.pretrain_counter == self.pretrain_iters:\n",
        "            self.pretrain = False\n",
        "\n",
        "        if self.dynamics.loss_type == 'brt_hjivi':\n",
        "            return {'model_coords': model_coords}, {'boundary_values': boundary_values, 'dirichlet_masks': dirichlet_masks}\n",
        "        elif self.dynamics.loss_type == 'brat_hjivi':\n",
        "            return {'model_coords': model_coords}, {'boundary_values': boundary_values, 'reach_values': reach_values, 'avoid_values': avoid_values, 'dirichlet_masks': dirichlet_masks}\n",
        "        else:\n",
        "            raise NotImplementedError"
      ],
      "metadata": {
        "id": "9hX0elicCcHU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: I don't think jacobian is needed here; torch.autograd.grad should be enough, to compute gradients of a scalar value function w.r.t. inputs\n",
        "\n",
        "# batched jacobian\n",
        "# y: [..., N], x: [..., M] -> [..., N, M]\n",
        "def jacobian(y, x):\n",
        "    ''' jacobian of y wrt x '''\n",
        "    jac = torch.zeros(*y.shape, x.shape[-1]).to(y.device)\n",
        "    for i in range(y.shape[-1]):\n",
        "        # calculate dydx over batches for each feature value of y\n",
        "        y_flat = y[...,i].view(-1, 1)\n",
        "        jac[..., i, :] = grad(y_flat, x, torch.ones_like(y_flat), create_graph=True)[0]\n",
        "\n",
        "    status = 0\n",
        "    if torch.any(torch.isnan(jac)):\n",
        "        status = -1\n",
        "\n",
        "    return jac, status"
      ],
      "metadata": {
        "id": "TnNOsIvlClMZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Validator(ABC):\n",
        "    @abstractmethod\n",
        "    def validate(self, coords, values):\n",
        "        raise NotImplementedError\n",
        "\n",
        "class ValueThresholdValidator(Validator):\n",
        "    def __init__(self, v_min, v_max):\n",
        "        self.v_min = v_min\n",
        "        self.v_max = v_max\n",
        "\n",
        "    def validate(self, coords, values):\n",
        "        return (values >= self.v_min)*(values <= self.v_max)\n",
        "\n",
        "class MLPValidator(Validator):\n",
        "    def __init__(self, device, mlp, o_min, o_max, model, dynamics):\n",
        "        self.device = device\n",
        "        self.mlp = mlp\n",
        "        self.o_min = o_min\n",
        "        self.o_max = o_max\n",
        "        self.model = model\n",
        "        self.dynamics = dynamics\n",
        "\n",
        "    def validate(self, coords, values):\n",
        "        model_results = self.model({'coords': self.dynamics.coord_to_input(coords.to(self.device))})\n",
        "        inputs = torch.cat((coords[..., 1:].to(self.device), values[:, None].to(self.device)), dim=-1)\n",
        "        outputs = torch.sigmoid(self.mlp(inputs).squeeze())\n",
        "        return ((outputs >= self.o_min)*(outputs <=self.o_max)).to(device=values.device)\n",
        "\n",
        "class MLPConditionedValidator(Validator):\n",
        "    def __init__(self, device, mlp, o_levels, v_levels, model, dynamics):\n",
        "        self.device = device\n",
        "        self.mlp = mlp\n",
        "        self.o_levels = o_levels\n",
        "        self.v_levels = v_levels\n",
        "        self.model = model\n",
        "        self.dynamics = dynamics\n",
        "        assert len(self.o_levels) == len(self.v_levels) + 1\n",
        "\n",
        "    def validate(self, coords, values):\n",
        "        model_results = self.model({'coords': self.dynamics.coord_to_input(coords.to(self.device))})\n",
        "        inputs = torch.cat((coords[..., 1:].to(self.device), values[:, None].to(self.device)), dim=-1)\n",
        "        outputs = torch.sigmoid(self.mlp(inputs).squeeze(dim=-1)).to(device=values.device)\n",
        "        valids = torch.zeros_like(outputs)\n",
        "        for i in range(len(self.o_levels) - 1):\n",
        "            valids = torch.logical_or(\n",
        "                valids,\n",
        "                (outputs > self.o_levels[i])*(outputs <= self.o_levels[i+1])*(values >= self.v_levels[i][0])*(values <= self.v_levels[i][1])\n",
        "            )\n",
        "        return valids\n",
        "\n",
        "class MultiValidator(Validator):\n",
        "    def __init__(self, validators):\n",
        "        self.validators = validators\n",
        "\n",
        "    def validate(self, coords, values):\n",
        "        result = self.validators[0].validate(coords, values)\n",
        "        for i in range(len(self.validators)-1):\n",
        "            result = result * self.validators[i+1].validate(coords, values)\n",
        "        return result\n",
        "\n",
        "class SampleGenerator(ABC):\n",
        "    @abstractmethod\n",
        "    def sample(self, num_samples):\n",
        "        raise NotImplementedError\n",
        "\n",
        "class SliceSampleGenerator(SampleGenerator):\n",
        "    def __init__(self, dynamics, slices):\n",
        "        self.dynamics = dynamics\n",
        "        self.slices = slices\n",
        "        assert self.dynamics.state_dim == len(slices)\n",
        "\n",
        "    def sample(self, num_samples):\n",
        "        samples = torch.zeros(num_samples, self.dynamics.state_dim)\n",
        "        for dim in range(self.dynamics.state_dim):\n",
        "            if self.slices[dim] is None:\n",
        "                samples[:, dim].uniform_(*self.dynamics.state_test_range()[dim])\n",
        "            else:\n",
        "                samples[:, dim] = self.slices[dim]\n",
        "        return samples\n",
        "\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "# # get the tEarliest in [tMin:tMax:dt] at which the state is still valid\n",
        "# def get_tEarliest(device, model, dynamics, state, tMin, tMax, dt, validator):\n",
        "#     with torch.no_grad():\n",
        "#         tEarliest = torch.full(state.shape[:-1], tMin - 1)\n",
        "#         model_state = dynamics.normalize_state(state)\n",
        "\n",
        "#         times_to_try = torch.arange(tMin, tMax + dt, dt)\n",
        "#         for time_to_try in times_to_try:\n",
        "#             blank_idx = (tEarliest < tMin)\n",
        "#             time = torch.full((*state.shape[:-1], 1), time_to_try)\n",
        "#             model_time = dynamics.normalize_time(time)\n",
        "#             model_coord = torch.cat((model_time, model_state), dim=-1)[blank_idx]\n",
        "#             model_result = model({'coords': model_coord.to(device)})\n",
        "#             value = dynamics.output_to_value(output=model_result['model_out'][..., 0], state=state.to(device)).cpu()\n",
        "#             valid_idx = validator.validate(torch.cat((time, state), dim=-1), value)\n",
        "#             tMasked = tEarliest[blank_idx]\n",
        "#             tMasked[valid_idx] = time_to_try\n",
        "#             tEarliest[blank_idx] = tMasked\n",
        "#             if torch.all(tEarliest >= tMin):\n",
        "#                 break\n",
        "#         blank_idx = (tEarliest < tMin)\n",
        "#         if torch.any(blank_idx):\n",
        "#             print(str(torch.sum(blank_idx)), 'invalid states')\n",
        "#             tEarliest[blank_idx] = tMax\n",
        "#         return tEarliest\n",
        "\n",
        "def scenario_optimization(device, model, policy, dynamics, tMin, tMax, dt, set_type, control_type, scenario_batch_size, sample_batch_size, sample_generator, sample_validator, violation_validator, max_scenarios=None, max_samples=None, max_violations=None, tStart_generator=None):\n",
        "    rem = ((tMax-tMin) / dt)%1\n",
        "    e_tol = 1e-12\n",
        "    assert rem < e_tol or 1 - rem < e_tol, f'{tMax-tMin} is not divisible by {dt}'\n",
        "    assert tMax > tMin\n",
        "    assert set_type in ['BRS', 'BRT']\n",
        "    if set_type == 'BRS':\n",
        "        print('confirm correct calculation of true values of trajectories (batch_scenario_costs)')\n",
        "        raise NotImplementedError\n",
        "    assert control_type in ['value', 'ttr', 'init_ttr']\n",
        "    assert max_scenarios or max_samples or max_violations, 'one of the termination conditions must be used'\n",
        "    if max_scenarios:\n",
        "        assert (max_scenarios / scenario_batch_size)%1 == 0, 'max_scenarios is not divisible by scenario_batch_size'\n",
        "    if max_samples:\n",
        "        assert (max_samples / sample_batch_size)%1 == 0, 'max_samples is not divisible by sample_batch_size'\n",
        "\n",
        "    # accumulate scenarios\n",
        "    times = torch.zeros(0, )\n",
        "    states = torch.zeros(0, dynamics.state_dim)\n",
        "    values = torch.zeros(0, )\n",
        "    costs = torch.zeros(0, )\n",
        "    init_hams = torch.zeros(0, )\n",
        "    mean_hams = torch.zeros(0, )\n",
        "    mean_abs_hams = torch.zeros(0, )\n",
        "    max_abs_hams = torch.zeros(0, )\n",
        "    min_abs_hams = torch.zeros(0, )\n",
        "\n",
        "    num_scenarios = 0\n",
        "    num_samples = 0\n",
        "    num_violations = 0\n",
        "\n",
        "    pbar_pos = 0\n",
        "    if max_scenarios:\n",
        "        scenarios_pbar = tqdm(total=max_scenarios, desc='Scenarios', position=pbar_pos)\n",
        "        pbar_pos += 1\n",
        "    if max_samples:\n",
        "        samples_pbar = tqdm(total=max_samples, desc='Samples', position=pbar_pos)\n",
        "        pbar_pos += 1\n",
        "    if max_violations:\n",
        "        violations_pbar = tqdm(total=max_violations, desc='Violations', position=pbar_pos)\n",
        "        pbar_pos += 1\n",
        "\n",
        "    nums_valid_samples = []\n",
        "    while True:\n",
        "        if (max_scenarios and (num_scenarios >= max_scenarios)) or (max_violations and (num_violations >= max_violations)):\n",
        "            break\n",
        "\n",
        "        batch_scenario_times = torch.zeros(scenario_batch_size, )\n",
        "        batch_scenario_states = torch.zeros(scenario_batch_size, dynamics.state_dim)\n",
        "        batch_scenario_values = torch.zeros(scenario_batch_size, )\n",
        "\n",
        "        num_collected_scenarios = 0\n",
        "        while num_collected_scenarios < scenario_batch_size:\n",
        "            if max_samples and (num_samples >= max_samples):\n",
        "                break\n",
        "            # sample batch\n",
        "            if tStart_generator is not None:\n",
        "                batch_sample_times = tStart_generator(sample_batch_size)\n",
        "                # need to round to nearest dt\n",
        "                batch_sample_times = torch.round(batch_sample_times/dt)*dt\n",
        "            else:\n",
        "                batch_sample_times = torch.full((sample_batch_size, ), tMax)\n",
        "            batch_sample_states = dynamics.equivalent_wrapped_state(sample_generator.sample(sample_batch_size))\n",
        "            batch_sample_coords = torch.cat((batch_sample_times.unsqueeze(-1), batch_sample_states), dim=-1)\n",
        "\n",
        "            # validate batch\n",
        "            with torch.no_grad():\n",
        "                batch_sample_model_results = model({'coords': dynamics.coord_to_input(batch_sample_coords.to(device))})\n",
        "                batch_sample_values = dynamics.io_to_value(batch_sample_model_results['model_in'].detach(), batch_sample_model_results['model_out'].squeeze(dim=-1).detach())\n",
        "            batch_valid_sample_idxs = torch.where(sample_validator.validate(batch_sample_coords, batch_sample_values))[0].detach().cpu()\n",
        "\n",
        "            # store valid samples\n",
        "            num_valid_samples = len(batch_valid_sample_idxs)\n",
        "            start_idx = num_collected_scenarios\n",
        "            end_idx = min(start_idx + num_valid_samples, scenario_batch_size)\n",
        "            batch_scenario_times[start_idx:end_idx] = batch_sample_times[batch_valid_sample_idxs][:end_idx-start_idx]\n",
        "            batch_scenario_states[start_idx:end_idx] = batch_sample_states[batch_valid_sample_idxs][:end_idx-start_idx]\n",
        "            batch_scenario_values[start_idx:end_idx] = batch_sample_values[batch_valid_sample_idxs][:end_idx-start_idx]\n",
        "\n",
        "            # update counters\n",
        "            num_samples += sample_batch_size\n",
        "            if max_samples:\n",
        "                samples_pbar.update(sample_batch_size)\n",
        "            num_collected_scenarios += end_idx - start_idx\n",
        "            nums_valid_samples.append(num_valid_samples)\n",
        "        if max_samples and (num_samples >= max_samples):\n",
        "            break\n",
        "\n",
        "        # propagate scenarios\n",
        "        state_trajs = torch.zeros(scenario_batch_size, int((tMax-tMin)/dt + 1), dynamics.state_dim)\n",
        "        ctrl_trajs = torch.zeros(scenario_batch_size, int((tMax-tMin)/dt), dynamics.control_dim)\n",
        "        dstb_trajs = torch.zeros(scenario_batch_size, int((tMax-tMin)/dt), dynamics.disturbance_dim)\n",
        "        ham_trajs = torch.zeros(scenario_batch_size, int((tMax-tMin)/dt))\n",
        "\n",
        "        state_trajs[:, 0, :] = batch_scenario_states\n",
        "        for k in tqdm(range(int((tMax-tMin)/dt)), desc='Trajectory Propagation', position=pbar_pos, leave=False):\n",
        "            if control_type == 'value':\n",
        "                traj_time = tMax - k*dt\n",
        "                traj_times = torch.full((scenario_batch_size, ), traj_time)\n",
        "            # elif control_type == 'ttr':\n",
        "            #     traj_times = get_tEarliest(model=model, dynamics=dynamics, state=state_trajs[:, k], tMin=tMin, tMax=traj_time, dt=dt, validator=sample_validator)\n",
        "            # elif control_type == 'init_ttr':\n",
        "            #     if k == 0:\n",
        "            #         init_traj_times = get_tEarliest(model=model, dynamics=dynamics, state=state_trajs[:, k], tMin=tMin, tMax=traj_time, dt=dt, validator=sample_validator)\n",
        "            #     traj_times = torch.maximum(init_traj_times - k*dt, torch.tensor(tMin)) # check whether this is the best thing to do for init_ttr\n",
        "            traj_coords = torch.cat((traj_times.unsqueeze(-1), state_trajs[:, k]), dim=-1)\n",
        "            traj_policy_results = policy({'coords': dynamics.coord_to_input(traj_coords.to(device))})\n",
        "            traj_dvs = dynamics.io_to_dv(traj_policy_results['model_in'], traj_policy_results['model_out'].squeeze(dim=-1)).detach()\n",
        "\n",
        "            # TODO: I do not think there is actually any reason to store these trajs? Could save space by removing these.\n",
        "            ctrl_trajs[:, k] = dynamics.optimal_control(traj_coords[:, 1:].to(device), traj_dvs[..., 1:].to(device))\n",
        "            dstb_trajs[:, k] = dynamics.optimal_disturbance(traj_coords[:, 1:].to(device), traj_dvs[..., 1:].to(device))\n",
        "            ham_trajs[:, k] = dynamics.hamiltonian(traj_coords[:, 1:].to(device), traj_dvs[..., 1:].to(device))\n",
        "\n",
        "            if tStart_generator is not None: # freeze states whose start time has not been reached yet\n",
        "                is_frozen = batch_scenario_times < traj_times\n",
        "                is_unfrozen = torch.logical_not(is_frozen)\n",
        "                state_trajs[is_frozen, k+1] = state_trajs[is_frozen, k]\n",
        "                state_trajs[is_unfrozen, k+1] = dynamics.equivalent_wrapped_state(state_trajs[is_unfrozen, k].to(device) + dt*dynamics.dsdt(state_trajs[is_unfrozen, k].to(device), ctrl_trajs[is_unfrozen, k].to(device), dstb_trajs[is_unfrozen, k].to(device))).cpu()\n",
        "            else:\n",
        "                state_trajs[:, k+1] = dynamics.equivalent_wrapped_state(state_trajs[:, k].to(device) + dt*dynamics.dsdt(state_trajs[:, k].to(device), ctrl_trajs[:, k].to(device), dstb_trajs[:, k].to(device)))\n",
        "\n",
        "        # compute batch_scenario_costs\n",
        "        # TODO: need to handle the case of using tStart_generator when extending a trajectory by a frozen initial state will inadvertently affect cost computation (the min lx cost formulation is unaffected, but other cost formulations might care)\n",
        "        if set_type == 'BRT':\n",
        "            batch_scenario_costs = dynamics.cost_fn(state_trajs.to(device))\n",
        "        elif set_type == 'BRS':\n",
        "            if control_type == 'init_ttr': # is this correct for init_ttr?\n",
        "                batch_scenario_costs =  dynamics.boundary_fn(state_trajs.to(device))[:, (init_traj_times - tMin) / dt]\n",
        "            elif control_type == 'value':\n",
        "                batch_scenario_costs =  dynamics.boundary_fn(state_trajs.to(device))[:, -1]\n",
        "            else:\n",
        "                raise NotImplementedError # what is the correct thing to do for ttr?\n",
        "\n",
        "        # compute batch_scenario_init_hams, batch_scenario_mean_hams, batch_scenario_mean_abs_hams, batch_scenario_max_abs_hams, batch_scenario_min_abs_hams\n",
        "        batch_scenario_init_hams = ham_trajs[:, 0]\n",
        "        batch_scenario_mean_hams = torch.mean(ham_trajs, dim=-1)\n",
        "        batch_scenario_mean_abs_hams = torch.mean(torch.abs(ham_trajs), dim=-1)\n",
        "        batch_scenario_max_abs_hams = torch.max(torch.abs(ham_trajs), dim=-1).values\n",
        "        batch_scenario_min_abs_hams = torch.min(torch.abs(ham_trajs), dim=-1).values\n",
        "\n",
        "        # store scenarios\n",
        "        times = torch.cat((times, batch_scenario_times.cpu()), dim=0)\n",
        "        states = torch.cat((states, batch_scenario_states.cpu()), dim=0)\n",
        "        values = torch.cat((values, batch_scenario_values.cpu()), dim=0)\n",
        "        costs = torch.cat((costs, batch_scenario_costs.cpu()), dim=0)\n",
        "        init_hams = torch.cat((init_hams, batch_scenario_init_hams.cpu()), dim=0)\n",
        "        mean_hams = torch.cat((mean_hams, batch_scenario_mean_hams.cpu()), dim=0)\n",
        "        mean_abs_hams = torch.cat((mean_abs_hams, batch_scenario_mean_abs_hams.cpu()), dim=0)\n",
        "        max_abs_hams = torch.cat((max_abs_hams, batch_scenario_max_abs_hams.cpu()), dim=0)\n",
        "        min_abs_hams = torch.cat((min_abs_hams, batch_scenario_min_abs_hams.cpu()), dim=0)\n",
        "\n",
        "        # update counters\n",
        "        num_scenarios += scenario_batch_size\n",
        "        if max_scenarios:\n",
        "            scenarios_pbar.update(scenario_batch_size)\n",
        "        num_new_violations = int(torch.sum(violation_validator.validate(batch_scenario_states, batch_scenario_costs)))\n",
        "        num_violations += num_new_violations\n",
        "        if max_violations:\n",
        "            violations_pbar.update(num_new_violations)\n",
        "\n",
        "    if max_scenarios:\n",
        "        scenarios_pbar.close()\n",
        "    if max_samples:\n",
        "        samples_pbar.close()\n",
        "    if max_violations:\n",
        "        violations_pbar.close()\n",
        "\n",
        "    violations = violation_validator.validate(states, costs)\n",
        "\n",
        "    return {\n",
        "        'times': times,\n",
        "        'states': states,\n",
        "        'values': values,\n",
        "        'costs': costs,\n",
        "        'init_hams': init_hams,\n",
        "        'init_abs_hams': torch.abs(init_hams),\n",
        "        'mean_hams': mean_hams,\n",
        "        'mean_abs_hams': mean_abs_hams,\n",
        "        'max_abs_hams': max_abs_hams,\n",
        "        'min_abs_hams': min_abs_hams,\n",
        "        'violations': violations,\n",
        "        'valid_sample_fraction': torch.mean(torch.tensor(nums_valid_samples, dtype=float))/sample_batch_size,\n",
        "        'violation_rate': 0 if not num_scenarios else num_violations / num_scenarios,\n",
        "        'maxed_scenarios': (max_scenarios is not None) and num_scenarios >= max_scenarios,\n",
        "        'maxed_samples': (max_samples is not None) and num_samples >= max_samples,\n",
        "        'maxed_violations': (max_violations is not None) and num_violations >= max_violations,\n",
        "        'batch_state_trajs': None if (max_samples and (num_samples >= max_samples)) else state_trajs,\n",
        "    }\n",
        "\n",
        "def target_fraction(device, model, dynamics, t, sample_validator, target_validator, num_samples, batch_size):\n",
        "    with torch.no_grad():\n",
        "        states = torch.zeros(0, dynamics.state_dim)\n",
        "        values = torch.zeros(0, )\n",
        "\n",
        "        while len(states) < num_samples:\n",
        "            # sample batch\n",
        "            batch_times = torch.full((batch_size, 1), t)\n",
        "            batch_states = torch.zeros(batch_size, dynamics.state_dim)\n",
        "            for dim in range(dynamics.state_dim):\n",
        "                batch_states[:, dim].uniform_(*dynamics.state_test_range()[dim])\n",
        "            batch_states = dynamics.equivalent_wrapped_state(batch_states)\n",
        "            batch_coords = torch.cat((batch_times, batch_states), dim=-1)\n",
        "\n",
        "            # validate batch\n",
        "            batch_model_results = model({'coords': dynamics.coord_to_input(batch_coords.to(device))})\n",
        "            batch_values = dynamics.io_to_value(batch_model_results['model_in'], batch_model_results['model_out'].squeeze(dim=-1)).detach()\n",
        "            batch_valids = sample_validator.validate(batch_coords, batch_values).detach().cpu()\n",
        "\n",
        "            # store valid portion of batch\n",
        "            states = torch.cat((states, batch_states[batch_valids].cpu()), dim=0)\n",
        "            values = torch.cat((values, batch_values[batch_valids].cpu()), dim=0)\n",
        "\n",
        "        states = states[:num_samples]\n",
        "        values = values[:num_samples]\n",
        "        coords = torch.cat((torch.full((num_samples, 1), t), states), dim=-1)\n",
        "        valids = target_validator.validate(coords.to(device), values.to(device))\n",
        "    return torch.sum(valids) / num_samples\n",
        "\n",
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        s1 = int(2*input_size)\n",
        "        s2 = int(input_size)\n",
        "        s3 = int(input_size)\n",
        "        self.l1 = torch.nn.Linear(input_size, s1)\n",
        "        self.a1 = torch.nn.ReLU()\n",
        "        self.l2 = torch.nn.Linear(s1, s2)\n",
        "        self.a2 = torch.nn.ReLU()\n",
        "        self.l3 = torch.nn.Linear(s2, s3)\n",
        "        self.a3 = torch.nn.ReLU()\n",
        "        self.l4 = torch.nn.Linear(s3, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.l1(x)\n",
        "        x = self.a1(x)\n",
        "        x = self.l2(x)\n",
        "        x = self.a2(x)\n",
        "        x = self.l3(x)\n",
        "        x = self.a3(x)\n",
        "        x = self.l4(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "def sample_values(device, model, dynamics, t, num_samples, batch_size):\n",
        "    with torch.no_grad():\n",
        "        states = torch.zeros(0, dynamics.state_dim)\n",
        "        values = torch.zeros(0, )\n",
        "\n",
        "        while len(states) < num_samples:\n",
        "            # sample batch\n",
        "            batch_times = torch.full((batch_size, 1), t)\n",
        "            batch_states = torch.zeros(batch_size, dynamics.state_dim)\n",
        "            for dim in range(dynamics.state_dim):\n",
        "                batch_states[:, dim].uniform_(*dynamics.state_test_range()[dim])\n",
        "            batch_states = dynamics.equivalent_wrapped_state(batch_states)\n",
        "            batch_coords = torch.cat((batch_times, batch_states), dim=-1)\n",
        "\n",
        "            batch_model_results = model({'coords': dynamics.coord_to_input(batch_coords.to(device))})\n",
        "            batch_values = dynamics.io_to_value(batch_model_results['model_in'], batch_model_results['model_out'].squeeze(dim=-1)).detach()\n",
        "\n",
        "            # store batch\n",
        "            states = torch.cat((states, batch_states.cpu()), dim=0)\n",
        "            values = torch.cat((values, batch_values.cpu()), dim=0)\n",
        "\n",
        "        states = states[:num_samples]\n",
        "        values = values[:num_samples]\n",
        "        coords = torch.cat((torch.full((num_samples, 1), t), states), dim=-1)\n",
        "    return values\n"
      ],
      "metadata": {
        "id": "JT3KyjNnCqHc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# uses real units\n",
        "def init_brt_hjivi_loss(dynamics, minWith, dirichlet_loss_divisor):\n",
        "    def brt_hjivi_loss(state, value, dvdt, dvds, boundary_value, dirichlet_mask, output):\n",
        "        if torch.all(dirichlet_mask):\n",
        "            # pretraining loss\n",
        "            diff_constraint_hom = torch.Tensor([0])\n",
        "        else:\n",
        "            ham = dynamics.hamiltonian(state, dvds)\n",
        "            if minWith == 'zero':\n",
        "                ham = torch.clamp(ham, max=0.0)\n",
        "\n",
        "            diff_constraint_hom = dvdt - ham\n",
        "            if minWith == 'target':\n",
        "                diff_constraint_hom = torch.max(\n",
        "                    diff_constraint_hom, value - boundary_value)\n",
        "        dirichlet = value[dirichlet_mask] - boundary_value[dirichlet_mask]\n",
        "        if dynamics.deepreach_model == 'exact':\n",
        "            if torch.all(dirichlet_mask):\n",
        "                # pretraining\n",
        "                dirichlet = output.squeeze(dim=-1)[dirichlet_mask]-0.0\n",
        "            else:\n",
        "                return {'diff_constraint_hom': torch.abs(diff_constraint_hom).sum()}\n",
        "\n",
        "        return {'dirichlet': torch.abs(dirichlet).sum() / dirichlet_loss_divisor,\n",
        "                'diff_constraint_hom': torch.abs(diff_constraint_hom).sum()}\n",
        "\n",
        "    return brt_hjivi_loss\n",
        "def init_brat_hjivi_loss(dynamics, minWith, dirichlet_loss_divisor):\n",
        "    def brat_hjivi_loss(state, value, dvdt, dvds, boundary_value, reach_value, avoid_value, dirichlet_mask, output):\n",
        "        if torch.all(dirichlet_mask):\n",
        "            # pretraining loss\n",
        "            diff_constraint_hom = torch.Tensor([0])\n",
        "        else:\n",
        "            ham = dynamics.hamiltonian(state, dvds)\n",
        "            if minWith == 'zero':\n",
        "                ham = torch.clamp(ham, max=0.0)\n",
        "\n",
        "            diff_constraint_hom = dvdt - ham\n",
        "            if minWith == 'target':\n",
        "                diff_constraint_hom = torch.min(\n",
        "                    torch.max(diff_constraint_hom, value - reach_value), value + avoid_value)\n",
        "\n",
        "        dirichlet = value[dirichlet_mask] - boundary_value[dirichlet_mask]\n",
        "        if dynamics.deepreach_model == 'exact':\n",
        "            if torch.all(dirichlet_mask):\n",
        "                dirichlet = output.squeeze(dim=-1)[dirichlet_mask]-0.0\n",
        "            else:\n",
        "                return {'diff_constraint_hom': torch.abs(diff_constraint_hom).sum()}\n",
        "        return {'dirichlet': torch.abs(dirichlet).sum() / dirichlet_loss_divisor,\n",
        "                'diff_constraint_hom': torch.abs(diff_constraint_hom).sum()}\n",
        "    return brat_hjivi_loss"
      ],
      "metadata": {
        "id": "ojN0xTCfCx5p"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2020 Vincent Sitzmann\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE.\n",
        "\"\"\"\n",
        "\n",
        "class BatchLinear(nn.Linear):\n",
        "    '''A linear layer'''\n",
        "    __doc__ = nn.Linear.__doc__\n",
        "\n",
        "    def forward(self, input, params=None):\n",
        "        if params is None:\n",
        "            params = OrderedDict(self.named_parameters())\n",
        "\n",
        "        bias = params.get('bias', None)\n",
        "        weight = params['weight']\n",
        "\n",
        "        output = input.matmul(weight.permute(*[i for i in range(len(weight.shape) - 2)], -1, -2))\n",
        "        output += bias.unsqueeze(-2)\n",
        "        return output\n",
        "\n",
        "\n",
        "class Sine(nn.Module):\n",
        "    def __init(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of factor 30\n",
        "        return torch.sin(30 * input)\n",
        "\n",
        "\n",
        "class FCBlock(nn.Module):\n",
        "    '''A fully connected neural network.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, in_features, out_features, num_hidden_layers, hidden_features,\n",
        "                 outermost_linear=False, nonlinearity='relu', weight_init=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.first_layer_init = None\n",
        "\n",
        "        # Dictionary that maps nonlinearity name to the respective function, initialization, and, if applicable,\n",
        "        # special first-layer initialization scheme\n",
        "        nls_and_inits = {'sine':(Sine(), sine_init, first_layer_sine_init),\n",
        "                         'relu':(nn.ReLU(inplace=True), init_weights_normal, None),\n",
        "                         'sigmoid':(nn.Sigmoid(), init_weights_xavier, None),\n",
        "                         'tanh':(nn.Tanh(), init_weights_xavier, None),\n",
        "                         'selu':(nn.SELU(inplace=True), init_weights_selu, None),\n",
        "                         'softplus':(nn.Softplus(), init_weights_normal, None),\n",
        "                         'elu':(nn.ELU(inplace=True), init_weights_elu, None)}\n",
        "\n",
        "        nl, nl_weight_init, first_layer_init = nls_and_inits[nonlinearity]\n",
        "\n",
        "        if weight_init is not None:  # Overwrite weight init if passed\n",
        "            self.weight_init = weight_init\n",
        "        else:\n",
        "            self.weight_init = nl_weight_init\n",
        "\n",
        "        self.net = []\n",
        "        self.net.append(nn.Sequential(\n",
        "            BatchLinear(in_features, hidden_features), nl\n",
        "        ))\n",
        "\n",
        "        for i in range(num_hidden_layers):\n",
        "            self.net.append(nn.Sequential(\n",
        "                BatchLinear(hidden_features, hidden_features), nl\n",
        "            ))\n",
        "\n",
        "        if outermost_linear:\n",
        "            self.net.append(nn.Sequential(BatchLinear(hidden_features, out_features)))\n",
        "        else:\n",
        "            self.net.append(nn.Sequential(\n",
        "                BatchLinear(hidden_features, out_features), nl\n",
        "            ))\n",
        "\n",
        "        self.net = nn.Sequential(*self.net)\n",
        "        if self.weight_init is not None:\n",
        "            self.net.apply(self.weight_init)\n",
        "\n",
        "        if first_layer_init is not None: # Apply special initialization to first layer, if applicable.\n",
        "            self.net[0].apply(first_layer_init)\n",
        "\n",
        "    def forward(self, coords, params=None, **kwargs):\n",
        "        if params is None:\n",
        "            params = OrderedDict(self.named_parameters())\n",
        "\n",
        "        output = self.net(coords)\n",
        "        return output\n",
        "\n",
        "\n",
        "class SingleBVPNet(nn.Module):\n",
        "    '''A canonical representation network for a BVP.'''\n",
        "\n",
        "    def __init__(self, out_features=1, type='sine', in_features=2,\n",
        "                 mode='mlp', hidden_features=256, num_hidden_layers=3, **kwargs):\n",
        "        super().__init__()\n",
        "        self.mode = mode\n",
        "        self.net = FCBlock(in_features=in_features, out_features=out_features, num_hidden_layers=num_hidden_layers,\n",
        "                           hidden_features=hidden_features, outermost_linear=True, nonlinearity=type)\n",
        "        print(self)\n",
        "\n",
        "    def forward(self, model_input, params=None):\n",
        "        if params is None:\n",
        "            params = OrderedDict(self.named_parameters())\n",
        "\n",
        "        # Enables us to compute gradients w.r.t. coordinates\n",
        "        # TODO: should not need to .clone().detach().requires_grad_(True); instead, use .retain_grad() on input in calling script\n",
        "        # otherwise, .detach() removes input from the graph so grad cannot propagate back end-to-end, e.g., percept -> NN -> state estimation (input)\n",
        "        coords_org = model_input['coords'].clone().detach().requires_grad_(True)\n",
        "        coords = coords_org\n",
        "\n",
        "        output = self.net(coords)\n",
        "        return {'model_in': coords_org, 'model_out': output}\n",
        "\n",
        "\n",
        "########################\n",
        "# Initialization methods\n",
        "def init_weights_normal(m):\n",
        "    if type(m) == BatchLinear or type(m) == nn.Linear:\n",
        "        if hasattr(m, 'weight'):\n",
        "            nn.init.kaiming_normal_(m.weight, a=0.0, nonlinearity='relu', mode='fan_in')\n",
        "\n",
        "\n",
        "def init_weights_selu(m):\n",
        "    if type(m) == BatchLinear or type(m) == nn.Linear:\n",
        "        if hasattr(m, 'weight'):\n",
        "            num_input = m.weight.size(-1)\n",
        "            nn.init.normal_(m.weight, std=1 / math.sqrt(num_input))\n",
        "\n",
        "\n",
        "def init_weights_elu(m):\n",
        "    if type(m) == BatchLinear or type(m) == nn.Linear:\n",
        "        if hasattr(m, 'weight'):\n",
        "            num_input = m.weight.size(-1)\n",
        "            nn.init.normal_(m.weight, std=math.sqrt(1.5505188080679277) / math.sqrt(num_input))\n",
        "\n",
        "\n",
        "def init_weights_xavier(m):\n",
        "    if type(m) == BatchLinear or type(m) == nn.Linear:\n",
        "        if hasattr(m, 'weight'):\n",
        "            nn.init.xavier_normal_(m.weight)\n",
        "\n",
        "\n",
        "def sine_init(m):\n",
        "    with torch.no_grad():\n",
        "        if hasattr(m, 'weight'):\n",
        "            num_input = m.weight.size(-1)\n",
        "            # See supplement Sec. 1.5 for discussion of factor 30\n",
        "            m.weight.uniform_(-np.sqrt(6 / num_input) / 30, np.sqrt(6 / num_input) / 30)\n",
        "\n",
        "\n",
        "def first_layer_sine_init(m):\n",
        "    with torch.no_grad():\n",
        "        if hasattr(m, 'weight'):\n",
        "            num_input = m.weight.size(-1)\n",
        "            # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of factor 30\n",
        "            m.weight.uniform_(-1 / num_input, 1 / num_input)\n"
      ],
      "metadata": {
        "id": "_103N1sCCzv1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Dynamics Code"
      ],
      "metadata": {
        "id": "8YL1FjbYDcRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# during training, states will be sampled uniformly by each state dimension from the model-unit -1 to 1 range (for training stability),\n",
        "# which may or may not correspond to proper test ranges\n",
        "# note that coord refers to [time, *state], and input refers to whatever is fed directly to the model (often [time, *state, params])\n",
        "# in the future, code will need to be fixed to correctly handle parameterized models\n",
        "class Dynamics(ABC):\n",
        "    def __init__(self,\n",
        "    loss_type:str, set_mode:str,\n",
        "    state_dim:int, input_dim:int,\n",
        "    control_dim:int, disturbance_dim:int,\n",
        "    state_mean:list, state_var:list,\n",
        "    value_mean:float, value_var:float, value_normto:float,\n",
        "    deepreach_model:str):\n",
        "        self.loss_type = loss_type\n",
        "        self.set_mode = set_mode\n",
        "        self.state_dim = state_dim\n",
        "        self.input_dim = input_dim\n",
        "        self.control_dim = control_dim\n",
        "        self.disturbance_dim = disturbance_dim\n",
        "        self.state_mean = torch.tensor(state_mean)\n",
        "        self.state_var = torch.tensor(state_var)\n",
        "        self.value_mean = value_mean\n",
        "        self.value_var = value_var\n",
        "        self.value_normto = value_normto\n",
        "        self.deepreach_model = deepreach_model\n",
        "        assert self.loss_type in ['brt_hjivi', 'brat_hjivi'], f'loss type {self.loss_type} not recognized'\n",
        "        if self.loss_type == 'brat_hjivi':\n",
        "            assert callable(self.reach_fn) and callable(self.avoid_fn)\n",
        "        assert self.set_mode in ['reach', 'avoid'], f'set mode {self.set_mode} not recognized'\n",
        "        for state_descriptor in [self.state_mean, self.state_var]:\n",
        "            assert len(state_descriptor) == self.state_dim, 'state descriptor dimension does not equal state dimension, ' + str(len(state_descriptor)) + ' != ' + str(self.state_dim)\n",
        "\n",
        "    # ALL METHODS ARE BATCH COMPATIBLE\n",
        "\n",
        "    # MODEL-UNIT CONVERSIONS (TODO: refactor into separate model-unit conversion class?)\n",
        "\n",
        "    # convert model input to real coord\n",
        "    def input_to_coord(self, input):\n",
        "        coord = input.clone()\n",
        "        coord[..., 1:] = (input[..., 1:] * self.state_var.to(device=input.device)) + self.state_mean.to(device=input.device)\n",
        "        return coord\n",
        "\n",
        "    # convert real coord to model input\n",
        "    def coord_to_input(self, coord):\n",
        "        input = coord.clone()\n",
        "        input[..., 1:] = (coord[..., 1:] - self.state_mean.to(device=coord.device)) / self.state_var.to(device=coord.device)\n",
        "        return input\n",
        "\n",
        "    # convert model io to real value\n",
        "    def io_to_value(self, input, output):\n",
        "        if self.deepreach_model==\"diff\":\n",
        "            return (output * self.value_var / self.value_normto) + self.boundary_fn(self.input_to_coord(input)[..., 1:])\n",
        "        elif self.deepreach_model==\"exact\":\n",
        "            return (output * input[..., 0] * self.value_var / self.value_normto) + self.boundary_fn(self.input_to_coord(input)[..., 1:])\n",
        "        else:\n",
        "            return (output * self.value_var / self.value_normto) + self.value_mean\n",
        "\n",
        "    # convert model io to real dv\n",
        "    def io_to_dv(self, input, output):\n",
        "        dodi = jacobian(output.unsqueeze(dim=-1), input)[0].squeeze(dim=-2)\n",
        "\n",
        "        if self.deepreach_model==\"diff\":\n",
        "            dvdt = (self.value_var / self.value_normto) * dodi[..., 0]\n",
        "\n",
        "            dvds_term1 = (self.value_var / self.value_normto / self.state_var.to(device=dodi.device)) * dodi[..., 1:]\n",
        "            state = self.input_to_coord(input)[..., 1:]\n",
        "            dvds_term2 = jacobian(self.boundary_fn(state).unsqueeze(dim=-1), state)[0].squeeze(dim=-2)\n",
        "            dvds = dvds_term1 + dvds_term2\n",
        "        elif self.deepreach_model==\"exact\":\n",
        "            dvdt = (self.value_var / self.value_normto) * \\\n",
        "                (input[..., 0]*dodi[..., 0] + output)\n",
        "\n",
        "            dvds_term1 = (self.value_var / self.value_normto /\n",
        "                          self.state_var.to(device=dodi.device)) * dodi[..., 1:] * input[..., 0].unsqueeze(-1)\n",
        "            state = self.input_to_coord(input)[..., 1:]\n",
        "            dvds_term2 = jacobian(self.boundary_fn(\n",
        "                state).unsqueeze(dim=-1), state)[0].squeeze(dim=-2)\n",
        "            dvds = dvds_term1 + dvds_term2\n",
        "        else:\n",
        "            dvdt = (self.value_var / self.value_normto) * dodi[..., 0]\n",
        "            dvds = (self.value_var / self.value_normto / self.state_var.to(device=dodi.device)) * dodi[..., 1:]\n",
        "\n",
        "        return torch.cat((dvdt.unsqueeze(dim=-1), dvds), dim=-1)\n",
        "\n",
        "    # ALL FOLLOWING METHODS USE REAL UNITS\n",
        "\n",
        "    @abstractmethod\n",
        "    def state_test_range(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def equivalent_wrapped_state(self, state):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def dsdt(self, state, control, disturbance):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def boundary_fn(self, state):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def sample_target_state(self, num_samples):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def cost_fn(self, state_traj):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def hamiltonian(self, state, dvds):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def optimal_control(self, state, dvds):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def optimal_disturbance(self, state, dvds):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def plot_config(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "class ParameterizedVertDrone2D(Dynamics):\n",
        "    def __init__(self, gravity:float, input_multiplier_max:float, input_magnitude_max:float):\n",
        "        self.gravity = gravity                             # g\n",
        "        self.input_multiplier_max = input_multiplier_max   # k_max\n",
        "        self.input_magnitude_max = input_magnitude_max     # u_max\n",
        "        super().__init__(\n",
        "            loss_type='brt_hjivi', set_mode='avoid',\n",
        "            state_dim=3, input_dim=4, control_dim=1, disturbance_dim=0,\n",
        "            state_mean=[0, 1.5, self.input_multiplier_max/2], # v, z, k\n",
        "            state_var=[4, 2, self.input_multiplier_max/2],    # v, z, k\n",
        "            value_mean=0.25,\n",
        "            value_var=0.5,\n",
        "            value_normto=0.02,\n",
        "            deepreach_model=\"exact\",\n",
        "        )\n",
        "\n",
        "    def state_test_range(self):\n",
        "        return [\n",
        "            [-4, 4],                        # v\n",
        "            [-0.5, 3.5],                    # z\n",
        "            [0, self.input_multiplier_max], # k\n",
        "        ]\n",
        "\n",
        "    def equivalent_wrapped_state(self, state):\n",
        "        wrapped_state = torch.clone(state)\n",
        "        return wrapped_state\n",
        "\n",
        "    # ParameterizedVertDrone2D dynamics\n",
        "    # \\dot v = k*u - g\n",
        "    # \\dot z = v\n",
        "    # \\dot k = 0\n",
        "    def dsdt(self, state, control, disturbance):\n",
        "        dsdt = torch.zeros_like(state)\n",
        "        dsdt[..., 0] = state[..., 2]*control[..., 0] - self.gravity\n",
        "        dsdt[..., 1] = state[..., 0]\n",
        "        dsdt[..., 2] = 0\n",
        "        return dsdt\n",
        "\n",
        "    def boundary_fn(self, state):\n",
        "        return -torch.abs(state[..., 1] - 1.5) + 1.5\n",
        "\n",
        "    def sample_target_state(self, num_samples):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def cost_fn(self, state_traj):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def hamiltonian(self, state, dvds):\n",
        "        return state[..., 2]*torch.abs(dvds[..., 0]*self.input_magnitude_max) \\\n",
        "                - dvds[..., 0]*self.gravity \\\n",
        "                + dvds[..., 1]*state[..., 0]\n",
        "\n",
        "    def optimal_control(self, state, dvds):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def optimal_disturbance(self, state, dvds):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def plot_config(self):\n",
        "        return {\n",
        "            'state_slices': [0, 1.5, self.input_multiplier_max/2],\n",
        "            'state_labels': ['v', 'z', 'k'],\n",
        "            'x_axis_idx': 0,\n",
        "            'y_axis_idx': 1,\n",
        "            'z_axis_idx': 2,\n",
        "        }\n",
        "\n",
        "class Air3D(Dynamics):\n",
        "    def __init__(self, collisionR:float, velocity:float, omega_max:float, angle_alpha_factor:float):\n",
        "        self.collisionR = collisionR\n",
        "        self.velocity = velocity\n",
        "        self.omega_max = omega_max\n",
        "        self.angle_alpha_factor = angle_alpha_factor\n",
        "        super().__init__(\n",
        "            loss_type='brt_hjivi', set_mode='avoid',\n",
        "            state_dim=3, input_dim=4, control_dim=1, disturbance_dim=1,\n",
        "            state_mean=[0, 0, 0],\n",
        "            state_var=[1, 1, self.angle_alpha_factor*math.pi],\n",
        "            value_mean=0.25,\n",
        "            value_var=0.5,\n",
        "            value_normto=0.02,\n",
        "            deepreach_model=\"exact\",\n",
        "        )\n",
        "\n",
        "    def state_test_range(self):\n",
        "        return [\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-math.pi, math.pi],\n",
        "        ]\n",
        "\n",
        "    def equivalent_wrapped_state(self, state):\n",
        "        wrapped_state = torch.clone(state)\n",
        "        wrapped_state[..., 2] = (wrapped_state[..., 2] + math.pi) % (2*math.pi) - math.pi\n",
        "        return wrapped_state\n",
        "\n",
        "    # Air3D dynamics\n",
        "    # \\dot x    = -v + v \\cos \\psi + u y\n",
        "    # \\dot y    = v \\sin \\psi - u x\n",
        "    # \\dot \\psi = d - u\n",
        "    def dsdt(self, state, control, disturbance):\n",
        "        dsdt = torch.zeros_like(state)\n",
        "        dsdt[..., 0] = -self.velocity + self.velocity*torch.cos(state[..., 2]) + control[..., 0]*state[..., 1]\n",
        "        dsdt[..., 1] = self.velocity*torch.sin(state[..., 2]) - control[..., 0]*state[..., 0]\n",
        "        dsdt[..., 2] = disturbance[..., 0] - control[..., 0]\n",
        "        return dsdt\n",
        "\n",
        "    def boundary_fn(self, state):\n",
        "        return torch.norm(state[..., :2], dim=-1) - self.collisionR\n",
        "\n",
        "    def sample_target_state(self, num_samples):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def cost_fn(self, state_traj):\n",
        "        return torch.min(self.boundary_fn(state_traj), dim=-1).values\n",
        "\n",
        "    def hamiltonian(self, state, dvds):\n",
        "        ham = self.omega_max * torch.abs(dvds[..., 0] * state[..., 1] - dvds[..., 1] * state[..., 0] - dvds[..., 2])  # Control component\n",
        "        ham = ham - self.omega_max * torch.abs(dvds[..., 2])  # Disturbance component\n",
        "        ham = ham + (self.velocity * (torch.cos(state[..., 2]) - 1.0) * dvds[..., 0]) + (self.velocity * torch.sin(state[..., 2]) * dvds[..., 1])  # Constant component\n",
        "        return ham\n",
        "\n",
        "    def optimal_control(self, state, dvds):\n",
        "        det = dvds[..., 0]*state[..., 1] - dvds[..., 1]*state[..., 0]-dvds[..., 2]\n",
        "        return (self.omega_max * torch.sign(det))[..., None]\n",
        "\n",
        "    def optimal_disturbance(self, state, dvds):\n",
        "        return (-self.omega_max * torch.sign(dvds[..., 2]))[..., None]\n",
        "\n",
        "    def plot_config(self):\n",
        "        return {\n",
        "            'state_slices': [0, 0, 0],\n",
        "            'state_labels': ['x', 'y', 'theta'],\n",
        "            'x_axis_idx': 0,\n",
        "            'y_axis_idx': 1,\n",
        "            'z_axis_idx': 2,\n",
        "        }\n",
        "\n",
        "class Dubins3D(Dynamics):\n",
        "    def __init__(self, goalR:float, velocity:float, omega_max:float, angle_alpha_factor:float, set_mode:str, freeze_model: bool):\n",
        "        self.goalR = goalR\n",
        "        self.velocity = velocity\n",
        "        self.omega_max = omega_max\n",
        "        self.angle_alpha_factor = angle_alpha_factor\n",
        "        self.freeze_model = freeze_model\n",
        "        super().__init__(\n",
        "            loss_type='brt_hjivi', set_mode=set_mode,\n",
        "            state_dim=3, input_dim=4, control_dim=1, disturbance_dim=0,\n",
        "            state_mean=[0, 0, 0],\n",
        "            state_var=[1, 1, self.angle_alpha_factor*math.pi],\n",
        "            value_mean=0.25,\n",
        "            value_var=0.5,\n",
        "            value_normto=0.02,\n",
        "            deepreach_model=\"exact\"\n",
        "        )\n",
        "\n",
        "    def state_test_range(self):\n",
        "        return [\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-math.pi, math.pi],\n",
        "        ]\n",
        "\n",
        "    def equivalent_wrapped_state(self, state):\n",
        "        wrapped_state = torch.clone(state)\n",
        "        wrapped_state[..., 2] = (wrapped_state[..., 2] + math.pi) % (2*math.pi) - math.pi\n",
        "        return wrapped_state\n",
        "\n",
        "    # Dubins3D dynamics\n",
        "    # \\dot x    = v \\cos \\theta\n",
        "    # \\dot y    = v \\sin \\theta\n",
        "    # \\dot \\theta = u\n",
        "    def dsdt(self, state, control, disturbance):\n",
        "        if self.freeze_model:\n",
        "            raise NotImplementedError\n",
        "        dsdt = torch.zeros_like(state)\n",
        "        dsdt[..., 0] = self.velocity*torch.cos(state[..., 2])\n",
        "        dsdt[..., 1] = self.velocity*torch.sin(state[..., 2])\n",
        "        dsdt[..., 2] = control[..., 0]\n",
        "        return dsdt\n",
        "\n",
        "    def boundary_fn(self, state):\n",
        "        return torch.norm(state[..., :2], dim=-1) - self.goalR\n",
        "\n",
        "    def sample_target_state(self, num_samples):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def cost_fn(self, state_traj):\n",
        "        return torch.min(self.boundary_fn(state_traj), dim=-1).values\n",
        "\n",
        "    def hamiltonian(self, state, dvds):\n",
        "        if self.freeze_model:\n",
        "            raise NotImplementedError\n",
        "        if self.set_mode == 'reach':\n",
        "            return self.velocity*(torch.cos(state[..., 2]) * dvds[..., 0] + torch.sin(state[..., 2]) * dvds[..., 1]) - self.omega_max * torch.abs(dvds[..., 2])\n",
        "        elif self.set_mode == 'avoid':\n",
        "            return self.velocity*(torch.cos(state[..., 2]) * dvds[..., 0] + torch.sin(state[..., 2]) * dvds[..., 1]) + self.omega_max * torch.abs(dvds[..., 2])\n",
        "\n",
        "    def optimal_control(self, state, dvds):\n",
        "        if self.set_mode == 'reach':\n",
        "            return (-self.omega_max*torch.sign(dvds[..., 2]))[..., None]\n",
        "        elif self.set_mode == 'avoid':\n",
        "            return (self.omega_max*torch.sign(dvds[..., 2]))[..., None]\n",
        "\n",
        "    def optimal_disturbance(self, state, dvds):\n",
        "        return 0\n",
        "\n",
        "    def plot_config(self):\n",
        "        return {\n",
        "            'state_slices': [0, 0, 0],\n",
        "            'state_labels': ['x', 'y', r'$\\theta$'],\n",
        "            'x_axis_idx': 0,\n",
        "            'y_axis_idx': 1,\n",
        "            'z_axis_idx': 2,\n",
        "        }\n",
        "\n",
        "class Dubins4D(Dynamics):\n",
        "    def __init__(self, bound_mode:str):\n",
        "        self.vMin = 0.2\n",
        "        self.vMax = 14.8\n",
        "        self.collisionR = 1.5\n",
        "        self.bound_mode = bound_mode\n",
        "        assert self.bound_mode in ['v1', 'v2']\n",
        "\n",
        "        xMean = 0\n",
        "        yMean = 0\n",
        "        thetaMean = 0\n",
        "        vMean = 7.5\n",
        "        aMean = 0\n",
        "        oMean = 0\n",
        "\n",
        "        xVar = 10\n",
        "        yVar = 10\n",
        "        thetaVar = 1.2*math.pi\n",
        "        vVar = 7.5\n",
        "        aVar = 10\n",
        "        oVar = 3*math.pi if self.bound_mode == 'v1' else 2.0\n",
        "\n",
        "        super().__init__(\n",
        "            loss_type='brt_hjivi',\n",
        "            state_dim=14, input_dim=15,  control_dim=2, disturbance_dim=0,\n",
        "            state_mean=[xMean, yMean, thetaMean, vMean, xMean, yMean, aMean, aMean, oMean, oMean, aMean, aMean, oMean, oMean],\n",
        "            state_var=[xVar, yVar, thetaVar, vVar, xVar, yVar, aVar, aVar, oVar, oVar, aVar, aVar, oVar, oVar],\n",
        "            value_mean=13,\n",
        "            value_var=14,\n",
        "            value_normto=0.02,\n",
        "            deepreach_model=\"exact\",\n",
        "        )\n",
        "\n",
        "    def state_test_range(self):\n",
        "        return [\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-math.pi, math.pi],\n",
        "            [self.vMin, self.vMax],\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "        ]\n",
        "\n",
        "    def equivalent_wrapped_state(self, state):\n",
        "        wrapped_state = torch.clone(state)\n",
        "        wrapped_state[..., 2] = (wrapped_state[..., 2] + math.pi) % (2*math.pi) - math.pi\n",
        "        return wrapped_state\n",
        "\n",
        "    def boundary_fn(self, state):\n",
        "        return torch.norm(state[..., 0:2] - state[..., 4:6], dim=-1) - self.collisionR\n",
        "\n",
        "    def sample_target_state(self, num_samples):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def cost_fn(self, state_traj):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def dsdt(self, state, control, disturbance):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def hamiltonian(self, state, dvds):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def optimal_control(self, state, dvds):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def optimal_disturbance(self, state, dvds):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def plot_config(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "class NarrowPassage(Dynamics):\n",
        "    def __init__(self, avoid_fn_weight:float, avoid_only:bool):\n",
        "        self.L = 2.0\n",
        "\n",
        "        # # Target positions\n",
        "        self.goalX = [6.0, -6.0]\n",
        "        self.goalY = [-1.4, 1.4]\n",
        "\n",
        "        # State bounds\n",
        "        self.vMin = 0.001\n",
        "        self.vMax = 6.50\n",
        "        self.phiMin = -0.3*math.pi + 0.001\n",
        "        self.phiMax = 0.3*math.pi - 0.001\n",
        "\n",
        "        # Control bounds\n",
        "        self.aMin = -4.0\n",
        "        self.aMax = 2.0\n",
        "        self.psiMin = -3.0*math.pi\n",
        "        self.psiMax = 3.0*math.pi\n",
        "\n",
        "        # Lower and upper curb positions (in the y direction)\n",
        "        self.curb_positions = [-2.8, 2.8]\n",
        "\n",
        "        # Stranded car position\n",
        "        self.stranded_car_pos = [0.0, -1.8]\n",
        "\n",
        "        self.avoid_fn_weight = avoid_fn_weight\n",
        "\n",
        "        self.avoid_only = avoid_only\n",
        "\n",
        "        super().__init__(\n",
        "            loss_type='brt_hjivi' if self.avoid_only else 'brat_hjivi', set_mode='avoid' if self.avoid_only else 'reach',\n",
        "            state_dim=10, input_dim=11, control_dim=4, disturbance_dim=0,\n",
        "            # state = [x1, y1, th1, v1, phi1, x2, y2, th2, v2, phi2]\n",
        "            state_mean=[\n",
        "                0, 0, 0, 3, 0,\n",
        "                0, 0, 0, 3, 0\n",
        "            ],\n",
        "            state_var=[\n",
        "                8.0, 3.8, 1.2*math.pi, 4.0, 1.2*0.3*math.pi,\n",
        "                8.0, 3.8, 1.2*math.pi, 4.0, 1.2*0.3*math.pi,\n",
        "            ],\n",
        "            value_mean=0.25*8.0,\n",
        "            value_var=0.5*8.0,\n",
        "            value_normto=0.02,\n",
        "            deepreach_model=\"exact\",\n",
        "        )\n",
        "\n",
        "    def state_test_range(self):\n",
        "        return [\n",
        "            [-8, 8],\n",
        "            [-3.8, 3.8],\n",
        "            [-math.pi, math.pi],\n",
        "            [-1, 7],\n",
        "            [-0.3*math.pi, 0.3*math.pi],\n",
        "            [-8, 8],\n",
        "            [-3.8, 3.8],\n",
        "            [-math.pi, math.pi],\n",
        "            [-1, 7],\n",
        "            [-0.3*math.pi, 0.3*math.pi],\n",
        "        ]\n",
        "\n",
        "    def equivalent_wrapped_state(self, state):\n",
        "        wrapped_state = torch.clone(state)\n",
        "        wrapped_state[..., 2] = (wrapped_state[..., 2] + math.pi) % (2*math.pi) - math.pi\n",
        "        wrapped_state[..., 4] = (wrapped_state[..., 4] + math.pi) % (2*math.pi) - math.pi\n",
        "        wrapped_state[..., 7] = (wrapped_state[..., 7] + math.pi) % (2*math.pi) - math.pi\n",
        "        wrapped_state[..., 9] = (wrapped_state[..., 9] + math.pi) % (2*math.pi) - math.pi\n",
        "        return wrapped_state\n",
        "\n",
        "    # NarrowPassage dynamics\n",
        "    # \\dot x   = v * cos(th)\n",
        "    # \\dot y   = v * sin(th)\n",
        "    # \\dot th  = v * tan(phi) / L\n",
        "    # \\dot v   = u1\n",
        "    # \\dot phi = u2\n",
        "    # \\dot x   = ...\n",
        "    # \\dot y   = ...\n",
        "    # \\dot th  = ...\n",
        "    # \\dot v   = ...\n",
        "    # \\dot phi = ...\n",
        "    def dsdt(self, state, control, disturbance):\n",
        "        dsdt = torch.zeros_like(state)\n",
        "        dsdt[..., 0] = state[..., 3]*torch.cos(state[..., 2])\n",
        "        dsdt[..., 1] = state[..., 3]*torch.sin(state[..., 2])\n",
        "        dsdt[..., 2] = state[..., 3]*torch.tan(state[..., 4]) / self.L\n",
        "        dsdt[..., 3] = control[..., 0]\n",
        "        dsdt[..., 4] = control[..., 1]\n",
        "        dsdt[..., 5] = state[..., 8]*torch.cos(state[..., 7])\n",
        "        dsdt[..., 6] = state[..., 8]*torch.sin(state[..., 7])\n",
        "        dsdt[..., 7] = state[..., 8]*torch.tan(state[..., 9]) / self.L\n",
        "        dsdt[..., 8] = control[..., 2]\n",
        "        dsdt[..., 9] = control[..., 3]\n",
        "        return dsdt\n",
        "\n",
        "    def reach_fn(self, state):\n",
        "        if self.avoid_only:\n",
        "            raise RuntimeError\n",
        "        # vehicle 1\n",
        "        goal_tensor_R1 = torch.tensor([self.goalX[0], self.goalY[0]], device=state.device)\n",
        "        dist_R1 = torch.norm(state[..., 0:2] - goal_tensor_R1, dim=-1) - self.L\n",
        "        # vehicle 2\n",
        "        goal_tensor_R2 = torch.tensor([self.goalX[1], self.goalY[1]], device=state.device)\n",
        "        dist_R2 = torch.norm(state[..., 5:7] - goal_tensor_R2, dim=-1) - self.L\n",
        "        return torch.maximum(dist_R1, dist_R2)\n",
        "\n",
        "    def avoid_fn(self, state):\n",
        "        # distance from lower curb\n",
        "        dist_lc_R1 = state[..., 1] - self.curb_positions[0] - 0.5*self.L\n",
        "        dist_lc_R2 = state[..., 6] - self.curb_positions[0] - 0.5*self.L\n",
        "        dist_lc = torch.minimum(dist_lc_R1, dist_lc_R2)\n",
        "\n",
        "        # distance from upper curb\n",
        "        dist_uc_R1 = self.curb_positions[1] - state[..., 1] - 0.5*self.L\n",
        "        dist_uc_R2 = self.curb_positions[1] - state[..., 6] - 0.5*self.L\n",
        "        dist_uc = torch.minimum(dist_uc_R1, dist_uc_R2)\n",
        "\n",
        "        # distance from the stranded car\n",
        "        stranded_car_pos = torch.tensor(self.stranded_car_pos, device=state.device)\n",
        "        dist_stranded_R1 = torch.norm(state[..., 0:2] - stranded_car_pos, dim=-1) - self.L\n",
        "        dist_stranded_R2 = torch.norm(state[..., 5:7] - stranded_car_pos, dim=-1) - self.L\n",
        "        dist_stranded = torch.minimum(dist_stranded_R1, dist_stranded_R2)\n",
        "\n",
        "        # distance between the vehicles themselves\n",
        "        dist_R1R2 = torch.norm(state[..., 0:2] - state[..., 5:7], dim=-1) - self.L\n",
        "\n",
        "        return self.avoid_fn_weight * torch.min(torch.min(torch.min(dist_lc, dist_uc), dist_stranded), dist_R1R2)\n",
        "\n",
        "    def boundary_fn(self, state):\n",
        "        if self.avoid_only:\n",
        "            return self.avoid_fn(state)\n",
        "        else:\n",
        "            return torch.maximum(self.reach_fn(state), -self.avoid_fn(state))\n",
        "\n",
        "    def sample_target_state(self, num_samples):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def cost_fn(self, state_traj):\n",
        "        if self.avoid_only:\n",
        "            return torch.min(self.avoid_fn(state_traj), dim=-1).values\n",
        "        else:\n",
        "            # return min_t max{l(x(t)), max_k_up_to_t{-g(x(k))}}, where l(x) is reach_fn, g(x) is avoid_fn\n",
        "            reach_values = self.reach_fn(state_traj)\n",
        "            avoid_values = self.avoid_fn(state_traj)\n",
        "            return torch.min(torch.maximum(reach_values, torch.cummax(-avoid_values, dim=-1).values), dim=-1).values\n",
        "\n",
        "    def hamiltonian(self, state, dvds):\n",
        "        optimal_control = self.optimal_control(state, dvds)\n",
        "        return state[..., 3] * torch.cos(state[..., 2]) * dvds[..., 0] + \\\n",
        "               state[..., 3] * torch.sin(state[..., 2]) * dvds[..., 1] + \\\n",
        "               state[..., 3] * torch.tan(state[..., 4]) * dvds[..., 2] / self.L + \\\n",
        "               optimal_control[..., 0] * dvds[..., 3] + \\\n",
        "               optimal_control[..., 1] * dvds[..., 4] + \\\n",
        "               state[..., 8] * torch.cos(state[..., 7]) * dvds[..., 5] + \\\n",
        "               state[..., 8] * torch.sin(state[..., 7]) * dvds[..., 6] + \\\n",
        "               state[..., 8] * torch.tan(state[..., 9]) * dvds[..., 7] / self.L + \\\n",
        "               optimal_control[..., 2] * dvds[..., 8] + \\\n",
        "               optimal_control[..., 3] * dvds[..., 9]\n",
        "\n",
        "    def optimal_control(self, state, dvds):\n",
        "        a1_min = self.aMin * (state[..., 3] > self.vMin)\n",
        "        a1_max = self.aMax * (state[..., 3] < self.vMax)\n",
        "        psi1_min = self.psiMin * (state[..., 4] > self.phiMin)\n",
        "        psi1_max = self.psiMax * (state[..., 4] < self.phiMax)\n",
        "        a2_min = self.aMin * (state[..., 8] > self.vMin)\n",
        "        a2_max = self.aMax * (state[..., 8] < self.vMax)\n",
        "        psi2_min = self.psiMin * (state[..., 9] > self.phiMin)\n",
        "        psi2_max = self.psiMax * (state[..., 9] < self.phiMax)\n",
        "\n",
        "        if self.avoid_only:\n",
        "            a1 = torch.where(dvds[..., 3] < 0, a1_min, a1_max)\n",
        "            psi1 = torch.where(dvds[..., 4] < 0, psi1_min, psi1_max)\n",
        "            a2 = torch.where(dvds[..., 8] < 0, a2_min, a2_max)\n",
        "            psi2 = torch.where(dvds[..., 9] < 0, psi2_min, psi2_max)\n",
        "\n",
        "        else:\n",
        "            a1 = torch.where(dvds[..., 3] > 0, a1_min, a1_max)\n",
        "            psi1 = torch.where(dvds[..., 4] > 0, psi1_min, psi1_max)\n",
        "            a2 = torch.where(dvds[..., 8] > 0, a2_min, a2_max)\n",
        "            psi2 = torch.where(dvds[..., 9] > 0, psi2_min, psi2_max)\n",
        "\n",
        "        return torch.cat((a1[..., None], psi1[..., None], a2[..., None], psi2[..., None]), dim=-1)\n",
        "\n",
        "    def optimal_disturbance(self, state, dvds):\n",
        "        return 0\n",
        "\n",
        "    def plot_config(self):\n",
        "        return {\n",
        "            'state_slices': [\n",
        "                -6.0, -1.4, 0.0, 6.5, 0.0,\n",
        "                -6.0, 1.4, -math.pi, 0.0, 0.0\n",
        "            ],\n",
        "            'state_labels': [\n",
        "                r'$x_1$', r'$y_1$', r'$\\theta_1$', r'$v_1$', r'$\\phi_1$',\n",
        "                r'$x_2$', r'$y_2$', r'$\\theta_2$', r'$v_2$', r'$\\phi_2$',\n",
        "            ],\n",
        "            'x_axis_idx': 0,\n",
        "            'y_axis_idx': 1,\n",
        "            'z_axis_idx': 2,\n",
        "        }\n",
        "\n",
        "class ReachAvoidRocketLanding(Dynamics):\n",
        "    def __init__(self):\n",
        "        super().__init__(\n",
        "            loss_type='brat_hjivi', set_mode='reach',\n",
        "            state_dim=6, input_dim=7, control_dim=2, disturbance_dim=0,\n",
        "            state_mean=[0.0, 80.0, 0.0, 0.0, 0.0, 0.0],\n",
        "            state_var=[150.0, 70.0, 1.2*math.pi, 200.0, 200.0, 10.0],\n",
        "            value_mean=0.0,\n",
        "            value_var=1.0,\n",
        "            value_normto=0.02,\n",
        "            deepreach_model=\"exact\",\n",
        "        )\n",
        "\n",
        "    def state_test_range(self):\n",
        "        return [\n",
        "            [-150, 150],\n",
        "            [10, 150],\n",
        "            [-math.pi, math.pi],\n",
        "            [-200, 200],\n",
        "            [-200, 200],\n",
        "            [-10, 10],\n",
        "        ]\n",
        "\n",
        "    def equivalent_wrapped_state(self, state):\n",
        "        wrapped_state = torch.clone(state)\n",
        "        wrapped_state[..., 2] = (wrapped_state[..., 2] + math.pi) % (2*math.pi) - math.pi\n",
        "        return wrapped_state\n",
        "\n",
        "    # \\dot x = v_x\n",
        "    # \\dot y = v_y\n",
        "    # \\dot th = w\n",
        "    # \\dot v_x = u1 * cos(th) - u2 sin(th)\n",
        "    # \\dot v_y = u1 * sin(th) + u2 cos(th) - 9.81\n",
        "    # \\dot w = 0.3 * u1\n",
        "    def dsdt(self, state, control, disturbance):\n",
        "        dsdt = torch.zeros_like(state)\n",
        "        dsdt[..., 0] = state[..., 3]\n",
        "        dsdt[..., 1] = state[..., 4]\n",
        "        dsdt[..., 2] = state[..., 5]\n",
        "        dsdt[..., 3] = control[..., 0]*torch.cos(state[..., 2]) - control[..., 1]*torch.sin(state[..., 2])\n",
        "        dsdt[..., 4] = control[..., 0]*torch.sin(state[..., 2]) + control[..., 1]*torch.cos(state[..., 2]) - 9.81\n",
        "        dsdt[..., 5] = 0.3*control[..., 0]\n",
        "        return dsdt\n",
        "\n",
        "    def reach_fn(self, state):\n",
        "        # Only target set in the xy direction\n",
        "        # Target set position in x direction\n",
        "        dist_x = torch.abs(state[..., 0]) - 20.0 #[-20, 150] boundary_fn range\n",
        "\n",
        "        # Target set position in y direction\n",
        "        dist_y = state[..., 1] - 20.0  #[-10, 130] boundary_fn range\n",
        "\n",
        "        # First compute the target function as you normally would but then normalize it later.\n",
        "        max_dist = torch.max(dist_x, dist_y)\n",
        "        return torch.where((max_dist >= 0), max_dist/150.0, max_dist/10.0)\n",
        "\n",
        "    def avoid_fn(self, state):\n",
        "        # distance to floor\n",
        "        dist_y = state[..., 1]\n",
        "\n",
        "        # distance to wall\n",
        "        wall_left = -30\n",
        "        wall_right = -20\n",
        "        wall_bottom = 0\n",
        "        wall_top = 100\n",
        "        dist_left = wall_left - state[..., 0]\n",
        "        dist_right = state[..., 0] - wall_right\n",
        "        dist_bottom = wall_bottom - state[..., 1]\n",
        "        dist_top = state[..., 1] - wall_top\n",
        "        dist_wall_x = torch.max(dist_left, dist_right)\n",
        "        dist_wall_y = torch.max(dist_bottom, dist_top)\n",
        "        dist_wall = torch.norm(torch.cat((torch.max(torch.tensor(0), dist_wall_x).unsqueeze(-1), torch.max(torch.tensor(0), dist_wall_y).unsqueeze(-1)), dim=-1), dim=-1) + torch.min(torch.tensor(0), torch.max(dist_wall_x, dist_wall_y))\n",
        "\n",
        "        return torch.min(dist_y, dist_wall)\n",
        "\n",
        "    def boundary_fn(self, state):\n",
        "        return torch.maximum(self.reach_fn(state), -self.avoid_fn(state))\n",
        "\n",
        "    def sample_target_state(self, num_samples):\n",
        "        target_state_range = self.state_test_range()\n",
        "        target_state_range[0] = [-20, 20] # y in [-20, 20]\n",
        "        target_state_range[1] = [10, 20]  # z in [10, 20]\n",
        "        target_state_range = torch.tensor(target_state_range)\n",
        "        return target_state_range[:, 0] + torch.rand(num_samples, self.state_dim)*(target_state_range[:, 1] - target_state_range[:, 0])\n",
        "\n",
        "    def cost_fn(self, state_traj):\n",
        "        # return min_t max{l(x(t)), max_k_up_to_t{-g(x(k))}}, where l(x) is reach_fn, g(x) is avoid_fn\n",
        "        reach_values = self.reach_fn(state_traj)\n",
        "        avoid_values = self.avoid_fn(state_traj)\n",
        "        return torch.min(torch.maximum(reach_values, torch.cummax(-avoid_values, dim=-1).values), dim=-1).values\n",
        "\n",
        "    def hamiltonian(self, state, dvds):\n",
        "        # Control Hamiltonian\n",
        "        u1_coeff = dvds[..., 3] * torch.cos(state[..., 2]) + dvds[..., 4] * torch.sin(state[..., 2]) + 0.3 * dvds[..., 5]\n",
        "        u2_coeff = -dvds[..., 3] * torch.sin(state[..., 2]) + dvds[..., 4] * torch.cos(state[..., 2])\n",
        "        ham_ctrl = -250.0 * torch.sqrt(u1_coeff * u1_coeff + u2_coeff * u2_coeff)\n",
        "        # Constant Hamiltonian\n",
        "        ham_constant = dvds[..., 0] * state[..., 3] + dvds[..., 1] * state[..., 4] + \\\n",
        "                      dvds[..., 2] * state[..., 5]  - dvds[..., 4] * 9.81\n",
        "        # Compute the Hamiltonian\n",
        "        ham_vehicle = ham_ctrl + ham_constant\n",
        "        return ham_vehicle\n",
        "\n",
        "    def optimal_control(self, state, dvds):\n",
        "        u1_coeff = dvds[..., 3] * torch.cos(state[..., 2]) + dvds[..., 4] * torch.sin(state[..., 2]) + 0.3 * dvds[..., 5]\n",
        "        u2_coeff = -dvds[..., 3] * torch.sin(state[..., 2]) + dvds[..., 4] * torch.cos(state[..., 2])\n",
        "        opt_angle = torch.atan2(u2_coeff, u1_coeff) + math.pi\n",
        "        return torch.cat((250.0 * torch.cos(opt_angle)[..., None], 250.0 * torch.sin(opt_angle)[..., None]), dim=-1)\n",
        "\n",
        "    def optimal_disturbance(self, state, dvds):\n",
        "        return 0\n",
        "\n",
        "    def plot_config(self):\n",
        "        return {\n",
        "            'state_slices': [-100, 120, 0, 150, -5, 0.0],\n",
        "            'state_labels': ['x', 'y', r'$\\theta$', r'$v_x$', r'$v_y$', r'$\\omega'],\n",
        "            'x_axis_idx': 0,\n",
        "            'y_axis_idx': 1,\n",
        "            'z_axis_idx': 4,\n",
        "        }\n",
        "\n",
        "class RocketLanding(Dynamics):\n",
        "    def __init__(self):\n",
        "        super().__init__(\n",
        "            loss_type='brt_hjivi', set_mode='reach',\n",
        "            state_dim=6, input_dim=8, control_dim=2, disturbance_dim=0,\n",
        "            state_mean=[0.0, 80.0, 0.0, 0.0, 0.0, 0.0],\n",
        "            state_var=[150.0, 70.0, 1.2*math.pi, 200.0, 200.0, 10.0],\n",
        "            value_mean=0.0,\n",
        "            value_var=1.0,\n",
        "            value_normto=0.02,\n",
        "            deepreach_model=\"exact\",\n",
        "        )\n",
        "\n",
        "    # convert model input to real coord\n",
        "    def input_to_coord(self, input):\n",
        "        input = input[..., :-1]\n",
        "        coord = input.clone()\n",
        "        coord[..., 1:] = (input[..., 1:] * self.state_var.to(device=input.device)) + self.state_mean.to(device=input.device)\n",
        "        return coord\n",
        "\n",
        "    # convert real coord to model input\n",
        "    def coord_to_input(self, coord):\n",
        "        input = coord.clone()\n",
        "        input[..., 1:] = (coord[..., 1:] - self.state_mean.to(device=coord.device)) / self.state_var.to(device=coord.device)\n",
        "        input = torch.cat((input, torch.zeros((*input.shape[:-1], 1), device=input.device)), dim=-1)\n",
        "        return input\n",
        "\n",
        "    # convert model io to real value\n",
        "    def io_to_value(self, input, output):\n",
        "        if self.deepreach_model==\"diff\":\n",
        "            return (output * self.value_var / self.value_normto) + self.boundary_fn(self.input_to_coord(input)[..., 1:])\n",
        "        else:\n",
        "            return (output * self.value_var / self.value_normto) + self.value_mean\n",
        "\n",
        "    # convert model io to real dv\n",
        "    def io_to_dv(self, input, output):\n",
        "        dodi = jacobian(output.unsqueeze(dim=-1), input)[0].squeeze(dim=-2)[..., :-1]\n",
        "\n",
        "        if self.deepreach_model==\"diff\":\n",
        "            dvdt = (self.value_var / self.value_normto) * dodi[..., 0]\n",
        "\n",
        "            dvds_term1 = (self.value_var / self.value_normto / self.state_var.to(device=dodi.device)) * dodi[..., 1:]\n",
        "            state = self.input_to_coord(input)[..., 1:]\n",
        "            dvds_term2 = jacobian(self.boundary_fn(state).unsqueeze(dim=-1), state)[0].squeeze(dim=-2)\n",
        "            dvds = dvds_term1 + dvds_term2\n",
        "\n",
        "        else:\n",
        "            dvdt = (self.value_var / self.value_normto) * dodi[..., 0]\n",
        "            dvds = (self.value_var / self.value_normto / self.state_var.to(device=dodi.device)) * dodi[..., 1:]\n",
        "\n",
        "        return torch.cat((dvdt.unsqueeze(dim=-1), dvds), dim=-1)\n",
        "\n",
        "\n",
        "    def state_test_range(self):\n",
        "        return [\n",
        "            [-150, 150],\n",
        "            [10, 150],\n",
        "            [-math.pi, math.pi],\n",
        "            [-200, 200],\n",
        "            [-200, 200],\n",
        "            [-10, 10],\n",
        "        ]\n",
        "\n",
        "    def equivalent_wrapped_state(self, state):\n",
        "        wrapped_state = torch.clone(state)\n",
        "        wrapped_state[..., 2] = (wrapped_state[..., 2] + math.pi) % (2*math.pi) - math.pi\n",
        "        return wrapped_state\n",
        "\n",
        "    # \\dot x = v_x\n",
        "    # \\dot y = v_y\n",
        "    # \\dot th = w\n",
        "    # \\dot v_x = u1 * cos(th) - u2 sin(th)\n",
        "    # \\dot v_y = u1 * sin(th) + u2 cos(th) - 9.81\n",
        "    # \\dot w = 0.3 * u1\n",
        "    def dsdt(self, state, control, disturbance):\n",
        "        dsdt = torch.zeros_like(state)\n",
        "        dsdt[..., 0] = state[..., 3]\n",
        "        dsdt[..., 1] = state[..., 4]\n",
        "        dsdt[..., 2] = state[..., 5]\n",
        "        dsdt[..., 3] = control[..., 0]*torch.cos(state[..., 2]) - control[..., 1]*torch.sin(state[..., 2])\n",
        "        dsdt[..., 4] = control[..., 0]*torch.sin(state[..., 2]) + control[..., 1]*torch.cos(state[..., 2]) - 9.81\n",
        "        dsdt[..., 5] = 0.3*control[..., 0]\n",
        "        return dsdt\n",
        "\n",
        "    def boundary_fn(self, state):\n",
        "        # Only target set in the yz direction\n",
        "        # Target set position in y direction\n",
        "        dist_y = torch.abs(state[..., 0]) - 20.0 #[-20, 150] boundary_fn range\n",
        "\n",
        "        # Target set position in z direction\n",
        "        dist_z = state[..., 1] - 20.0  #[-10, 130] boundary_fn range\n",
        "\n",
        "        # First compute the l(x) as you normally would but then normalize it later.\n",
        "        lx = torch.max(dist_y, dist_z)\n",
        "        return torch.where((lx >= 0), lx/150.0, lx/10.0)\n",
        "\n",
        "    def sample_target_state(self, num_samples):\n",
        "        target_state_range = self.state_test_range()\n",
        "        target_state_range[0] = [-20, 20] # y in [-20, 20]\n",
        "        target_state_range[1] = [10, 20]  # z in [10, 20]\n",
        "        target_state_range = torch.tensor(target_state_range)\n",
        "        return target_state_range[:, 0] + torch.rand(num_samples, self.state_dim)*(target_state_range[:, 1] - target_state_range[:, 0])\n",
        "\n",
        "    def cost_fn(self, state_traj):\n",
        "        return torch.min(self.boundary_fn(state_traj), dim=-1).values\n",
        "\n",
        "    def hamiltonian(self, state, dvds):\n",
        "        # Control Hamiltonian\n",
        "        u1_coeff = dvds[..., 3] * torch.cos(state[..., 2]) + dvds[..., 4] * torch.sin(state[..., 2]) + 0.3 * dvds[..., 5]\n",
        "        u2_coeff = -dvds[..., 3] * torch.sin(state[..., 2]) + dvds[..., 4] * torch.cos(state[..., 2])\n",
        "        ham_ctrl = -250.0 * torch.sqrt(u1_coeff * u1_coeff + u2_coeff * u2_coeff)\n",
        "        # Constant Hamiltonian\n",
        "        ham_constant = dvds[..., 0] * state[..., 3] + dvds[..., 1] * state[..., 4] + \\\n",
        "                      dvds[..., 2] * state[..., 5]  - dvds[..., 4] * 9.81\n",
        "        # Compute the Hamiltonian\n",
        "        ham_vehicle = ham_ctrl + ham_constant\n",
        "        return ham_vehicle\n",
        "\n",
        "    def optimal_control(self, state, dvds):\n",
        "        u1_coeff = dvds[..., 3] * torch.cos(state[..., 2]) + dvds[..., 4] * torch.sin(state[..., 2]) + 0.3 * dvds[..., 5]\n",
        "        u2_coeff = -dvds[..., 3] * torch.sin(state[..., 2]) + dvds[..., 4] * torch.cos(state[..., 2])\n",
        "        opt_angle = torch.atan2(u2_coeff, u1_coeff) + math.pi\n",
        "        return torch.cat((250.0 * torch.cos(opt_angle)[..., None], 250.0 * torch.sin(opt_angle)[..., None]), dim=-1)\n",
        "\n",
        "    def optimal_disturbance(self, state, dvds):\n",
        "        return 0\n",
        "\n",
        "    def plot_config(self):\n",
        "        return {\n",
        "            'state_slices': [-100, 120, 0, 150, -5, 0.0],\n",
        "            'state_labels': ['x', 'y', r'$\\theta$', r'$v_x$', r'$v_y$', r'$\\omega'],\n",
        "            'x_axis_idx': 0,\n",
        "            'y_axis_idx': 1,\n",
        "            'z_axis_idx': 4,\n",
        "        }\n",
        "\n",
        "class Quadrotor(Dynamics):\n",
        "    def __init__(self, collisionR:float, thrust_max:float, set_mode:str):\n",
        "        self.thrust_max = thrust_max\n",
        "        self.m=1 #mass\n",
        "        self.arm_l=0.17\n",
        "        self.CT=1\n",
        "        self.CM=0.016\n",
        "        self.Gz=-9.8\n",
        "\n",
        "        self.thrust_max = thrust_max\n",
        "        self.collisionR = collisionR\n",
        "\n",
        "\n",
        "        super().__init__(\n",
        "            loss_type='brt_hjivi', set_mode=set_mode,\n",
        "            state_dim=13, input_dim=14, control_dim=4, disturbance_dim=0,\n",
        "            state_mean=[0 for i in range(13)],\n",
        "            state_var=[1.5, 1.5, 1.5, 1, 1, 1, 1, 10, 10 ,10 ,10 ,10 ,10],\n",
        "            value_mean=(math.sqrt(1.5**2+1.5**2+1.5**2)-2*self.collisionR)/2,\n",
        "            value_var=math.sqrt(1.5**2+1.5**2+1.5**2),\n",
        "            value_normto=0.02,\n",
        "            deepreach_model=\"exact\"\n",
        "        )\n",
        "\n",
        "    def state_test_range(self):\n",
        "        return [\n",
        "            [-1.5, 1.5],\n",
        "            [-1.5, 1.5],\n",
        "            [-1.5, 1.5],\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-10, 10],\n",
        "            [-10, 10],\n",
        "            [-10, 10],\n",
        "            [-10, 10],\n",
        "            [-10, 10],\n",
        "            [-10, 10],\n",
        "        ]\n",
        "\n",
        "    def equivalent_wrapped_state(self, state):\n",
        "        wrapped_state = torch.clone(state)\n",
        "        return wrapped_state\n",
        "\n",
        "    # Dubins3D dynamics\n",
        "    # \\dot x    = v \\cos \\theta\n",
        "    # \\dot y    = v \\sin \\theta\n",
        "    # \\dot \\theta = u\n",
        "    def dsdt(self, state, control, disturbance):\n",
        "        qw = state[..., 3] * 1.0\n",
        "        qx = state[..., 4] * 1.0\n",
        "        qy = state[..., 5] * 1.0\n",
        "        qz = state[..., 6] * 1.0\n",
        "        vx = state[..., 7] * 1.0\n",
        "        vy = state[..., 8] * 1.0\n",
        "        vz = state[..., 9] * 1.0\n",
        "        wx = state[..., 10] * 1.0\n",
        "        wy = state[..., 11] * 1.0\n",
        "        wz = state[..., 12] * 1.0\n",
        "        u1 = control[...,0] * 1.0\n",
        "        u2 = control[...,1] * 1.0\n",
        "        u3 = control[...,2] * 1.0\n",
        "        u4 = control[...,3] * 1.0\n",
        "\n",
        "\n",
        "        dsdt = torch.zeros_like(state)\n",
        "        dsdt[..., 0] = vx\n",
        "        dsdt[..., 1] = vy\n",
        "        dsdt[..., 2] = vz\n",
        "        dsdt[..., 3] = -(wx*qx+wy*qy+wz*qz)/2.0\n",
        "        dsdt[..., 4] =  (wx*qw+wz*qy-wy*qz)/2.0\n",
        "        dsdt[..., 5] = (wy*qw-wz*qx+wx*qz)/2.0\n",
        "        dsdt[..., 6] = (wz*qw+wy*qx-wx*qy)/2.0\n",
        "        dsdt[..., 7] = 2*(qw*qy+qx*qz)*self.CT/self.m*(u1+u2+u3+u4)\n",
        "        dsdt[..., 8] =2*(-qw*qx+qy*qz)*self.CT/self.m*(u1+u2+u3+u4)\n",
        "        dsdt[..., 9] =self.Gz+(1-2*torch.pow(qx,2)-2*torch.pow(qy,2))*self.CT/self.m*(u1+u2+u3+u4)\n",
        "        dsdt[..., 10] = 4*math.sqrt(2)*self.CT*(u1-u2-u3+u4)/(3*self.arm_l*self.m)-5*wy*wz/9.0\n",
        "        dsdt[..., 11] = 4*math.sqrt(2)*self.CT*(-u1-u2+u3+u4)/(3*self.arm_l*self.m)+5*wx*wz/9.0\n",
        "        dsdt[..., 12] =12*self.CT*self.CM/(7*self.arm_l**2*self.m)*(u1-u2+u3-u4)\n",
        "        return dsdt\n",
        "\n",
        "    def boundary_fn(self, state):\n",
        "        return torch.norm(state[..., :3], dim=-1) - self.collisionR\n",
        "\n",
        "    def sample_target_state(self, num_samples):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def cost_fn(self, state_traj):\n",
        "        return torch.min(self.boundary_fn(state_traj), dim=-1).values\n",
        "\n",
        "    def hamiltonian(self, state, dvds):\n",
        "        if self.set_mode == 'reach':\n",
        "            raise NotImplementedError\n",
        "\n",
        "        elif self.set_mode == 'avoid':\n",
        "            qw = state[..., 3] * 1.0\n",
        "            qx = state[..., 4] * 1.0\n",
        "            qy = state[..., 5] * 1.0\n",
        "            qz = state[..., 6] * 1.0\n",
        "            vx = state[..., 7] * 1.0\n",
        "            vy = state[..., 8] * 1.0\n",
        "            vz = state[..., 9] * 1.0\n",
        "            wx = state[..., 10] * 1.0\n",
        "            wy = state[..., 11] * 1.0\n",
        "            wz = state[..., 12] * 1.0\n",
        "\n",
        "\n",
        "            C1=2*(qw*qy+qx*qz)*self.CT/self.m\n",
        "            C2=2*(-qw*qx+qy*qz)*self.CT/self.m\n",
        "            C3=(1-2*torch.pow(qx,2)-2*torch.pow(qy,2))*self.CT/self.m\n",
        "            C4=4*math.sqrt(2)*self.CT/(3*self.arm_l*self.m)\n",
        "            C5=4*math.sqrt(2)*self.CT/(3*self.arm_l*self.m)\n",
        "            C6=12*self.CT*self.CM/(7*self.arm_l**2*self.m)\n",
        "\n",
        "            # Compute the hamiltonian for the quadrotor\n",
        "            ham= dvds[..., 0]*vx + dvds[..., 1]*vy+ dvds[..., 2]*vz\n",
        "            ham+= -dvds[..., 3]* (wx*qx+wy*qy+wz*qz)/2.0\n",
        "            ham+= dvds[..., 4]*(wx*qw+wz*qy-wy*qz)/2.0\n",
        "            ham+= dvds[..., 5]*(wy*qw-wz*qx+wx*qz)/2.0\n",
        "            ham+= dvds[..., 6]*(wz*qw+wy*qx-wx*qy)/2.0\n",
        "            ham+= dvds[..., 9]*-9.8\n",
        "            ham+= -dvds[..., 10]*5*wy*wz/9.0+ dvds[..., 11]*5*wx*wz/9.0\n",
        "\n",
        "            ham+=torch.abs(dvds[..., 7]*C1+dvds[..., 8]*C2+dvds[..., 9]*C3\n",
        "                +dvds[..., 10]*C4-dvds[..., 11]*C5+dvds[..., 12]*C6)*self.thrust_max\n",
        "\n",
        "            ham+=torch.abs(dvds[..., 7]*C1+dvds[..., 8]*C2+dvds[..., 9]*C3\n",
        "                -dvds[..., 10]*C4-dvds[..., 11]*C5-dvds[..., 12]*C6)*self.thrust_max\n",
        "\n",
        "            ham+=torch.abs(dvds[..., 7]*C1+dvds[..., 8]*C2+dvds[..., 9]*C3\n",
        "                -dvds[..., 10]*C4+dvds[..., 11]*C5+dvds[..., 12]*C6)*self.thrust_max\n",
        "\n",
        "            ham+=torch.abs(dvds[..., 7]*C1+dvds[..., 8]*C2+dvds[..., 9]*C3\n",
        "                +dvds[..., 10]*C4+dvds[..., 11]*C5-dvds[..., 12]*C6)*self.thrust_max\n",
        "\n",
        "            return ham\n",
        "\n",
        "    def optimal_control(self, state, dvds):\n",
        "        if self.set_mode == 'reach':\n",
        "            raise NotImplementedError\n",
        "        elif self.set_mode == 'avoid':\n",
        "            qw = state[..., 3] * 1.0\n",
        "            qx = state[..., 4] * 1.0\n",
        "            qy = state[..., 5] * 1.0\n",
        "            qz = state[..., 6] * 1.0\n",
        "\n",
        "\n",
        "            C1=2*(qw*qy+qx*qz)*self.CT/self.m\n",
        "            C2=2*(-qw*qx+qy*qz)*self.CT/self.m\n",
        "            C3=(1-2*torch.pow(qx,2)-2*torch.pow(qy,2))*self.CT/self.m\n",
        "            C4=4*math.sqrt(2)*self.CT/(3*self.arm_l*self.m)\n",
        "            C5=4*math.sqrt(2)*self.CT/(3*self.arm_l*self.m)\n",
        "            C6=12*self.CT*self.CM/(7*self.arm_l**2*self.m)\n",
        "\n",
        "\n",
        "            u1=self.thrust_max*torch.sign(dvds[..., 7]*C1+dvds[..., 8]*C2+dvds[..., 9]*C3\n",
        "                +dvds[..., 10]*C4-dvds[..., 11]*C5+dvds[..., 12]*C6)\n",
        "            u2=self.thrust_max*torch.sign(dvds[..., 7]*C1+dvds[..., 8]*C2+dvds[..., 9]*C3\n",
        "                -dvds[..., 10]*C4-dvds[..., 11]*C5-dvds[..., 12]*C6)\n",
        "            u3=self.thrust_max*torch.sign(dvds[..., 7]*C1+dvds[..., 8]*C2+dvds[..., 9]*C3\n",
        "                -dvds[..., 10]*C4+dvds[..., 11]*C5+dvds[..., 12]*C6)\n",
        "            u4=self.thrust_max*torch.sign(dvds[..., 7]*C1+dvds[..., 8]*C2+dvds[..., 9]*C3\n",
        "                +dvds[..., 10]*C4+dvds[..., 11]*C5-dvds[..., 12]*C6)\n",
        "\n",
        "        return torch.cat((u1[..., None], u2[..., None], u3[..., None], u4[..., None]), dim=-1)\n",
        "\n",
        "    def optimal_disturbance(self, state, dvds):\n",
        "        return 0\n",
        "\n",
        "    def plot_config(self):\n",
        "        return {\n",
        "            'state_slices': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "            'state_labels': ['x', 'y', 'z', 'qw', 'qx', 'qy', 'qz', 'vx', 'vy', 'vz', 'wx', 'wy', 'wz'],\n",
        "            'x_axis_idx': 0,\n",
        "            'y_axis_idx': 2,\n",
        "            'z_axis_idx': 7,\n",
        "        }\n",
        "\n",
        "class MultiVehicleCollision(Dynamics):\n",
        "    def __init__(self):\n",
        "        self.angle_alpha_factor = 1.2\n",
        "        self.velocity = 0.6\n",
        "        self.omega_max = 1.1\n",
        "        self.collisionR = 0.25\n",
        "        super().__init__(\n",
        "            loss_type='brt_hjivi', set_mode='avoid',\n",
        "            state_dim=9, input_dim=10, control_dim=3, disturbance_dim=0,\n",
        "            state_mean=[\n",
        "                0, 0,\n",
        "                0, 0,\n",
        "                0, 0,\n",
        "                0, 0, 0,\n",
        "            ],\n",
        "            state_var=[\n",
        "                1, 1,\n",
        "                1, 1,\n",
        "                1, 1,\n",
        "                self.angle_alpha_factor*math.pi, self.angle_alpha_factor*math.pi, self.angle_alpha_factor*math.pi,\n",
        "            ],\n",
        "            value_mean=0.25,\n",
        "            value_var=0.5,\n",
        "            value_normto=0.02,\n",
        "            deepreach_model=\"exact\"\n",
        "        )\n",
        "\n",
        "    def state_test_range(self):\n",
        "        return [\n",
        "            [-1, 1], [-1, 1],\n",
        "            [-1, 1], [-1, 1],\n",
        "            [-1, 1], [-1, 1],\n",
        "            [-math.pi, math.pi], [-math.pi, math.pi], [-math.pi, math.pi],\n",
        "        ]\n",
        "\n",
        "    def equivalent_wrapped_state(self, state):\n",
        "        wrapped_state = torch.clone(state)\n",
        "        wrapped_state[..., 6] = (wrapped_state[..., 6] + math.pi) % (2*math.pi) - math.pi\n",
        "        wrapped_state[..., 7] = (wrapped_state[..., 7] + math.pi) % (2*math.pi) - math.pi\n",
        "        wrapped_state[..., 8] = (wrapped_state[..., 8] + math.pi) % (2*math.pi) - math.pi\n",
        "        return wrapped_state\n",
        "\n",
        "    # dynamics (per car)\n",
        "    # \\dot x    = v \\cos \\theta\n",
        "    # \\dot y    = v \\sin \\theta\n",
        "    # \\dot \\theta = u\n",
        "    def dsdt(self, state, control, disturbance):\n",
        "        dsdt = torch.zeros_like(state)\n",
        "        dsdt[..., 0] = self.velocity*torch.cos(state[..., 6])\n",
        "        dsdt[..., 1] = self.velocity*torch.sin(state[..., 6])\n",
        "        dsdt[..., 2] = self.velocity*torch.cos(state[..., 7])\n",
        "        dsdt[..., 3] = self.velocity*torch.sin(state[..., 7])\n",
        "        dsdt[..., 4] = self.velocity*torch.cos(state[..., 8])\n",
        "        dsdt[..., 5] = self.velocity*torch.sin(state[..., 8])\n",
        "        dsdt[..., 6] = control[..., 0]\n",
        "        dsdt[..., 7] = control[..., 1]\n",
        "        dsdt[..., 8] = control[..., 2]\n",
        "        return dsdt\n",
        "\n",
        "    def boundary_fn(self, state):\n",
        "        boundary_values = torch.norm(state[..., 0:2] - state[..., 2:4], dim=-1) - self.collisionR\n",
        "        for i in range(1, 2):\n",
        "            boundary_values_current = torch.norm(state[..., 0:2] - state[..., 2*(i+1):2*(i+1)+2], dim=-1) - self.collisionR\n",
        "            boundary_values = torch.min(boundary_values, boundary_values_current)\n",
        "        # Collision cost between the evaders themselves\n",
        "        for i in range(2):\n",
        "            for j in range(i+1, 2):\n",
        "                evader1_coords_index = (i+1)*2\n",
        "                evader2_coords_index = (j+1)*2\n",
        "                boundary_values_current = torch.norm(state[..., evader1_coords_index:evader1_coords_index+2] - state[..., evader2_coords_index:evader2_coords_index+2], dim=-1) - self.collisionR\n",
        "                boundary_values = torch.min(boundary_values, boundary_values_current)\n",
        "        return boundary_values\n",
        "\n",
        "    def sample_target_state(self, num_samples):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def cost_fn(self, state_traj):\n",
        "        return torch.min(self.boundary_fn(state_traj), dim=-1).values\n",
        "\n",
        "    def hamiltonian(self, state, dvds):\n",
        "        # Compute the hamiltonian for the ego vehicle\n",
        "        ham = self.velocity*(torch.cos(state[..., 6]) * dvds[..., 0] + torch.sin(state[..., 6]) * dvds[..., 1]) + self.omega_max * torch.abs(dvds[..., 6])\n",
        "        # Hamiltonian effect due to other vehicles\n",
        "        ham += self.velocity*(torch.cos(state[..., 7]) * dvds[..., 2] + torch.sin(state[..., 7]) * dvds[..., 3]) + self.omega_max * torch.abs(dvds[..., 7])\n",
        "        ham += self.velocity*(torch.cos(state[..., 8]) * dvds[..., 4] + torch.sin(state[..., 8]) * dvds[..., 5]) + self.omega_max * torch.abs(dvds[..., 8])\n",
        "        return ham\n",
        "\n",
        "    def optimal_control(self, state, dvds):\n",
        "        return self.omega_max*torch.sign(dvds[..., [6, 7, 8]])\n",
        "\n",
        "    def optimal_disturbance(self, state, dvds):\n",
        "        return 0\n",
        "\n",
        "    def plot_config(self):\n",
        "        return {\n",
        "            'state_slices': [\n",
        "                0, 0,\n",
        "                -0.4, 0,\n",
        "                0.4, 0,\n",
        "                math.pi/2, math.pi/4, 3*math.pi/4,\n",
        "            ],\n",
        "            'state_labels': [\n",
        "                r'$x_1$', r'$y_1$',\n",
        "                r'$x_2$', r'$y_2$',\n",
        "                r'$x_3$', r'$y_3$',\n",
        "                r'$\\theta_1$', r'$\\theta_2$', r'$\\theta_3$',\n",
        "            ],\n",
        "            'x_axis_idx': 0,\n",
        "            'y_axis_idx': 1,\n",
        "            'z_axis_idx': 6,\n",
        "        }\n",
        "\n",
        "###############################################################\n",
        "# Custom Dynamics for 2d Planar Robot\n",
        "###############################################################\n",
        "class PlanarRobot2D(Dynamics):\n",
        "    def __init__(\n",
        "        self,\n",
        "        goalR: float,\n",
        "        velocity: float,\n",
        "        set_mode: str = 'avoid',\n",
        "        freeze_model: bool = False\n",
        "    ):\n",
        "        \"\"\"\n",
        "        2D constant-speed robot dynamics for reach/avoid problems.\n",
        "\n",
        "        Args:\n",
        "            goalR: Radius of the obstacle (avoid) or goal (reach) circle.\n",
        "            velocity: Constant forward speed (m/s).\n",
        "            set_mode: 'reach' or 'avoid'.\n",
        "            freeze_model: If True, dsdt/hamiltonian will raise NotImplementedError.\n",
        "        \"\"\"\n",
        "        self.goalR = goalR\n",
        "        self.velocity = velocity\n",
        "        self.freeze_model = freeze_model\n",
        "\n",
        "        super().__init__(\n",
        "            loss_type='brt_hjivi',\n",
        "            set_mode=set_mode,\n",
        "            state_dim=2, # [p_x, p_y]\n",
        "            input_dim=3, # [p_x, p_y, t]\n",
        "            control_dim=1, # [theta]\n",
        "            disturbance_dim=0,\n",
        "\n",
        "            # Normalize x,y from [-2,2] to [-1,1]\n",
        "            state_mean=[0.0, 0.0],\n",
        "            state_var=[2.0, 2.0],\n",
        "\n",
        "            value_mean=0.0, # value_mean is not used in 'exact' mode\n",
        "            value_var=0.5,\n",
        "            value_normto=0.02,\n",
        "            deepreach_model=\"exact\",\n",
        "        )\n",
        "\n",
        "    def state_test_range(self):\n",
        "        return [\n",
        "            [-2.0, 2.0], # p_x\n",
        "            [-2.0, 2.0], # p_y\n",
        "        ]\n",
        "\n",
        "    def equivalent_wrapped_state(self, state):\n",
        "        return state\n",
        "\n",
        "    def dsdt(self, state, control, disturbance):\n",
        "        # \\dot p_x = v \\cos \\theta\n",
        "        # \\dot p_y = v \\sin \\theta\n",
        "        if self.freeze_model:\n",
        "            raise NotImplementedError\n",
        "        theta = control[..., 0]\n",
        "        ds = torch.zeros_like(state)\n",
        "        ds[..., 0] = self.velocity * torch.cos(theta)\n",
        "        ds[..., 1] = self.velocity * torch.sin(theta)\n",
        "        return ds\n",
        "\n",
        "    def boundary_fn(self, state):\n",
        "        return torch.norm(state, dim=-1) - self.goalR\n",
        "\n",
        "    def sample_target_state(self, num_samples):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def cost_fn(self, state_traj):\n",
        "        raise NotImplementedError\n",
        "        # return torch.min(self.boundary_fn(state_traj), dim=-1).values\n",
        "\n",
        "    def hamiltonian(self, state, dvds):\n",
        "        if self.freeze_model:\n",
        "            raise NotImplementedError\n",
        "        norm = torch.sqrt(dvds[..., 0]**2 + dvds[..., 1]**2)\n",
        "        if self.set_mode == 'reach':\n",
        "            return  - self.velocity * norm\n",
        "        elif self.set_mode == 'avoid':\n",
        "            return  self.velocity * norm\n",
        "\n",
        "    def optimal_control(self, state, dvds):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def optimal_disturbance(self, state, dvds):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def plot_config(self):\n",
        "        return {\n",
        "            \"state_slices\": [0, 0],\n",
        "            \"state_labels\": [\"p_x\", \"p_y\"],\n",
        "            \"x_axis_idx\": 0,\n",
        "            \"y_axis_idx\": 1,\n",
        "            \"z_axis_idx\": -1,\n",
        "        }\n",
        "\n",
        "###############################################################\n"
      ],
      "metadata": {
        "id": "8dauKrtlDfXO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Experiments Code"
      ],
      "metadata": {
        "id": "cZYSaKilD_U3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Experiment(ABC):\n",
        "    def __init__(self, model, dataset, experiment_dir, use_wandb):\n",
        "        self.model = model\n",
        "        self.dataset = dataset\n",
        "        self.experiment_dir = experiment_dir\n",
        "        self.use_wandb = use_wandb\n",
        "\n",
        "    @abstractmethod\n",
        "    def init_special(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def _load_checkpoint(self, epoch):\n",
        "        if epoch == -1:\n",
        "            model_path = os.path.join(self.experiment_dir, 'training', 'checkpoints', 'model_final.pth')\n",
        "            self.model.load_state_dict(torch.load(model_path))\n",
        "        else:\n",
        "            model_path = os.path.join(self.experiment_dir, 'training', 'checkpoints', 'model_epoch_%04d.pth' % epoch)\n",
        "            self.model.load_state_dict(torch.load(model_path)['model'])\n",
        "\n",
        "    def validate(self, device, epoch, save_path, x_resolution, y_resolution, z_resolution, time_resolution):\n",
        "        was_training = self.model.training\n",
        "        self.model.eval()\n",
        "        self.model.requires_grad_(False)\n",
        "\n",
        "        plot_config = self.dataset.dynamics.plot_config()\n",
        "        state_test_range = self.dataset.dynamics.state_test_range()\n",
        "\n",
        "        x_idx = plot_config['x_axis_idx']\n",
        "        y_idx = plot_config['y_axis_idx']\n",
        "        z_idx = plot_config.get('z_axis_idx', -1)\n",
        "\n",
        "        x_min, x_max = state_test_range[x_idx]\n",
        "        y_min, y_max = state_test_range[y_idx]\n",
        "        xs = torch.linspace(x_min, x_max, x_resolution)\n",
        "        ys = torch.linspace(y_min, y_max, y_resolution)\n",
        "        xys = torch.cartesian_prod(xs, ys)\n",
        "\n",
        "        # Determine z slices: if z_idx == -1, use a single dummy slice\n",
        "        if z_idx == -1:\n",
        "            zs = torch.tensor([0.0], dtype=torch.float32)\n",
        "        else:\n",
        "            z_min, z_max = state_test_range[z_idx]\n",
        "            zs = torch.linspace(z_min, z_max, z_resolution)\n",
        "\n",
        "        times = torch.linspace(0, self.dataset.tMax, time_resolution)\n",
        "        fig = plt.figure(figsize=(5*len(times), 5*len(zs)))\n",
        "\n",
        "        # Loop over time and z-slices\n",
        "        for i, t in enumerate(times):\n",
        "            for j, z_val in enumerate(zs):\n",
        "                coords = torch.zeros(x_resolution*y_resolution, self.dataset.dynamics.state_dim + 1)\n",
        "                coords[:, 0] = t\n",
        "                coords[:, 1:] = torch.tensor(plot_config['state_slices'])\n",
        "\n",
        "                coords[:, 1 + x_idx] = xys[:, 0]\n",
        "                coords[:, 1 + y_idx] = xys[:, 1]\n",
        "\n",
        "                # Only fill z if it's a real 3D axis\n",
        "                if z_idx != -1:\n",
        "                    coords[:, 1 + z_idx] = z_val\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    inp = self.dataset.dynamics.coord_to_input(coords.to(device))\n",
        "                    results = self.model({'coords': inp})\n",
        "                    values = self.dataset.dynamics.io_to_value(results['model_in'].detach(), results['model_out'].squeeze(dim=-1).detach())\n",
        "\n",
        "                ax = fig.add_subplot(len(times), len(zs), (j+1) + i*len(zs))\n",
        "                title_z = (f\", {plot_config['state_labels'][z_idx]} = {z_val:.2f}\"\n",
        "                        if z_idx != -1 else \"\")\n",
        "                ax.set_title(f\"t = {t:.2f}{title_z}\")\n",
        "\n",
        "                img = values.cpu().numpy().reshape(x_resolution, y_resolution).T\n",
        "                # binary decision boundary: <=0 in red/blue\n",
        "                mask = (img <= 0).astype(float)\n",
        "                s = ax.imshow(mask, cmap='bwr', origin='lower', extent=(x_min, x_max, y_min, y_max))\n",
        "                fig.colorbar(s, ax=ax)\n",
        "\n",
        "        fig.savefig(save_path)\n",
        "        if self.use_wandb:\n",
        "            wandb.log({\n",
        "                'step': epoch,\n",
        "                'val_plot': wandb.Image(fig),\n",
        "            })\n",
        "        plt.close()\n",
        "\n",
        "        if was_training:\n",
        "            self.model.train()\n",
        "            self.model.requires_grad_(True)\n",
        "\n",
        "    def train(\n",
        "            self, device, batch_size, epochs, lr,\n",
        "            steps_til_summary, epochs_til_checkpoint,\n",
        "            loss_fn, clip_grad, use_lbfgs, adjust_relative_grads,\n",
        "            val_x_resolution, val_y_resolution, val_z_resolution, val_time_resolution,\n",
        "            use_CSL, CSL_lr, CSL_dt, epochs_til_CSL, num_CSL_samples, CSL_loss_frac_cutoff, max_CSL_epochs, CSL_loss_weight, CSL_batch_size,\n",
        "        ):\n",
        "        was_eval = not self.model.training\n",
        "        self.model.train()\n",
        "        self.model.requires_grad_(True)\n",
        "\n",
        "        train_dataloader = DataLoader(self.dataset, shuffle=True, batch_size=batch_size, pin_memory=True, num_workers=0)\n",
        "\n",
        "        optim = torch.optim.Adam(lr=lr, params=self.model.parameters())\n",
        "\n",
        "        # copy settings from Raissi et al. (2019) and here\n",
        "        # https://github.com/maziarraissi/PINNs\n",
        "        if use_lbfgs:\n",
        "            optim = torch.optim.LBFGS(lr=lr, params=self.model.parameters(), max_iter=50000, max_eval=50000,\n",
        "                                    history_size=50, line_search_fn='strong_wolfe')\n",
        "\n",
        "        training_dir = os.path.join(self.experiment_dir, 'training')\n",
        "\n",
        "        summaries_dir = os.path.join(training_dir, 'summaries')\n",
        "        if not os.path.exists(summaries_dir):\n",
        "            os.makedirs(summaries_dir)\n",
        "\n",
        "        checkpoints_dir = os.path.join(training_dir, 'checkpoints')\n",
        "        if not os.path.exists(checkpoints_dir):\n",
        "            os.makedirs(checkpoints_dir)\n",
        "\n",
        "        writer = SummaryWriter(summaries_dir)\n",
        "\n",
        "        total_steps = 0\n",
        "\n",
        "        if adjust_relative_grads:\n",
        "            new_weight = 1\n",
        "\n",
        "        with tqdm(total=len(train_dataloader) * epochs) as pbar:\n",
        "            train_losses = []\n",
        "            last_CSL_epoch = -1\n",
        "            for epoch in range(0, epochs):\n",
        "                if self.dataset.pretrain: # skip CSL\n",
        "                    last_CSL_epoch = epoch\n",
        "                time_interval_length = (self.dataset.counter/self.dataset.counter_end)*(self.dataset.tMax-self.dataset.tMin)\n",
        "                CSL_tMax = self.dataset.tMin + int(time_interval_length/CSL_dt)*CSL_dt\n",
        "\n",
        "                # self-supervised learning\n",
        "                for step, (model_input, gt) in enumerate(train_dataloader):\n",
        "                    start_time = time.time()\n",
        "\n",
        "                    model_input = {key: value.to(device) for key, value in model_input.items()}\n",
        "                    gt = {key: value.to(device) for key, value in gt.items()}\n",
        "\n",
        "                    model_results = self.model({'coords': model_input['model_coords']})\n",
        "\n",
        "                    states = self.dataset.dynamics.input_to_coord(model_results['model_in'].detach())[..., 1:]\n",
        "                    values = self.dataset.dynamics.io_to_value(model_results['model_in'].detach(), model_results['model_out'].squeeze(dim=-1))\n",
        "                    dvs = self.dataset.dynamics.io_to_dv(model_results['model_in'], model_results['model_out'].squeeze(dim=-1))\n",
        "                    boundary_values = gt['boundary_values']\n",
        "                    if self.dataset.dynamics.loss_type == 'brat_hjivi':\n",
        "                        reach_values = gt['reach_values']\n",
        "                        avoid_values = gt['avoid_values']\n",
        "                    dirichlet_masks = gt['dirichlet_masks']\n",
        "\n",
        "                    if self.dataset.dynamics.loss_type == 'brt_hjivi':\n",
        "                        losses = loss_fn(states, values, dvs[..., 0], dvs[..., 1:], boundary_values, dirichlet_masks, model_results['model_out'])\n",
        "                    elif self.dataset.dynamics.loss_type == 'brat_hjivi':\n",
        "                        losses = loss_fn(states, values, dvs[..., 0], dvs[..., 1:], boundary_values, reach_values, avoid_values, dirichlet_masks, model_results['model_out'])\n",
        "                    else:\n",
        "                        raise NotImplementedError\n",
        "\n",
        "                    if use_lbfgs:\n",
        "                        def closure():\n",
        "                            optim.zero_grad()\n",
        "                            train_loss = 0.\n",
        "                            for loss_name, loss in losses.items():\n",
        "                                train_loss += loss.mean()\n",
        "                            train_loss.backward()\n",
        "                            return train_loss\n",
        "                        optim.step(closure)\n",
        "\n",
        "                    # Adjust the relative magnitude of the losses if required\n",
        "                    if self.dataset.dynamics.deepreach_model in ['vanilla', 'diff'] and adjust_relative_grads:\n",
        "                        if losses['diff_constraint_hom'] > 0.01:\n",
        "                            params = OrderedDict(self.model.named_parameters())\n",
        "                            # Gradients with respect to the PDE loss\n",
        "                            optim.zero_grad()\n",
        "                            losses['diff_constraint_hom'].backward(retain_graph=True)\n",
        "                            grads_PDE = []\n",
        "                            for key, param in params.items():\n",
        "                                grads_PDE.append(param.grad.view(-1))\n",
        "                            grads_PDE = torch.cat(grads_PDE)\n",
        "\n",
        "                            # Gradients with respect to the boundary loss\n",
        "                            optim.zero_grad()\n",
        "                            losses['dirichlet'].backward(retain_graph=True)\n",
        "                            grads_dirichlet = []\n",
        "                            for key, param in params.items():\n",
        "                                grads_dirichlet.append(param.grad.view(-1))\n",
        "                            grads_dirichlet = torch.cat(grads_dirichlet)\n",
        "\n",
        "                            # # Plot the gradients\n",
        "                            # import seaborn as sns\n",
        "                            # import matplotlib.pyplot as plt\n",
        "                            # fig = plt.figure(figsize=(5, 5))\n",
        "                            # ax = fig.add_subplot(1, 1, 1)\n",
        "                            # ax.set_yscale('symlog')\n",
        "                            # sns.distplot(grads_PDE.cpu().numpy(), hist=False, kde_kws={\"shade\": False}, norm_hist=True)\n",
        "                            # sns.distplot(grads_dirichlet.cpu().numpy(), hist=False, kde_kws={\"shade\": False}, norm_hist=True)\n",
        "                            # fig.savefig('gradient_visualization.png')\n",
        "\n",
        "                            # fig = plt.figure(figsize=(5, 5))\n",
        "                            # ax = fig.add_subplot(1, 1, 1)\n",
        "                            # ax.set_yscale('symlog')\n",
        "                            # grads_dirichlet_normalized = grads_dirichlet * torch.mean(torch.abs(grads_PDE))/torch.mean(torch.abs(grads_dirichlet))\n",
        "                            # sns.distplot(grads_PDE.cpu().numpy(), hist=False, kde_kws={\"shade\": False}, norm_hist=True)\n",
        "                            # sns.distplot(grads_dirichlet_normalized.cpu().numpy(), hist=False, kde_kws={\"shade\": False}, norm_hist=True)\n",
        "                            # ax.set_xlim([-1000.0, 1000.0])\n",
        "                            # fig.savefig('gradient_visualization_normalized.png')\n",
        "\n",
        "                            # Set the new weight according to the paper\n",
        "                            # num = torch.max(torch.abs(grads_PDE))\n",
        "                            num = torch.mean(torch.abs(grads_PDE))\n",
        "                            den = torch.mean(torch.abs(grads_dirichlet))\n",
        "                            new_weight = 0.9*new_weight + 0.1*num/den\n",
        "                            losses['dirichlet'] = new_weight*losses['dirichlet']\n",
        "                        writer.add_scalar('weight_scaling', new_weight, total_steps)\n",
        "\n",
        "                    # import ipdb; ipdb.set_trace()\n",
        "\n",
        "                    train_loss = 0.\n",
        "                    for loss_name, loss in losses.items():\n",
        "                        single_loss = loss.mean()\n",
        "\n",
        "                        if loss_name == 'dirichlet':\n",
        "                            writer.add_scalar(loss_name, single_loss/new_weight, total_steps)\n",
        "                        else:\n",
        "                            writer.add_scalar(loss_name, single_loss, total_steps)\n",
        "                        train_loss += single_loss\n",
        "\n",
        "                    train_losses.append(train_loss.item())\n",
        "                    writer.add_scalar(\"total_train_loss\", train_loss, total_steps)\n",
        "\n",
        "                    if not total_steps % steps_til_summary:\n",
        "                        torch.save(self.model.state_dict(),\n",
        "                                os.path.join(checkpoints_dir, 'model_current.pth'))\n",
        "                        # summary_fn(model, model_input, gt, model_output, writer, total_steps)\n",
        "\n",
        "                    if not use_lbfgs:\n",
        "                        optim.zero_grad()\n",
        "                        train_loss.backward()\n",
        "\n",
        "                        if clip_grad:\n",
        "                            if isinstance(clip_grad, bool):\n",
        "                                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.)\n",
        "                            else:\n",
        "                                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=clip_grad)\n",
        "\n",
        "                        optim.step()\n",
        "\n",
        "                    pbar.update(1)\n",
        "\n",
        "                    if not total_steps % steps_til_summary:\n",
        "                        tqdm.write(\"Epoch %d, Total loss %0.6f, iteration time %0.6f\" % (epoch, train_loss, time.time() - start_time))\n",
        "                        if self.use_wandb:\n",
        "                            wandb.log({\n",
        "                                'step': epoch,\n",
        "                                'train_loss': train_loss,\n",
        "                                'pde_loss': losses['diff_constraint_hom'],\n",
        "                            })\n",
        "\n",
        "                    total_steps += 1\n",
        "\n",
        "                # cost-supervised learning (CSL) phase\n",
        "                if use_CSL and not self.dataset.pretrain and (epoch-last_CSL_epoch) >= epochs_til_CSL:\n",
        "                    last_CSL_epoch = epoch\n",
        "\n",
        "                    # generate CSL datasets\n",
        "                    self.model.eval()\n",
        "\n",
        "                    CSL_dataset = scenario_optimization(\n",
        "                        device=device, model=self.model, policy=self.model, dynamics=self.dataset.dynamics,\n",
        "                        tMin=self.dataset.tMin, tMax=CSL_tMax, dt=CSL_dt,\n",
        "                        set_type=\"BRT\", control_type=\"value\", # TODO: implement option for BRS too\n",
        "                        scenario_batch_size=min(num_CSL_samples, 100000), sample_batch_size=min(10*num_CSL_samples, 1000000),\n",
        "                        sample_generator=SliceSampleGenerator(dynamics=self.dataset.dynamics, slices=[None]*self.dataset.dynamics.state_dim),\n",
        "                        sample_validator=ValueThresholdValidator(v_min=float('-inf'), v_max=float('inf')),\n",
        "                        violation_validator=ValueThresholdValidator(v_min=0.0, v_max=0.0),\n",
        "                        max_scenarios=num_CSL_samples, tStart_generator=lambda n : torch.zeros(n).uniform_(self.dataset.tMin, CSL_tMax)\n",
        "                    )\n",
        "                    CSL_coords = torch.cat((CSL_dataset['times'].unsqueeze(-1), CSL_dataset['states']), dim=-1)\n",
        "                    CSL_costs = CSL_dataset['costs']\n",
        "\n",
        "                    num_CSL_val_samples = int(0.1*num_CSL_samples)\n",
        "                    CSL_val_dataset = scenario_optimization(\n",
        "                        model=self.model, policy=self.model, dynamics=self.dataset.dynamics,\n",
        "                        tMin=self.dataset.tMin, tMax=CSL_tMax, dt=CSL_dt,\n",
        "                        set_type=\"BRT\", control_type=\"value\", # TODO: implement option for BRS too\n",
        "                        scenario_batch_size=min(num_CSL_val_samples, 100000), sample_batch_size=min(10*num_CSL_val_samples, 1000000),\n",
        "                        sample_generator=SliceSampleGenerator(dynamics=self.dataset.dynamics, slices=[None]*self.dataset.dynamics.state_dim),\n",
        "                        sample_validator=ValueThresholdValidator(v_min=float('-inf'), v_max=float('inf')),\n",
        "                        violation_validator=ValueThresholdValidator(v_min=0.0, v_max=0.0),\n",
        "                        max_scenarios=num_CSL_val_samples, tStart_generator=lambda n : torch.zeros(n).uniform_(self.dataset.tMin, CSL_tMax)\n",
        "                    )\n",
        "                    CSL_val_coords = torch.cat((CSL_val_dataset['times'].unsqueeze(-1), CSL_val_dataset['states']), dim=-1)\n",
        "                    CSL_val_costs = CSL_val_dataset['costs']\n",
        "\n",
        "                    CSL_val_tMax_dataset = scenario_optimization(\n",
        "                        model=self.model, policy=self.model, dynamics=self.dataset.dynamics,\n",
        "                        tMin=self.dataset.tMin, tMax=self.dataset.tMax, dt=CSL_dt,\n",
        "                        set_type=\"BRT\", control_type=\"value\", # TODO: implement option for BRS too\n",
        "                        scenario_batch_size=min(num_CSL_val_samples, 100000), sample_batch_size=min(10*num_CSL_val_samples, 1000000),\n",
        "                        sample_generator=SliceSampleGenerator(dynamics=self.dataset.dynamics, slices=[None]*self.dataset.dynamics.state_dim),\n",
        "                        sample_validator=ValueThresholdValidator(v_min=float('-inf'), v_max=float('inf')),\n",
        "                        violation_validator=ValueThresholdValidator(v_min=0.0, v_max=0.0),\n",
        "                        max_scenarios=num_CSL_val_samples # no tStart_generator, since I want all tMax times\n",
        "                    )\n",
        "                    CSL_val_tMax_coords = torch.cat((CSL_val_tMax_dataset['times'].unsqueeze(-1), CSL_val_tMax_dataset['states']), dim=-1)\n",
        "                    CSL_val_tMax_costs = CSL_val_tMax_dataset['costs']\n",
        "\n",
        "                    self.model.train()\n",
        "\n",
        "                    # CSL optimizer\n",
        "                    CSL_optim = torch.optim.Adam(lr=CSL_lr, params=self.model.parameters())\n",
        "\n",
        "                    # initial CSL val loss\n",
        "                    CSL_val_results = self.model({'coords': self.dataset.dynamics.coord_to_input(CSL_val_coords.to(device))})\n",
        "                    CSL_val_preds = self.dataset.dynamics.io_to_value(CSL_val_results['model_in'], CSL_val_results['model_out'].squeeze(dim=-1))\n",
        "                    CSL_val_errors = CSL_val_preds - CSL_val_costs.to(device)\n",
        "                    CSL_val_loss = torch.mean(torch.pow(CSL_val_errors, 2))\n",
        "                    CSL_initial_val_loss = CSL_val_loss\n",
        "                    if self.use_wandb:\n",
        "                        wandb.log({\n",
        "                            \"step\": epoch,\n",
        "                            \"CSL_val_loss\": CSL_val_loss.item()\n",
        "                        })\n",
        "\n",
        "                    # initial self-supervised learning (SSL) val loss\n",
        "                    # right now, just took code from dataio.py and the SSL training loop above; TODO: refactor all this for cleaner modular code\n",
        "                    CSL_val_states = CSL_val_coords[..., 1:].to(device)\n",
        "                    CSL_val_dvs = self.dataset.dynamics.io_to_dv(CSL_val_results['model_in'], CSL_val_results['model_out'].squeeze(dim=-1))\n",
        "                    CSL_val_boundary_values = self.dataset.dynamics.boundary_fn(CSL_val_states)\n",
        "                    if self.dataset.dynamics.loss_type == 'brat_hjivi':\n",
        "                        CSL_val_reach_values = self.dataset.dynamics.reach_fn(CSL_val_states)\n",
        "                        CSL_val_avoid_values = self.dataset.dynamics.avoid_fn(CSL_val_states)\n",
        "                    CSL_val_dirichlet_masks = CSL_val_coords[:, 0].to(device) == self.dataset.tMin # assumes time unit in dataset (model) is same as real time units\n",
        "                    if self.dataset.dynamics.loss_type == 'brt_hjivi':\n",
        "                        SSL_val_losses = loss_fn(CSL_val_states, CSL_val_preds, CSL_val_dvs[..., 0], CSL_val_dvs[..., 1:], CSL_val_boundary_values, CSL_val_dirichlet_masks)\n",
        "                    elif self.dataset.dynamics.loss_type == 'brat_hjivi':\n",
        "                        SSL_val_losses = loss_fn(CSL_val_states, CSL_val_preds, CSL_val_dvs[..., 0], CSL_val_dvs[..., 1:], CSL_val_boundary_values, CSL_val_reach_values, CSL_val_avoid_values, CSL_val_dirichlet_masks)\n",
        "                    else:\n",
        "                        NotImplementedError\n",
        "                    SSL_val_loss = SSL_val_losses['diff_constraint_hom'].mean() # I assume there is no dirichlet (boundary) loss here, because I do not ever explicitly generate source samples at tMin (i.e. torch.all(CSL_val_dirichlet_masks == False))\n",
        "                    if self.use_wandb:\n",
        "                        wandb.log({\n",
        "                            \"step\": epoch,\n",
        "                            \"SSL_val_loss\": SSL_val_loss.item()\n",
        "                        })\n",
        "\n",
        "                    # CSL training loop\n",
        "                    for CSL_epoch in tqdm(range(max_CSL_epochs)):\n",
        "                        CSL_idxs = torch.randperm(num_CSL_samples)\n",
        "                        for CSL_batch in range(math.ceil(num_CSL_samples/CSL_batch_size)):\n",
        "                            CSL_batch_idxs = CSL_idxs[CSL_batch*CSL_batch_size:(CSL_batch+1)*CSL_batch_size]\n",
        "                            CSL_batch_coords = CSL_coords[CSL_batch_idxs]\n",
        "\n",
        "                            CSL_batch_results = self.model({'coords': self.dataset.dynamics.coord_to_input(CSL_batch_coords.to(device))})\n",
        "                            CSL_batch_preds = self.dataset.dynamics.io_to_value(CSL_batch_results['model_in'], CSL_batch_results['model_out'].squeeze(dim=-1))\n",
        "                            CSL_batch_costs = CSL_costs[CSL_batch_idxs].to(device)\n",
        "                            CSL_batch_errors = CSL_batch_preds - CSL_batch_costs\n",
        "                            CSL_batch_loss = CSL_loss_weight*torch.mean(torch.pow(CSL_batch_errors, 2))\n",
        "\n",
        "                            CSL_batch_states = CSL_batch_coords[..., 1:].to(device)\n",
        "                            CSL_batch_dvs = self.dataset.dynamics.io_to_dv(CSL_batch_results['model_in'], CSL_batch_results['model_out'].squeeze(dim=-1))\n",
        "                            CSL_batch_boundary_values = self.dataset.dynamics.boundary_fn(CSL_batch_states)\n",
        "                            if self.dataset.dynamics.loss_type == 'brat_hjivi':\n",
        "                                CSL_batch_reach_values = self.dataset.dynamics.reach_fn(CSL_batch_states)\n",
        "                                CSL_batch_avoid_values = self.dataset.dynamics.avoid_fn(CSL_batch_states)\n",
        "                            CSL_batch_dirichlet_masks = CSL_batch_coords[:, 0].to(device) == self.dataset.tMin # assumes time unit in dataset (model) is same as real time units\n",
        "                            if self.dataset.dynamics.loss_type == 'brt_hjivi':\n",
        "                                SSL_batch_losses = loss_fn(CSL_batch_states, CSL_batch_preds, CSL_batch_dvs[..., 0], CSL_batch_dvs[..., 1:], CSL_batch_boundary_values, CSL_batch_dirichlet_masks)\n",
        "                            elif self.dataset.dynamics.loss_type == 'brat_hjivi':\n",
        "                                SSL_batch_losses = loss_fn(CSL_batch_states, CSL_batch_preds, CSL_batch_dvs[..., 0], CSL_batch_dvs[..., 1:], CSL_batch_boundary_values, CSL_batch_reach_values, CSL_batch_avoid_values, CSL_batch_dirichlet_masks)\n",
        "                            else:\n",
        "                                NotImplementedError\n",
        "                            SSL_batch_loss = SSL_batch_losses['diff_constraint_hom'].mean() # I assume there is no dirichlet (boundary) loss here, because I do not ever explicitly generate source samples at tMin (i.e. torch.all(CSL_batch_dirichlet_masks == False))\n",
        "\n",
        "                            CSL_optim.zero_grad()\n",
        "                            SSL_batch_loss.backward(retain_graph=True)\n",
        "                            if (not use_lbfgs) and clip_grad: # no adjust_relative_grads, because I assume even with adjustment, the diff_constraint_hom remains unaffected and the only other loss (dirichlet) is zero\n",
        "                                if isinstance(clip_grad, bool):\n",
        "                                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.)\n",
        "                                else:\n",
        "                                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=clip_grad)\n",
        "                            CSL_batch_loss.backward()\n",
        "                            CSL_optim.step()\n",
        "\n",
        "                        # evaluate on CSL_val_dataset\n",
        "                        CSL_val_results = self.model({'coords': self.dataset.dynamics.coord_to_input(CSL_val_coords.to(device))})\n",
        "                        CSL_val_preds = self.dataset.dynamics.io_to_value(CSL_val_results['model_in'], CSL_val_results['model_out'].squeeze(dim=-1))\n",
        "                        CSL_val_errors = CSL_val_preds - CSL_val_costs.to(device)\n",
        "                        CSL_val_loss = torch.mean(torch.pow(CSL_val_errors, 2))\n",
        "\n",
        "                        CSL_val_states = CSL_val_coords[..., 1:].to(device)\n",
        "                        CSL_val_dvs = self.dataset.dynamics.io_to_dv(CSL_val_results['model_in'], CSL_val_results['model_out'].squeeze(dim=-1))\n",
        "                        CSL_val_boundary_values = self.dataset.dynamics.boundary_fn(CSL_val_states)\n",
        "                        if self.dataset.dynamics.loss_type == 'brat_hjivi':\n",
        "                            CSL_val_reach_values = self.dataset.dynamics.reach_fn(CSL_val_states)\n",
        "                            CSL_val_avoid_values = self.dataset.dynamics.avoid_fn(CSL_val_states)\n",
        "                        CSL_val_dirichlet_masks = CSL_val_coords[:, 0].to(device) == self.dataset.tMin # assumes time unit in dataset (model) is same as real time units\n",
        "                        if self.dataset.dynamics.loss_type == 'brt_hjivi':\n",
        "                            SSL_val_losses = loss_fn(CSL_val_states, CSL_val_preds, CSL_val_dvs[..., 0], CSL_val_dvs[..., 1:], CSL_val_boundary_values, CSL_val_dirichlet_masks)\n",
        "                        elif self.dataset.dynamics.loss_type == 'brat_hjivi':\n",
        "                            SSL_val_losses = loss_fn(CSL_val_states, CSL_val_preds, CSL_val_dvs[..., 0], CSL_val_dvs[..., 1:], CSL_val_boundary_values, CSL_val_reach_values, CSL_val_avoid_values, CSL_val_dirichlet_masks)\n",
        "                        else:\n",
        "                            raise NotImplementedError\n",
        "                        SSL_val_loss = SSL_val_losses['diff_constraint_hom'].mean() # I assume there is no dirichlet (boundary) loss here, because I do not ever explicitly generate source samples at tMin (i.e. torch.all(CSL_val_dirichlet_masks == False))\n",
        "\n",
        "                        CSL_val_tMax_results = self.model({'coords': self.dataset.dynamics.coord_to_input(CSL_val_tMax_coords.to(device))})\n",
        "                        CSL_val_tMax_preds = self.dataset.dynamics.io_to_value(CSL_val_tMax_results['model_in'], CSL_val_tMax_results['model_out'].squeeze(dim=-1))\n",
        "                        CSL_val_tMax_errors = CSL_val_tMax_preds - CSL_val_tMax_costs.to(device)\n",
        "                        CSL_val_tMax_loss = torch.mean(torch.pow(CSL_val_tMax_errors, 2))\n",
        "\n",
        "                        # log CSL losses, recovered_safe_set_fracs\n",
        "                        if self.dataset.dynamics.set_mode == 'reach':\n",
        "                            CSL_train_batch_theoretically_recoverable_safe_set_frac = torch.sum(CSL_batch_costs.to(device) < 0) / len(CSL_batch_preds)\n",
        "                            CSL_train_batch_recovered_safe_set_frac = torch.sum(CSL_batch_preds < torch.min(CSL_batch_preds[CSL_batch_costs.to(device) > 0])) / len(CSL_batch_preds)\n",
        "                            CSL_val_theoretically_recoverable_safe_set_frac = torch.sum(CSL_val_costs.to(device) < 0) / len(CSL_val_preds)\n",
        "                            CSL_val_recovered_safe_set_frac = torch.sum(CSL_val_preds < torch.min(CSL_val_preds[CSL_val_costs.to(device) > 0])) / len(CSL_val_preds)\n",
        "                            CSL_val_tMax_theoretically_recoverable_safe_set_frac = torch.sum(CSL_val_tMax_costs.to(device) < 0) / len(CSL_val_tMax_preds)\n",
        "                            CSL_val_tMax_recovered_safe_set_frac = torch.sum(CSL_val_tMax_preds < torch.min(CSL_val_tMax_preds[CSL_val_tMax_costs.to(device) > 0])) / len(CSL_val_tMax_preds)\n",
        "                        elif self.dataset.dynamics.set_mode == 'avoid':\n",
        "                            CSL_train_batch_theoretically_recoverable_safe_set_frac = torch.sum(CSL_batch_costs.to(device) > 0) / len(CSL_batch_preds)\n",
        "                            CSL_train_batch_recovered_safe_set_frac = torch.sum(CSL_batch_preds > torch.max(CSL_batch_preds[CSL_batch_costs.to(device) < 0])) / len(CSL_batch_preds)\n",
        "                            CSL_val_theoretically_recoverable_safe_set_frac = torch.sum(CSL_val_costs.to(device) > 0) / len(CSL_val_preds)\n",
        "                            CSL_val_recovered_safe_set_frac = torch.sum(CSL_val_preds > torch.max(CSL_val_preds[CSL_val_costs.to(device) < 0])) / len(CSL_val_preds)\n",
        "                            CSL_val_tMax_theoretically_recoverable_safe_set_frac = torch.sum(CSL_val_tMax_costs.to(device) > 0) / len(CSL_val_tMax_preds)\n",
        "                            CSL_val_tMax_recovered_safe_set_frac = torch.sum(CSL_val_tMax_preds > torch.max(CSL_val_tMax_preds[CSL_val_tMax_costs.to(device) < 0])) / len(CSL_val_tMax_preds)\n",
        "                        else:\n",
        "                            raise NotImplementedError\n",
        "                        if self.use_wandb:\n",
        "                            wandb.log({\n",
        "                                \"step\": epoch+(CSL_epoch+1)*int(0.5*epochs_til_CSL/max_CSL_epochs),\n",
        "                                \"CSL_train_batch_loss\": CSL_batch_loss.item(),\n",
        "                                \"SSL_train_batch_loss\": SSL_batch_loss.item(),\n",
        "                                \"CSL_val_loss\": CSL_val_loss.item(),\n",
        "                                \"SSL_val_loss\": SSL_val_loss.item(),\n",
        "                                \"CSL_val_tMax_loss\": CSL_val_tMax_loss.item(),\n",
        "                                \"CSL_train_batch_theoretically_recoverable_safe_set_frac\": CSL_train_batch_theoretically_recoverable_safe_set_frac.item(),\n",
        "                                \"CSL_val_theoretically_recoverable_safe_set_frac\": CSL_val_theoretically_recoverable_safe_set_frac.item(),\n",
        "                                \"CSL_val_tMax_theoretically_recoverable_safe_set_frac\": CSL_val_tMax_theoretically_recoverable_safe_set_frac.item(),\n",
        "                                \"CSL_train_batch_recovered_safe_set_frac\": CSL_train_batch_recovered_safe_set_frac.item(),\n",
        "                                \"CSL_val_recovered_safe_set_frac\": CSL_val_recovered_safe_set_frac.item(),\n",
        "                                \"CSL_val_tMax_recovered_safe_set_frac\": CSL_val_tMax_recovered_safe_set_frac.item(),\n",
        "                            })\n",
        "\n",
        "                        if CSL_val_loss < CSL_loss_frac_cutoff*CSL_initial_val_loss:\n",
        "                            break\n",
        "\n",
        "                if not (epoch+1) % epochs_til_checkpoint:\n",
        "                    # Saving the optimizer state is important to produce consistent results\n",
        "                    checkpoint = {\n",
        "                        'epoch': epoch+1,\n",
        "                        'model': self.model.state_dict(),\n",
        "                        'optimizer': optim.state_dict()}\n",
        "                    torch.save(checkpoint,\n",
        "                        os.path.join(checkpoints_dir, 'model_epoch_%04d.pth' % (epoch+1)))\n",
        "                    np.savetxt(os.path.join(checkpoints_dir, 'train_losses_epoch_%04d.txt' % (epoch+1)),\n",
        "                        np.array(train_losses))\n",
        "                    self.validate(\n",
        "                        device=device, epoch=epoch+1, save_path=os.path.join(checkpoints_dir, 'BRS_validation_plot_epoch_%04d.png' % (epoch+1)),\n",
        "                        x_resolution = val_x_resolution, y_resolution = val_y_resolution, z_resolution=val_z_resolution, time_resolution=val_time_resolution)\n",
        "\n",
        "        if was_eval:\n",
        "            self.model.eval()\n",
        "            self.model.requires_grad_(False)\n",
        "\n",
        "    def test(self, device, current_time, last_checkpoint, checkpoint_dt, dt, num_scenarios, num_violations, set_type, control_type, data_step, checkpoint_toload=None):\n",
        "        was_training = self.model.training\n",
        "        self.model.eval()\n",
        "        self.model.requires_grad_(False)\n",
        "\n",
        "        testing_dir = os.path.join(self.experiment_dir, 'testing_%s' % current_time.strftime('%m_%d_%Y_%H_%M'))\n",
        "        if os.path.exists(testing_dir):\n",
        "            overwrite = input(\"The testing directory %s already exists. Overwrite? (y/n)\"%testing_dir)\n",
        "            if not (overwrite == 'y'):\n",
        "                print('Exiting.')\n",
        "                quit()\n",
        "            shutil.rmtree(testing_dir)\n",
        "        os.makedirs(testing_dir)\n",
        "\n",
        "        if checkpoint_toload is None:\n",
        "            print('running cross-checkpoint testing')\n",
        "\n",
        "            for i in tqdm(range(sidelen), desc='Checkpoint'):\n",
        "                self._load_checkpoint(epoch=checkpoints[i])\n",
        "                raise NotImplementedError\n",
        "\n",
        "        else:\n",
        "            print('running specific-checkpoint testing')\n",
        "            self._load_checkpoint(checkpoint_toload)\n",
        "\n",
        "            model = self.model\n",
        "            dataset = self.dataset\n",
        "            dynamics = dataset.dynamics\n",
        "            raise NotImplementedError\n",
        "\n",
        "        if was_training:\n",
        "            self.model.train()\n",
        "            self.model.requires_grad_(True)\n",
        "\n",
        "class DeepReach(Experiment):\n",
        "    def init_special(self):\n",
        "        pass"
      ],
      "metadata": {
        "id": "QMWFvhr8ECTy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Run Experiment"
      ],
      "metadata": {
        "id": "aA4ZpF_vE8wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "PDz8C2x_Q3gE",
        "outputId": "a6b74301-bd2a-4e0c-cb67-b0ebbd94f083"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maanirudh\u001b[0m (\u001b[33maanirudh-n-a\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "sys.argv = [\n",
        "    \"script_name\",  # Placeholder for script name (ignored by argparse)\n",
        "    \"--mode\", \"train\",\n",
        "    \"--experiment_class\", \"DeepReach\",\n",
        "    \"--dynamics_class\", \"PlanarRobot2D\",\n",
        "    \"--experiment_name\", \"brt_obstacle_05m\",\n",
        "    \"--minWith\", \"target\",\n",
        "    \"--goalR\", \"0.5\",\n",
        "    \"--velocity\", \"1.0\",\n",
        "    \"--set_mode\", \"avoid\",\n",
        "    \"--num_epochs\", \"40000\",\n",
        "\n",
        "    \"--wandb_project\", \"reachability-experiments\",\n",
        "    \"--wandb_entity\", \"aanirudh-n-a\",\n",
        "    '--wandb_group', \"Training\",\n",
        "    '--wandb_name', \"brt_obstacle_05m_run_01\",\n",
        "]"
      ],
      "metadata": {
        "id": "F6Uc01CzFDSb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "from inspect import isclass\n",
        "p = configargparse.ArgumentParser()\n",
        "\n",
        "p.add_argument('-c', '--config_filepath', required=False, is_config_file=True, help='Path to config file.')\n",
        "p.add_argument('--mode', type=str, required=True, choices=['all', 'train', 'test'], help=\"Experiment mode to run (new experiments must choose 'all' or 'train').\")\n",
        "\n",
        "# save/load directory options\n",
        "p.add_argument('--experiments_dir', type=str, default='./runs', help='Where to save the experiment subdirectory.')\n",
        "p.add_argument('--experiment_name', type=str, required=True, help='Name of the experient subdirectory.')\n",
        "p.add_argument('--use_wandb', default=True, action='store_false', help='use wandb for logging')\n",
        "\n",
        "use_wandb = p.parse_known_args()[0].use_wandb\n",
        "if use_wandb:\n",
        "    p.add_argument('--wandb_project', type=str, required=True, help='wandb project')\n",
        "    p.add_argument('--wandb_entity', type=str, required=True, help='wandb entity')\n",
        "    p.add_argument('--wandb_group', type=str, required=True, help='wandb group')\n",
        "    p.add_argument('--wandb_name', type=str, required=True, help='name of wandb run')\n",
        "\n",
        "mode = p.parse_known_args()[0].mode\n",
        "\n",
        "if (mode == 'all') or (mode == 'train'):\n",
        "    p.add_argument('--seed', type=int, default=0, required=False, help='Seed for the experiment.')\n",
        "\n",
        "    # load experiment_class choices dynamically from experiments module\n",
        "    experiment_classes_dict = {\n",
        "        name: clss for name, clss in globals().items()\n",
        "        if isclass(clss) and issubclass(clss, Experiment) and clss is not Experiment\n",
        "    }\n",
        "    # experiment_classes_dict = {name: clss for name, clss in inspect.getmembers(experiments, inspect.isclass) if clss.__bases__[0] == experiments.Experiment}\n",
        "    p.add_argument('--experiment_class', type=str, default='DeepReach', choices=experiment_classes_dict.keys(), help='Experiment class to use.')\n",
        "    # load special experiment_class arguments dynamically from chosen experiment class\n",
        "    experiment_class = DeepReach #experiment_classes_dict[p.parse_known_args()[0].experiment_class]\n",
        "    experiment_params = {name: param for name, param in inspect.signature(experiment_class.init_special).parameters.items() if name != 'self'}\n",
        "    for param in experiment_params.keys():\n",
        "        p.add_argument('--' + param, type=experiment_params[param].annotation, required=True, help='special experiment_class argument')\n",
        "\n",
        "    # simulation data source options\n",
        "    p.add_argument('--device', type=str, default='cuda:0', required=False, help='CUDA Device to use.')\n",
        "    p.add_argument('--numpoints', type=int, default=65000, help='Number of points in simulation data source __getitem__.')\n",
        "    p.add_argument('--pretrain', action='store_true', default=False, required=False, help='Pretrain dirichlet conditions')\n",
        "    p.add_argument('--pretrain_iters', type=int, default=2000, required=False, help='Number of pretrain iterations')\n",
        "    p.add_argument('--tMin', type=float, default=0.0, required=False, help='Start time of the simulation')\n",
        "    p.add_argument('--tMax', type=float, default=1.0, required=False, help='End time of the simulation')\n",
        "    p.add_argument('--counter_start', type=int, default=0, required=False, help='Defines the initial time for the curriculum training')\n",
        "    p.add_argument('--counter_end', type=int, default=-1, required=False, help='Defines the linear step for curriculum training starting from the initial time')\n",
        "    p.add_argument('--num_src_samples', type=int, default=1000, required=False, help='Number of source samples (initial-time samples) at each time step')\n",
        "    p.add_argument('--num_target_samples', type=int, default=0, required=False, help='Number of samples inside the target set')\n",
        "\n",
        "    # model options\n",
        "    p.add_argument('--model', type=str, default='sine', required=False, choices=['sine', 'tanh', 'sigmoid', 'relu'], help='Type of model to evaluate, default is sine.')\n",
        "    p.add_argument('--model_mode', type=str, default='mlp', required=False, choices=['mlp', 'rbf', 'pinn'], help='Whether to use uniform velocity parameter')\n",
        "    p.add_argument('--num_hl', type=int, default=3, required=False, help='The number of hidden layers')\n",
        "    p.add_argument('--num_nl', type=int, default=512, required=False, help='Number of neurons per hidden layer.')\n",
        "    p.add_argument('--deepreach_model', type=str, default='exact', required=False, choices=['exact', 'diff', 'vanilla'], help='deepreach model')\n",
        "\n",
        "    # training options\n",
        "    p.add_argument('--epochs_til_ckpt', type=int, default=1000, help='Time interval in seconds until checkpoint is saved.')\n",
        "    p.add_argument('--steps_til_summary', type=int, default=100, help='Time interval in seconds until tensorboard summary is saved.')\n",
        "    p.add_argument('--batch_size', type=int, default=1, help='Batch size used during training (irrelevant, since len(dataset) == 1).')\n",
        "    p.add_argument('--lr', type=float, default=2e-5, help='learning rate. default=2e-5')\n",
        "    p.add_argument('--num_epochs', type=int, default=100000, help='Number of epochs to train for.')\n",
        "    p.add_argument('--clip_grad', default=0.0, type=float, help='Clip gradient.')\n",
        "    p.add_argument('--use_lbfgs', default=False, type=bool, help='use L-BFGS.')\n",
        "    p.add_argument('--adj_rel_grads', default=True, type=bool, help='adjust the relative magnitude of the losses')\n",
        "    p.add_argument('--dirichlet_loss_divisor', default=1.0, required=False, type=float, help='What to divide the dirichlet loss by for loss reweighting')\n",
        "\n",
        "    # cost-supervised learning (CSL) options\n",
        "    p.add_argument('--use_CSL', default=False, action='store_true', help='use cost-supervised learning (CSL)')\n",
        "    p.add_argument('--CSL_lr', type=float, default=2e-5, help='The learning rate used for CSL')\n",
        "    p.add_argument('--CSL_dt', type=float, default=0.0025, help='The dt used in rolling out trajectories to get cost labels')\n",
        "    p.add_argument('--epochs_til_CSL', type=int, default=10000, help='Number of epochs between CSL phases')\n",
        "    p.add_argument('--num_CSL_samples', type=int, default=1000000, help='Number of cost samples in training dataset for CSL phases')\n",
        "    p.add_argument('--CSL_loss_frac_cutoff', type=float, default=0.1, help='Fraction of initial cost loss on validation dataset to cutoff CSL phases')\n",
        "    p.add_argument('--max_CSL_epochs', type=int, default=100, help='Max number of CSL epochs per phase')\n",
        "    p.add_argument('--CSL_loss_weight', type=float, default=1.0, help='weight of cost loss (relative to PDE loss)')\n",
        "    p.add_argument('--CSL_batch_size', type=int, default=1000, help='Batch size for training in CSL phases')\n",
        "\n",
        "    # validation (during training) options\n",
        "    p.add_argument('--val_x_resolution', type=int, default=200, help='x-axis resolution of validation plot during training')\n",
        "    p.add_argument('--val_y_resolution', type=int, default=200, help='y-axis resolution of validation plot during training')\n",
        "    p.add_argument('--val_z_resolution', type=int, default=5, help='z-axis resolution of validation plot during training')\n",
        "    p.add_argument('--val_time_resolution', type=int, default=3, help='time-axis resolution of validation plot during training')\n",
        "\n",
        "    # loss options\n",
        "    p.add_argument('--minWith', type=str, required=True, choices=['none', 'zero', 'target'], help='BRS vs BRT computation (typically should be using target for BRT)')\n",
        "\n",
        "    # # load dynamics_class choices dynamically from dynamics module\n",
        "    # dynamics_classes_dict = {name: clss for name, clss in inspect.getmembers(dynamics, inspect.isclass) if clss.__bases__[0] == dynamics.Dynamics}\n",
        "    p.add_argument('--dynamics_class', type=str, required=True, choices=[\"PlanarRobot2D\"], help='Dynamics class to use.')\n",
        "    # # load special dynamics_class arguments dynamically from chosen dynamics class\n",
        "    # dynamics_class = dynamics_classes_dict[p.parse_known_args()[0].dynamics_class]\n",
        "    # dynamics_params = {name: param for name, param in inspect.signature(dynamics_class).parameters.items() if name != 'self'}\n",
        "    dynamics_class = PlanarRobot2D\n",
        "    dynamics_params = {\n",
        "        name: param for name, param in inspect.signature(dynamics_class).parameters.items() if name != 'self'\n",
        "    }\n",
        "\n",
        "    for param in dynamics_params.keys():\n",
        "        if dynamics_params[param].annotation is bool:\n",
        "            p.add_argument('--' + param, type=dynamics_params[param].annotation, default=False, help='special dynamics_class argument')\n",
        "        else:\n",
        "            p.add_argument('--' + param, type=dynamics_params[param].annotation, required=True, help='special dynamics_class argument')\n",
        "\n",
        "if (mode == 'all') or (mode == 'test'):\n",
        "    p.add_argument('--dt', type=float, default=0.0025, help='The dt used in testing simulations')\n",
        "    p.add_argument('--checkpoint_toload', type=int, default=None, help=\"The checkpoint to load for testing (-1 for final training checkpoint, None for cross-checkpoint testing\")\n",
        "    p.add_argument('--num_scenarios', type=int, default=100000, help='The number of scenarios sampled in scenario optimization for testing')\n",
        "    p.add_argument('--num_violations', type=int, default=1000, help='The number of violations to sample for in scenario optimization for testing')\n",
        "    p.add_argument('--control_type', type=str, default='value', choices=['value', 'ttr', 'init_ttr'], help='The controller to use in scenario optimization for testing')\n",
        "    p.add_argument('--data_step', type=str, default='run_basic_recovery', choices=['plot_violations', 'run_basic_recovery', 'plot_basic_recovery', 'collect_samples', 'train_binner', 'run_binned_recovery', 'plot_binned_recovery', 'plot_cost_function'], help='The data processing step to run')\n",
        "\n",
        "opt = p.parse_args()\n",
        "\n",
        "# start wandb\n",
        "if use_wandb:\n",
        "    wandb.init(\n",
        "        project = opt.wandb_project,\n",
        "        entity = opt.wandb_entity,\n",
        "        group = opt.wandb_group,\n",
        "        name = opt.wandb_name,\n",
        "    )\n",
        "    wandb.config.update(opt)\n",
        "\n",
        "experiment_dir = os.path.join(opt.experiments_dir, opt.experiment_name)\n",
        "if (mode == 'all') or (mode == 'train'):\n",
        "    # create experiment dir\n",
        "    if os.path.exists(experiment_dir):\n",
        "        overwrite = input(\"The experiment directory %s already exists. Overwrite? (y/n)\"%experiment_dir)\n",
        "        if not (overwrite == 'y'):\n",
        "            print('Exiting.')\n",
        "            quit()\n",
        "        shutil.rmtree(experiment_dir)\n",
        "    os.makedirs(experiment_dir)\n",
        "elif mode == 'test':\n",
        "    # confirm that experiment dir already exists\n",
        "    if not os.path.exists(experiment_dir):\n",
        "        raise RuntimeError('Cannot run test mode: experiment directory not found!')\n",
        "\n",
        "current_time = datetime.now()\n",
        "# log current config\n",
        "with open(os.path.join(experiment_dir, 'config_%s.txt' % current_time.strftime('%m_%d_%Y_%H_%M')), 'w') as f:\n",
        "    for arg, val in vars(opt).items():\n",
        "        f.write(arg + ' = ' + str(val) + '\\n')\n",
        "\n",
        "if (mode == 'all') or (mode == 'train'):\n",
        "    # set counter_end appropriately if needed\n",
        "    if opt.counter_end == -1:\n",
        "        opt.counter_end = opt.num_epochs\n",
        "\n",
        "    # log original options\n",
        "    with open(os.path.join(experiment_dir, 'orig_opt.pickle'), 'wb') as opt_file:\n",
        "        pickle.dump(opt, opt_file)\n",
        "\n",
        "# load original experiment settings\n",
        "with open(os.path.join(experiment_dir, 'orig_opt.pickle'), 'rb') as opt_file:\n",
        "    orig_opt = pickle.load(opt_file)\n",
        "\n",
        "# set the experiment seed\n",
        "torch.manual_seed(orig_opt.seed)\n",
        "random.seed(orig_opt.seed)\n",
        "np.random.seed(orig_opt.seed)\n",
        "\n",
        "dynamics_class = PlanarRobot2D #getattr(dynamics, orig_opt.dynamics_class)\n",
        "dynamics = dynamics_class(**{argname: getattr(orig_opt, argname) for argname in inspect.signature(dynamics_class).parameters.keys() if argname != 'self'})\n",
        "dynamics.deepreach_model=orig_opt.deepreach_model\n",
        "dataset = ReachabilityDataset(\n",
        "    dynamics=dynamics, numpoints=orig_opt.numpoints,\n",
        "    pretrain=orig_opt.pretrain, pretrain_iters=orig_opt.pretrain_iters,\n",
        "    tMin=orig_opt.tMin, tMax=orig_opt.tMax,\n",
        "    counter_start=orig_opt.counter_start, counter_end=orig_opt.counter_end,\n",
        "    num_src_samples=orig_opt.num_src_samples, num_target_samples=orig_opt.num_target_samples)\n",
        "\n",
        "model = SingleBVPNet(in_features=dynamics.input_dim, out_features=1, type=orig_opt.model, mode=orig_opt.model_mode,\n",
        "                             final_layer_factor=1., hidden_features=orig_opt.num_nl, num_hidden_layers=orig_opt.num_hl)\n",
        "model.to(opt.device)\n",
        "\n",
        "experiment_class = DeepReach #getattr(experiments, orig_opt.experiment_class)\n",
        "experiment = experiment_class(model=model, dataset=dataset, experiment_dir=experiment_dir, use_wandb=use_wandb)\n",
        "experiment.init_special(**{argname: getattr(orig_opt, argname) for argname in inspect.signature(experiment_class.init_special).parameters.keys() if argname != 'self'})\n",
        "\n",
        "if (mode == 'all') or (mode == 'train'):\n",
        "    if dynamics.loss_type == 'brt_hjivi':\n",
        "        loss_fn = init_brt_hjivi_loss(dynamics, orig_opt.minWith, orig_opt.dirichlet_loss_divisor)\n",
        "    elif dynamics.loss_type == 'brat_hjivi':\n",
        "        loss_fn = init_brat_hjivi_loss(dynamics, orig_opt.minWith, orig_opt.dirichlet_loss_divisor)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    experiment.train(\n",
        "        device=opt.device, batch_size=orig_opt.batch_size, epochs=orig_opt.num_epochs, lr=orig_opt.lr,\n",
        "        steps_til_summary=orig_opt.steps_til_summary, epochs_til_checkpoint=orig_opt.epochs_til_ckpt,\n",
        "        loss_fn=loss_fn, clip_grad=orig_opt.clip_grad, use_lbfgs=orig_opt.use_lbfgs, adjust_relative_grads=orig_opt.adj_rel_grads,\n",
        "        val_x_resolution=orig_opt.val_x_resolution, val_y_resolution=orig_opt.val_y_resolution, val_z_resolution=orig_opt.val_z_resolution, val_time_resolution=orig_opt.val_time_resolution,\n",
        "        use_CSL=orig_opt.use_CSL, CSL_lr=orig_opt.CSL_lr, CSL_dt=orig_opt.CSL_dt, epochs_til_CSL=orig_opt.epochs_til_CSL, num_CSL_samples=orig_opt.num_CSL_samples, CSL_loss_frac_cutoff=orig_opt.CSL_loss_frac_cutoff, max_CSL_epochs=orig_opt.max_CSL_epochs, CSL_loss_weight=orig_opt.CSL_loss_weight, CSL_batch_size=orig_opt.CSL_batch_size)\n",
        "\n",
        "if (mode == 'all') or (mode == 'test'):\n",
        "    experiment.test(\n",
        "        device=opt.device, current_time=current_time,\n",
        "        last_checkpoint=orig_opt.num_epochs, checkpoint_dt=orig_opt.epochs_til_ckpt,\n",
        "        checkpoint_toload=opt.checkpoint_toload, dt=opt.dt,\n",
        "        num_scenarios=opt.num_scenarios, num_violations=opt.num_violations,\n",
        "        set_type='BRT' if orig_opt.minWith in ['zero', 'target'] else 'BRS', control_type=opt.control_type, data_step=opt.data_step)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uC4PdfSbE-2l",
        "outputId": "178932e1-668e-48b0-bc4e-194ed439e421"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/My Drive/wandb/run-20250419_092652-wqatfcw9</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/aanirudh-n-a/reachability-experiments/runs/wqatfcw9' target=\"_blank\">brt_obstacle_05m_run_01</a></strong> to <a href='https://wandb.ai/aanirudh-n-a/reachability-experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/aanirudh-n-a/reachability-experiments' target=\"_blank\">https://wandb.ai/aanirudh-n-a/reachability-experiments</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/aanirudh-n-a/reachability-experiments/runs/wqatfcw9' target=\"_blank\">https://wandb.ai/aanirudh-n-a/reachability-experiments/runs/wqatfcw9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SingleBVPNet(\n",
            "  (net): FCBlock(\n",
            "    (net): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): BatchLinear(in_features=3, out_features=512, bias=True)\n",
            "        (1): Sine()\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): BatchLinear(in_features=512, out_features=512, bias=True)\n",
            "        (1): Sine()\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): BatchLinear(in_features=512, out_features=512, bias=True)\n",
            "        (1): Sine()\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (0): BatchLinear(in_features=512, out_features=512, bias=True)\n",
            "        (1): Sine()\n",
            "      )\n",
            "      (4): Sequential(\n",
            "        (0): BatchLinear(in_features=512, out_features=1, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/40000 [00:01<15:53:16,  1.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Total loss 2817.822021, iteration time 1.395628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 102/40000 [00:23<2:25:59,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100, Total loss 219.990967, iteration time 0.221183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 202/40000 [00:44<2:26:28,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 200, Total loss 7.243275, iteration time 0.222728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 302/40000 [01:06<2:29:38,  4.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 300, Total loss 4.085196, iteration time 0.231560\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 402/40000 [01:29<2:29:50,  4.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 400, Total loss 6.817874, iteration time 0.223333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 502/40000 [01:51<2:33:23,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Total loss 10.895412, iteration time 0.235565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 602/40000 [02:14<2:35:37,  4.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 600, Total loss 13.368431, iteration time 0.240972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 702/40000 [02:37<2:32:07,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 700, Total loss 15.966686, iteration time 0.234381\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 802/40000 [03:00<2:31:40,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 800, Total loss 21.346594, iteration time 0.231023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 902/40000 [03:22<2:30:06,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 900, Total loss 23.050741, iteration time 0.235264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 1002/40000 [03:46<4:14:27,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1000, Total loss 28.613506, iteration time 0.096495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 1102/40000 [04:09<2:33:22,  4.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1100, Total loss 28.930210, iteration time 0.239513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 1202/40000 [04:31<2:29:59,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1200, Total loss 24.129002, iteration time 0.238394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 1302/40000 [04:54<2:30:46,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1300, Total loss 55.264885, iteration time 0.233086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▎         | 1402/40000 [05:17<2:28:48,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1400, Total loss 37.189682, iteration time 0.229247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 1502/40000 [05:40<2:29:35,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1500, Total loss 61.090290, iteration time 0.245869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 1602/40000 [06:02<2:31:33,  4.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1600, Total loss 43.868122, iteration time 0.239611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 1702/40000 [06:25<2:29:02,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1700, Total loss 54.180862, iteration time 0.231577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▍         | 1802/40000 [06:48<2:29:20,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1800, Total loss 33.367905, iteration time 0.240482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▍         | 1902/40000 [07:11<2:28:36,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1900, Total loss 57.654694, iteration time 0.226864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 2002/40000 [07:34<3:48:32,  2.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2000, Total loss 72.086365, iteration time 0.107411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 2102/40000 [07:57<2:27:42,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2100, Total loss 56.818802, iteration time 0.234466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 2202/40000 [08:20<2:29:42,  4.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2200, Total loss 68.335808, iteration time 0.243784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 2302/40000 [08:42<2:26:58,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2300, Total loss 67.170265, iteration time 0.235011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 2402/40000 [09:05<2:27:19,  4.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2400, Total loss 72.707733, iteration time 0.234453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▋         | 2502/40000 [09:28<2:27:21,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2500, Total loss 52.796455, iteration time 0.244592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 2602/40000 [09:51<2:25:11,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2600, Total loss 70.123520, iteration time 0.233879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 2702/40000 [10:14<2:24:48,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2700, Total loss 49.686676, iteration time 0.234061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 2802/40000 [10:36<2:27:31,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2800, Total loss 48.602005, iteration time 0.246720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 2902/40000 [10:59<2:23:00,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2900, Total loss 60.628403, iteration time 0.231926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 3002/40000 [11:23<4:01:39,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3000, Total loss 55.661774, iteration time 0.113386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 3102/40000 [11:45<2:23:41,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3100, Total loss 58.595314, iteration time 0.234484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 3202/40000 [12:08<2:23:30,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3200, Total loss 80.446144, iteration time 0.237259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 3302/40000 [12:31<2:22:42,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3300, Total loss 75.966156, iteration time 0.238693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▊         | 3402/40000 [12:54<2:21:43,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3400, Total loss 57.590050, iteration time 0.246374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 3502/40000 [13:16<2:22:02,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3500, Total loss 64.050186, iteration time 0.237018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 3602/40000 [13:39<2:26:26,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3600, Total loss 50.104610, iteration time 0.254594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 3702/40000 [14:02<2:19:50,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3700, Total loss 50.366352, iteration time 0.233323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 3802/40000 [14:25<2:19:07,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3800, Total loss 49.920654, iteration time 0.235912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 3902/40000 [14:47<2:19:42,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3900, Total loss 41.173309, iteration time 0.238039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 4002/40000 [15:11<3:25:21,  2.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4000, Total loss 58.176147, iteration time 0.094923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 4102/40000 [15:33<2:18:34,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4100, Total loss 54.093719, iteration time 0.236010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 4202/40000 [15:56<2:22:04,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4200, Total loss 64.750778, iteration time 0.249045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 4302/40000 [16:19<2:17:33,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4300, Total loss 59.316818, iteration time 0.235753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 4402/40000 [16:42<2:21:15,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4400, Total loss 85.767426, iteration time 0.254475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█▏        | 4502/40000 [17:05<2:17:10,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4500, Total loss 72.771065, iteration time 0.237519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 4602/40000 [17:27<2:16:15,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4600, Total loss 57.073769, iteration time 0.228973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 4702/40000 [17:50<2:18:41,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4700, Total loss 55.400360, iteration time 0.242521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 4802/40000 [18:13<2:16:46,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4800, Total loss 72.964569, iteration time 0.235226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 4902/40000 [18:36<2:17:50,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4900, Total loss 81.723724, iteration time 0.239167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 5002/40000 [18:59<3:49:49,  2.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5000, Total loss 52.496445, iteration time 0.103832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 5102/40000 [19:22<2:15:52,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5100, Total loss 56.614189, iteration time 0.241461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 5202/40000 [19:45<2:18:10,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5200, Total loss 93.523422, iteration time 0.251094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 5302/40000 [20:07<2:15:15,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5300, Total loss 67.786697, iteration time 0.244226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▎        | 5402/40000 [20:30<2:14:35,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5400, Total loss 51.263859, iteration time 0.236355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 5502/40000 [20:53<2:13:03,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5500, Total loss 81.297386, iteration time 0.237618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 5602/40000 [21:16<2:14:33,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5600, Total loss 77.485214, iteration time 0.259334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 5702/40000 [21:38<2:12:43,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5700, Total loss 65.399040, iteration time 0.238080\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▍        | 5802/40000 [22:01<2:13:45,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5800, Total loss 77.356873, iteration time 0.238760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▍        | 5902/40000 [22:24<2:11:52,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5900, Total loss 79.610641, iteration time 0.235593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 6002/40000 [22:47<3:14:39,  2.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6000, Total loss 85.361610, iteration time 0.095567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 6102/40000 [23:10<2:12:29,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6100, Total loss 72.542984, iteration time 0.239195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 6202/40000 [23:33<2:10:11,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6200, Total loss 99.153488, iteration time 0.234835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 6302/40000 [23:55<2:10:17,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6300, Total loss 71.612411, iteration time 0.235656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 6402/40000 [24:18<2:11:15,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6400, Total loss 68.526871, iteration time 0.245173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▋        | 6502/40000 [24:41<2:10:04,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6500, Total loss 88.659073, iteration time 0.245777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 6602/40000 [25:04<2:09:35,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6600, Total loss 56.340637, iteration time 0.238552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 6702/40000 [25:26<2:10:52,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6700, Total loss 111.383659, iteration time 0.248721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 6802/40000 [25:49<2:07:42,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6800, Total loss 92.984863, iteration time 0.238152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 6902/40000 [26:12<2:07:35,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6900, Total loss 95.064453, iteration time 0.237861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 7002/40000 [26:35<3:39:44,  2.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7000, Total loss 106.084541, iteration time 0.103853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 7102/40000 [26:58<2:06:52,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7100, Total loss 117.329514, iteration time 0.229818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 7202/40000 [27:21<2:07:38,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7200, Total loss 99.308113, iteration time 0.237351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 7302/40000 [27:43<2:08:00,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7300, Total loss 110.602768, iteration time 0.240211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▊        | 7402/40000 [28:06<2:07:02,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7400, Total loss 64.019455, iteration time 0.239431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 7502/40000 [28:29<2:05:59,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7500, Total loss 51.818611, iteration time 0.240448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 7602/40000 [28:52<2:07:29,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7600, Total loss 66.712807, iteration time 0.248521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 7702/40000 [29:14<2:05:13,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7700, Total loss 119.937866, iteration time 0.236657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 7802/40000 [29:37<2:04:03,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7800, Total loss 61.171700, iteration time 0.237389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 7902/40000 [30:00<2:05:15,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7900, Total loss 52.633476, iteration time 0.238660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 8002/40000 [30:23<3:04:25,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8000, Total loss 66.848526, iteration time 0.099323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 8102/40000 [30:46<2:04:10,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8100, Total loss 107.534561, iteration time 0.235430\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 8202/40000 [31:08<2:03:14,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8200, Total loss 100.663803, iteration time 0.236523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 8302/40000 [31:31<2:02:18,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8300, Total loss 84.260117, iteration time 0.237783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 8402/40000 [31:54<2:04:03,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8400, Total loss 117.388908, iteration time 0.246680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██▏       | 8502/40000 [32:17<2:01:47,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8500, Total loss 71.769333, iteration time 0.236685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 8602/40000 [32:39<2:01:11,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8600, Total loss 107.827065, iteration time 0.237052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 8702/40000 [33:02<2:03:23,  4.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8700, Total loss 152.617142, iteration time 0.242337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 8802/40000 [33:25<2:00:11,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8800, Total loss 89.044830, iteration time 0.238173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 8902/40000 [33:48<2:01:22,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8900, Total loss 66.372826, iteration time 0.236705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 9002/40000 [34:11<3:28:19,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9000, Total loss 132.541153, iteration time 0.115783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 9102/40000 [34:34<1:59:25,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9100, Total loss 118.179939, iteration time 0.237157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 9202/40000 [34:57<1:58:47,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9200, Total loss 106.515923, iteration time 0.241896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 9302/40000 [35:19<2:00:28,  4.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9300, Total loss 180.582520, iteration time 0.235791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▎       | 9402/40000 [35:42<1:58:24,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9400, Total loss 47.404083, iteration time 0.236114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 9502/40000 [36:05<1:57:27,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9500, Total loss 116.499687, iteration time 0.236265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 9602/40000 [36:28<1:58:49,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9600, Total loss 90.575043, iteration time 0.240023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 9702/40000 [36:50<1:56:39,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9700, Total loss 54.128067, iteration time 0.241925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 9802/40000 [37:13<1:56:13,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9800, Total loss 138.051941, iteration time 0.235657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 9902/40000 [37:36<1:57:35,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9900, Total loss 151.827820, iteration time 0.239920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 10002/40000 [37:59<3:36:24,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10000, Total loss 92.714691, iteration time 0.108822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 10102/40000 [38:22<1:56:16,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10100, Total loss 148.415527, iteration time 0.231377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 10202/40000 [38:45<1:54:40,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10200, Total loss 73.214760, iteration time 0.235852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 10302/40000 [39:08<1:54:46,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10300, Total loss 66.505432, iteration time 0.235204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 10402/40000 [39:30<1:56:39,  4.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10400, Total loss 103.732178, iteration time 0.230792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▋       | 10502/40000 [39:53<1:54:22,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10500, Total loss 90.789230, iteration time 0.236264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 10602/40000 [40:16<1:53:59,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10600, Total loss 49.457283, iteration time 0.241551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 10702/40000 [40:38<1:54:24,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10700, Total loss 144.809158, iteration time 0.244074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 10802/40000 [41:01<1:53:40,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10800, Total loss 68.124283, iteration time 0.235677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 10902/40000 [41:24<1:53:26,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10900, Total loss 53.681175, iteration time 0.243179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 11002/40000 [41:48<3:14:27,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11000, Total loss 73.592079, iteration time 0.101164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 11102/40000 [42:10<1:51:20,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11100, Total loss 96.817413, iteration time 0.240860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 11202/40000 [42:33<1:50:51,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11200, Total loss 86.221756, iteration time 0.234702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 11302/40000 [42:56<1:52:51,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11300, Total loss 132.267517, iteration time 0.239508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▊       | 11402/40000 [43:19<1:50:36,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11400, Total loss 92.217903, iteration time 0.236128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 11502/40000 [43:41<1:51:31,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11500, Total loss 73.588120, iteration time 0.239594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 11602/40000 [44:04<1:51:57,  4.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11600, Total loss 105.795380, iteration time 0.247946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 11702/40000 [44:27<1:51:06,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11700, Total loss 157.014236, iteration time 0.241065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 11802/40000 [44:50<1:49:15,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11800, Total loss 170.414780, iteration time 0.243579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 11902/40000 [45:12<1:49:37,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11900, Total loss 162.678345, iteration time 0.234627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 12002/40000 [45:36<2:40:16,  2.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12000, Total loss 154.559113, iteration time 0.095380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 12102/40000 [45:58<1:48:47,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12100, Total loss 137.836151, iteration time 0.239300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 12202/40000 [46:21<1:49:19,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12200, Total loss 136.593597, iteration time 0.233598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 12302/40000 [46:44<1:47:46,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12300, Total loss 147.896927, iteration time 0.238690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 12402/40000 [47:06<1:46:55,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12400, Total loss 149.679138, iteration time 0.236651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███▏      | 12502/40000 [47:29<1:49:03,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12500, Total loss 167.267120, iteration time 0.245479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 12602/40000 [47:52<1:45:27,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12600, Total loss 151.684723, iteration time 0.240782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 12702/40000 [48:15<1:45:41,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12700, Total loss 149.770859, iteration time 0.239899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 12802/40000 [48:37<1:47:18,  4.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12800, Total loss 144.624039, iteration time 0.242434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 12902/40000 [49:00<1:44:19,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12900, Total loss 153.646301, iteration time 0.235232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 13002/40000 [49:23<2:35:23,  2.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13000, Total loss 160.098770, iteration time 0.098516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 13102/40000 [49:46<1:43:57,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13100, Total loss 150.226288, iteration time 0.237629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 13202/40000 [50:09<1:43:10,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13200, Total loss 157.488647, iteration time 0.235010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 13302/40000 [50:32<1:44:10,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13300, Total loss 153.030670, iteration time 0.237689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▎      | 13402/40000 [50:54<1:43:25,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13400, Total loss 156.222321, iteration time 0.242663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 13502/40000 [51:17<1:42:23,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13500, Total loss 150.037323, iteration time 0.234866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 13602/40000 [51:40<1:42:18,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13600, Total loss 155.878571, iteration time 0.239953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 13702/40000 [52:02<1:41:48,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13700, Total loss 151.892853, iteration time 0.238709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 13802/40000 [52:25<1:41:03,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13800, Total loss 170.864273, iteration time 0.234041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 13902/40000 [52:48<1:42:10,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13900, Total loss 183.908447, iteration time 0.241405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 14002/40000 [53:11<2:30:03,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14000, Total loss 154.846893, iteration time 0.096395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 14102/40000 [53:34<1:41:31,  4.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14100, Total loss 165.542526, iteration time 0.243828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 14202/40000 [53:57<1:42:21,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14200, Total loss 157.581543, iteration time 0.245763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 14302/40000 [54:19<1:39:27,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14300, Total loss 166.836411, iteration time 0.237076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 14402/40000 [54:42<1:38:50,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14400, Total loss 158.443115, iteration time 0.241874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▋      | 14502/40000 [55:05<1:40:32,  4.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14500, Total loss 165.637512, iteration time 0.250259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 14602/40000 [55:28<1:38:51,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14600, Total loss 163.113007, iteration time 0.236534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 14702/40000 [55:50<1:37:28,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14700, Total loss 215.083420, iteration time 0.239758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 14802/40000 [56:13<1:39:39,  4.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14800, Total loss 71.082466, iteration time 0.242603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 14902/40000 [56:36<1:36:58,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14900, Total loss 60.343845, iteration time 0.235643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 15002/40000 [56:59<2:23:20,  2.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15000, Total loss 84.234764, iteration time 0.095285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 15102/40000 [57:22<1:38:17,  4.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15100, Total loss 91.620132, iteration time 0.251218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 15202/40000 [57:45<1:36:40,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15200, Total loss 109.592674, iteration time 0.236212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 15302/40000 [58:08<1:36:24,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15300, Total loss 64.137924, iteration time 0.250713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▊      | 15402/40000 [58:30<1:36:20,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15400, Total loss 162.861160, iteration time 0.237625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 15502/40000 [58:53<1:34:51,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15500, Total loss 126.797127, iteration time 0.236989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 15602/40000 [59:16<1:35:21,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15600, Total loss 70.961105, iteration time 0.240182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 15702/40000 [59:39<1:36:00,  4.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15700, Total loss 1108.996826, iteration time 0.244985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|███▉      | 15802/40000 [1:00:01<1:33:41,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15800, Total loss 86.582527, iteration time 0.236611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|███▉      | 15902/40000 [1:00:24<1:34:02,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15900, Total loss 98.234512, iteration time 0.241433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 16002/40000 [1:00:48<2:39:52,  2.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16000, Total loss 71.438629, iteration time 0.107660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 16102/40000 [1:01:10<1:32:31,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16100, Total loss 138.945648, iteration time 0.243863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 16202/40000 [1:01:33<1:32:38,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16200, Total loss 287.744995, iteration time 0.236689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 16302/40000 [1:01:56<1:32:49,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16300, Total loss 169.426224, iteration time 0.235868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 16402/40000 [1:02:19<1:31:14,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16400, Total loss 189.952194, iteration time 0.238681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████▏     | 16502/40000 [1:02:41<1:30:02,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16500, Total loss 174.909271, iteration time 0.234065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 16602/40000 [1:03:04<1:30:06,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16600, Total loss 178.341003, iteration time 0.239259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 16702/40000 [1:03:27<1:29:59,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16700, Total loss 184.298798, iteration time 0.244132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 16802/40000 [1:03:49<1:30:20,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16800, Total loss 210.397552, iteration time 0.235781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 16902/40000 [1:04:12<1:30:35,  4.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16900, Total loss 152.063309, iteration time 0.238446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 17002/40000 [1:04:35<2:12:37,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17000, Total loss 186.473145, iteration time 0.096053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 17102/40000 [1:04:58<1:29:21,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17100, Total loss 189.067841, iteration time 0.252898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 17202/40000 [1:05:20<1:30:27,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17200, Total loss 187.995834, iteration time 0.247228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 17302/40000 [1:05:43<1:27:38,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17300, Total loss 178.230606, iteration time 0.234570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▎     | 17402/40000 [1:06:06<1:27:47,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17400, Total loss 183.333282, iteration time 0.234650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 17502/40000 [1:06:28<1:27:17,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17500, Total loss 173.672882, iteration time 0.233167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 17602/40000 [1:06:51<1:26:52,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17600, Total loss 204.696869, iteration time 0.235510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 17702/40000 [1:07:14<1:26:29,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17700, Total loss 182.594788, iteration time 0.246576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 17802/40000 [1:07:36<1:25:53,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17800, Total loss 175.469482, iteration time 0.241266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 17902/40000 [1:07:59<1:25:46,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17900, Total loss 184.616577, iteration time 0.233874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 18002/40000 [1:08:22<2:36:27,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18000, Total loss 184.925949, iteration time 0.104036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 18102/40000 [1:08:45<1:25:18,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18100, Total loss 188.882019, iteration time 0.249321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 18202/40000 [1:09:08<1:23:38,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18200, Total loss 182.457886, iteration time 0.237893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 18302/40000 [1:09:30<1:24:16,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18300, Total loss 180.546051, iteration time 0.238225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 18402/40000 [1:09:53<1:23:00,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18400, Total loss 190.535294, iteration time 0.238404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▋     | 18502/40000 [1:10:16<1:22:55,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18500, Total loss 200.262848, iteration time 0.234261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 18602/40000 [1:10:38<1:23:58,  4.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18600, Total loss 181.800156, iteration time 0.251006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 18702/40000 [1:11:01<1:22:33,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18700, Total loss 189.664185, iteration time 0.237022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 18802/40000 [1:11:24<1:22:07,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18800, Total loss 181.835205, iteration time 0.244052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 18902/40000 [1:11:46<1:21:59,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18900, Total loss 168.342575, iteration time 0.234261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 19002/40000 [1:12:09<1:57:53,  2.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19000, Total loss 199.268570, iteration time 0.093941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 19102/40000 [1:12:32<1:20:09,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19100, Total loss 195.018250, iteration time 0.233350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 19202/40000 [1:12:55<1:20:47,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19200, Total loss 182.373276, iteration time 0.235614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 19302/40000 [1:13:17<1:20:00,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19300, Total loss 189.964157, iteration time 0.234356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▊     | 19402/40000 [1:13:40<1:19:12,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19400, Total loss 194.100082, iteration time 0.242520\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 19502/40000 [1:14:03<1:19:40,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19500, Total loss 200.273148, iteration time 0.232102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 19602/40000 [1:14:25<1:19:39,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19600, Total loss 178.263794, iteration time 0.237522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 19702/40000 [1:14:48<1:18:17,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19700, Total loss 196.304413, iteration time 0.243052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|████▉     | 19802/40000 [1:15:11<1:19:24,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19800, Total loss 204.724167, iteration time 0.239987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|████▉     | 19902/40000 [1:15:33<1:18:05,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19900, Total loss 189.834412, iteration time 0.235184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 20002/40000 [1:15:57<1:54:16,  2.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20000, Total loss 207.295792, iteration time 0.095985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 20102/40000 [1:16:19<1:17:44,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20100, Total loss 205.970703, iteration time 0.241436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 20202/40000 [1:16:42<1:16:41,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20200, Total loss 201.280914, iteration time 0.234759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 20302/40000 [1:17:05<1:15:32,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20300, Total loss 189.182587, iteration time 0.236543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 20402/40000 [1:17:27<1:17:38,  4.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20400, Total loss 188.131226, iteration time 0.242912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████▏    | 20502/40000 [1:17:50<1:15:08,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20500, Total loss 191.883759, iteration time 0.232786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 20602/40000 [1:18:13<1:15:19,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20600, Total loss 180.347076, iteration time 0.238123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 20702/40000 [1:18:35<1:15:26,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20700, Total loss 191.082031, iteration time 0.237346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 20802/40000 [1:18:58<1:13:56,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20800, Total loss 234.632553, iteration time 0.233053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 20902/40000 [1:19:21<1:14:29,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20900, Total loss 212.362442, iteration time 0.244482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 21002/40000 [1:19:44<2:08:28,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21000, Total loss 186.148880, iteration time 0.099804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 21102/40000 [1:20:07<1:13:39,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21100, Total loss 189.408661, iteration time 0.234604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 21202/40000 [1:20:29<1:12:54,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21200, Total loss 193.686676, iteration time 0.237188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 21302/40000 [1:20:52<1:12:52,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21300, Total loss 198.130737, iteration time 0.232297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▎    | 21402/40000 [1:21:15<1:12:08,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21400, Total loss 184.925323, iteration time 0.240039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 21502/40000 [1:21:37<1:11:35,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21500, Total loss 217.164825, iteration time 0.233472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 21602/40000 [1:22:00<1:11:34,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21600, Total loss 207.304718, iteration time 0.234982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 21702/40000 [1:22:23<1:10:38,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21700, Total loss 202.748856, iteration time 0.233222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▍    | 21802/40000 [1:22:45<1:10:32,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21800, Total loss 186.944977, iteration time 0.234401\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▍    | 21902/40000 [1:23:08<1:10:04,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21900, Total loss 197.216934, iteration time 0.244787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 22002/40000 [1:23:31<2:00:37,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22000, Total loss 205.556030, iteration time 0.102317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 22102/40000 [1:23:54<1:10:00,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22100, Total loss 252.917709, iteration time 0.242299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 22202/40000 [1:24:17<1:09:46,  4.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22200, Total loss 203.243256, iteration time 0.244173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 22302/40000 [1:24:40<1:07:38,  4.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22300, Total loss 193.060272, iteration time 0.225783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 22402/40000 [1:25:02<1:07:29,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22400, Total loss 186.297348, iteration time 0.239145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▋    | 22502/40000 [1:25:25<1:09:11,  4.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22500, Total loss 207.015686, iteration time 0.234853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 22602/40000 [1:25:47<1:07:41,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22600, Total loss 213.496826, iteration time 0.234420\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 22702/40000 [1:26:10<1:06:10,  4.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22700, Total loss 209.451538, iteration time 0.242728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 22802/40000 [1:26:33<1:07:46,  4.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22800, Total loss 199.462189, iteration time 0.234916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 22902/40000 [1:26:55<1:05:52,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22900, Total loss 256.720795, iteration time 0.232318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 23002/40000 [1:27:19<1:53:49,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23000, Total loss 185.759979, iteration time 0.104937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 23102/40000 [1:27:41<1:05:40,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23100, Total loss 215.256821, iteration time 0.233466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 23202/40000 [1:28:04<1:04:56,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23200, Total loss 214.501923, iteration time 0.234781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 23302/40000 [1:28:27<1:04:53,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23300, Total loss 192.846466, iteration time 0.245230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▊    | 23402/40000 [1:28:49<1:04:13,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23400, Total loss 210.062286, iteration time 0.234886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 23502/40000 [1:29:12<1:04:12,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23500, Total loss 193.010483, iteration time 0.239156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 23602/40000 [1:29:35<1:04:29,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23600, Total loss 227.351944, iteration time 0.246318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 23702/40000 [1:29:57<1:02:42,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23700, Total loss 208.296021, iteration time 0.232617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|█████▉    | 23802/40000 [1:30:20<1:02:09,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23800, Total loss 225.530914, iteration time 0.232234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|█████▉    | 23902/40000 [1:30:43<1:02:32,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23900, Total loss 213.025696, iteration time 0.240066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 24002/40000 [1:31:06<1:31:52,  2.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24000, Total loss 202.020721, iteration time 0.092448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 24102/40000 [1:31:28<1:01:00,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24100, Total loss 212.662994, iteration time 0.228059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 24202/40000 [1:31:51<1:01:08,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24200, Total loss 212.702728, iteration time 0.239402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 24302/40000 [1:32:14<1:01:20,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24300, Total loss 194.582855, iteration time 0.233862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 24402/40000 [1:32:36<1:01:25,  4.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24400, Total loss 224.886078, iteration time 0.242545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████▏   | 24502/40000 [1:32:59<1:00:28,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24500, Total loss 216.757263, iteration time 0.237986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 24602/40000 [1:33:22<59:32,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24600, Total loss 204.083710, iteration time 0.240924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 24702/40000 [1:33:45<58:48,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24700, Total loss 212.339844, iteration time 0.236716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 24802/40000 [1:34:07<59:15,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24800, Total loss 204.325104, iteration time 0.244636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 24902/40000 [1:34:30<57:56,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24900, Total loss 227.194931, iteration time 0.233760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 25002/40000 [1:34:53<1:27:08,  2.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25000, Total loss 216.102844, iteration time 0.095966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 25102/40000 [1:35:16<58:14,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25100, Total loss 231.849823, iteration time 0.244421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 25202/40000 [1:35:38<58:09,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25200, Total loss 197.189423, iteration time 0.242904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 25302/40000 [1:36:01<56:31,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25300, Total loss 219.770905, iteration time 0.233084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 25402/40000 [1:36:24<56:27,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25400, Total loss 220.165070, iteration time 0.229814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 25502/40000 [1:36:46<55:59,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25500, Total loss 230.507965, iteration time 0.233922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 25602/40000 [1:37:09<55:47,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25600, Total loss 207.535614, iteration time 0.235638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 25702/40000 [1:37:31<54:50,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25700, Total loss 223.384094, iteration time 0.233905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▍   | 25802/40000 [1:37:54<55:01,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25800, Total loss 219.375336, iteration time 0.241164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▍   | 25902/40000 [1:38:17<54:55,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25900, Total loss 229.871704, iteration time 0.233901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 26002/40000 [1:38:40<1:33:14,  2.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26000, Total loss 226.501953, iteration time 0.100855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 26102/40000 [1:39:03<53:28,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26100, Total loss 220.718994, iteration time 0.235428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 26202/40000 [1:39:25<54:00,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26200, Total loss 205.127228, iteration time 0.240720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 26302/40000 [1:39:48<52:53,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26300, Total loss 229.030548, iteration time 0.234219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 26402/40000 [1:40:11<52:33,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26400, Total loss 217.772217, iteration time 0.233574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▋   | 26502/40000 [1:40:33<53:09,  4.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26500, Total loss 238.639420, iteration time 0.236840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 26602/40000 [1:40:56<51:38,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26600, Total loss 240.850327, iteration time 0.232473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 26702/40000 [1:41:19<51:03,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26700, Total loss 237.268631, iteration time 0.233142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 26802/40000 [1:41:41<51:33,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26800, Total loss 242.544220, iteration time 0.246878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 26902/40000 [1:42:04<50:38,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26900, Total loss 232.290070, iteration time 0.234416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 27002/40000 [1:42:27<1:15:30,  2.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27000, Total loss 237.468353, iteration time 0.093263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 27102/40000 [1:42:50<50:51,  4.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27100, Total loss 230.781952, iteration time 0.247886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 27202/40000 [1:43:12<49:09,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27200, Total loss 218.560760, iteration time 0.241525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 27302/40000 [1:43:35<48:41,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27300, Total loss 208.452942, iteration time 0.236084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▊   | 27402/40000 [1:43:58<49:09,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27400, Total loss 234.246704, iteration time 0.232933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 27502/40000 [1:44:20<48:15,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27500, Total loss 215.435394, iteration time 0.232116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 27602/40000 [1:44:43<48:33,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27600, Total loss 246.519714, iteration time 0.236419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 27702/40000 [1:45:06<47:55,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27700, Total loss 225.394302, iteration time 0.234792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|██████▉   | 27802/40000 [1:45:28<47:35,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27800, Total loss 230.803528, iteration time 0.246250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|██████▉   | 27902/40000 [1:45:51<46:54,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27900, Total loss 240.250290, iteration time 0.236202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 28002/40000 [1:46:15<1:45:37,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28000, Total loss 296.839203, iteration time 0.102054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 28102/40000 [1:46:38<45:55,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28100, Total loss 232.331253, iteration time 0.234660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 28202/40000 [1:47:00<46:03,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28200, Total loss 238.893005, iteration time 0.234397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 28302/40000 [1:47:23<46:05,  4.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28300, Total loss 226.786255, iteration time 0.246163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 28402/40000 [1:47:46<45:11,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28400, Total loss 226.559814, iteration time 0.240514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████▏  | 28502/40000 [1:48:09<44:33,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28500, Total loss 246.884888, iteration time 0.233507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 28602/40000 [1:48:31<44:08,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28600, Total loss 224.903229, iteration time 0.238910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 28702/40000 [1:48:54<43:53,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28700, Total loss 211.481964, iteration time 0.242214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 28802/40000 [1:49:17<43:12,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28800, Total loss 235.511230, iteration time 0.232653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 28902/40000 [1:49:39<43:28,  4.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28900, Total loss 231.645142, iteration time 0.229316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 29002/40000 [1:50:03<1:05:17,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29000, Total loss 207.296127, iteration time 0.096330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 29102/40000 [1:50:25<41:55,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29100, Total loss 224.044830, iteration time 0.234816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 29202/40000 [1:50:48<42:25,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29200, Total loss 278.278381, iteration time 0.250556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 29302/40000 [1:51:11<41:13,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29300, Total loss 247.870255, iteration time 0.233745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▎  | 29402/40000 [1:51:33<41:47,  4.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29400, Total loss 247.829224, iteration time 0.246438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 29502/40000 [1:51:56<40:28,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29500, Total loss 217.294662, iteration time 0.234661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 29602/40000 [1:52:19<40:17,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29600, Total loss 265.881836, iteration time 0.239615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 29702/40000 [1:52:41<40:18,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29700, Total loss 238.960175, iteration time 0.238176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▍  | 29802/40000 [1:53:04<39:34,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29800, Total loss 223.887329, iteration time 0.233017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▍  | 29902/40000 [1:53:27<39:08,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29900, Total loss 320.197327, iteration time 0.233182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 30002/40000 [1:53:50<1:14:15,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30000, Total loss 224.568253, iteration time 0.117054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 30102/40000 [1:54:13<37:54,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30100, Total loss 250.417603, iteration time 0.234518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 30202/40000 [1:54:36<38:06,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30200, Total loss 232.508636, iteration time 0.238976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 30302/40000 [1:54:58<37:51,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30300, Total loss 246.197067, iteration time 0.239120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 30402/40000 [1:55:21<36:52,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30400, Total loss 239.802994, iteration time 0.240190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▋  | 30502/40000 [1:55:44<37:00,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30500, Total loss 267.824402, iteration time 0.252737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 30602/40000 [1:56:06<36:22,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30600, Total loss 220.364655, iteration time 0.232911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 30702/40000 [1:56:29<35:55,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30700, Total loss 233.334808, iteration time 0.232348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 30802/40000 [1:56:52<36:17,  4.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30800, Total loss 231.686890, iteration time 0.239955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 30902/40000 [1:57:14<35:07,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30900, Total loss 223.781799, iteration time 0.239735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 31002/40000 [1:57:38<52:15,  2.87it/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31000, Total loss 256.092224, iteration time 0.094450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 31102/40000 [1:58:00<34:48,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31100, Total loss 258.097198, iteration time 0.241724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 31202/40000 [1:58:23<33:48,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31200, Total loss 233.200012, iteration time 0.231320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 31302/40000 [1:58:46<33:25,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31300, Total loss 258.188416, iteration time 0.232607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▊  | 31402/40000 [1:59:08<33:50,  4.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31400, Total loss 239.913513, iteration time 0.248321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 31502/40000 [1:59:31<32:32,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31500, Total loss 243.624023, iteration time 0.232352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 31602/40000 [1:59:53<33:27,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31600, Total loss 260.887512, iteration time 0.239347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 31702/40000 [2:00:16<32:15,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31700, Total loss 231.124344, iteration time 0.234121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|███████▉  | 31802/40000 [2:00:39<31:30,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31800, Total loss 254.964447, iteration time 0.234541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|███████▉  | 31902/40000 [2:01:01<31:31,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31900, Total loss 234.838928, iteration time 0.231323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 32002/40000 [2:01:25<46:37,  2.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32000, Total loss 255.205872, iteration time 0.096014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 32102/40000 [2:01:47<30:21,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32100, Total loss 237.945129, iteration time 0.226271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 32202/40000 [2:02:10<30:38,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32200, Total loss 272.317993, iteration time 0.242346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 32302/40000 [2:02:33<29:52,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32300, Total loss 264.194580, iteration time 0.235689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 32402/40000 [2:02:56<29:20,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32400, Total loss 259.964355, iteration time 0.233918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████▏ | 32502/40000 [2:03:18<29:01,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32500, Total loss 226.015167, iteration time 0.234256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 32602/40000 [2:03:41<28:25,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32600, Total loss 246.016174, iteration time 0.238197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 32702/40000 [2:04:04<28:24,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32700, Total loss 299.166046, iteration time 0.236497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 32802/40000 [2:04:27<27:54,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32800, Total loss 276.549042, iteration time 0.236871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 32902/40000 [2:04:49<27:33,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32900, Total loss 243.312408, iteration time 0.235525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 33002/40000 [2:05:13<43:26,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33000, Total loss 276.717010, iteration time 0.098107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 33102/40000 [2:05:35<26:46,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33100, Total loss 257.021118, iteration time 0.233412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 33202/40000 [2:05:58<26:26,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33200, Total loss 249.659164, iteration time 0.232153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 33302/40000 [2:06:21<26:01,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33300, Total loss 241.097382, iteration time 0.237361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▎ | 33402/40000 [2:06:44<25:39,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33400, Total loss 258.901367, iteration time 0.233152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 33502/40000 [2:07:07<25:03,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33500, Total loss 247.298904, iteration time 0.236541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 33602/40000 [2:07:29<25:07,  4.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33600, Total loss 240.969543, iteration time 0.247370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 33702/40000 [2:07:52<24:16,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33700, Total loss 243.893402, iteration time 0.235099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▍ | 33802/40000 [2:08:15<24:04,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33800, Total loss 295.900146, iteration time 0.239902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▍ | 33902/40000 [2:08:37<23:49,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33900, Total loss 248.842773, iteration time 0.237531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 34002/40000 [2:09:01<35:19,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34000, Total loss 231.945572, iteration time 0.097545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 34102/40000 [2:09:24<23:09,  4.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34100, Total loss 254.183823, iteration time 0.243257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 34202/40000 [2:09:46<22:23,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34200, Total loss 247.087891, iteration time 0.233589\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 34302/40000 [2:10:09<22:24,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34300, Total loss 246.667145, iteration time 0.243048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 34402/40000 [2:10:32<21:46,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34400, Total loss 294.412842, iteration time 0.239132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▋ | 34502/40000 [2:10:55<21:16,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34500, Total loss 283.438568, iteration time 0.235296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 34602/40000 [2:11:17<20:59,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34600, Total loss 268.569794, iteration time 0.238469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 34702/40000 [2:11:40<20:56,  4.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34700, Total loss 266.711609, iteration time 0.243774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 34802/40000 [2:12:03<20:06,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34800, Total loss 266.396881, iteration time 0.235360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 34902/40000 [2:12:26<19:55,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34900, Total loss 265.401672, iteration time 0.231278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 35002/40000 [2:12:49<34:38,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35000, Total loss 249.605927, iteration time 0.109180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 35102/40000 [2:13:12<18:54,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35100, Total loss 257.985657, iteration time 0.240375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 35202/40000 [2:13:35<18:49,  4.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35200, Total loss 272.539856, iteration time 0.241008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 35302/40000 [2:13:57<18:20,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35300, Total loss 244.720383, iteration time 0.232879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▊ | 35402/40000 [2:14:20<17:53,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35400, Total loss 268.609558, iteration time 0.237635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 35502/40000 [2:14:43<17:29,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35500, Total loss 307.687073, iteration time 0.233822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 35602/40000 [2:15:06<16:57,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35600, Total loss 285.442352, iteration time 0.234483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 35702/40000 [2:15:28<16:39,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35700, Total loss 259.795868, iteration time 0.232022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|████████▉ | 35802/40000 [2:15:51<16:36,  4.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35800, Total loss 266.166199, iteration time 0.238419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|████████▉ | 35902/40000 [2:16:14<15:49,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35900, Total loss 307.476318, iteration time 0.232938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 36002/40000 [2:16:37<23:48,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36000, Total loss 261.181274, iteration time 0.095647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 36102/40000 [2:17:00<15:10,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36100, Total loss 243.629257, iteration time 0.236601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 36202/40000 [2:17:23<14:37,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36200, Total loss 231.180023, iteration time 0.235440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 36302/40000 [2:17:45<14:21,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36300, Total loss 282.683594, iteration time 0.230103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 36402/40000 [2:18:08<13:55,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36400, Total loss 263.492767, iteration time 0.235023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████▏| 36502/40000 [2:18:31<13:31,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36500, Total loss 266.110413, iteration time 0.232779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 36602/40000 [2:18:54<13:09,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36600, Total loss 332.828217, iteration time 0.242337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 36702/40000 [2:19:16<12:41,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36700, Total loss 270.935425, iteration time 0.234577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 36802/40000 [2:19:39<12:20,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36800, Total loss 330.950439, iteration time 0.233659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 36902/40000 [2:20:02<12:14,  4.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36900, Total loss 295.116852, iteration time 0.239424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 37002/40000 [2:20:25<17:44,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37000, Total loss 297.224731, iteration time 0.096295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 37102/40000 [2:20:48<11:08,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37100, Total loss 289.134460, iteration time 0.232198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 37202/40000 [2:21:10<10:57,  4.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37200, Total loss 276.678192, iteration time 0.243912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 37302/40000 [2:21:33<10:27,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37300, Total loss 272.772614, iteration time 0.238134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▎| 37402/40000 [2:21:55<10:02,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37400, Total loss 275.001129, iteration time 0.233809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 37502/40000 [2:22:18<09:37,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37500, Total loss 251.423386, iteration time 0.236192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 37602/40000 [2:22:41<09:24,  4.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37600, Total loss 333.483521, iteration time 0.234170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 37702/40000 [2:23:04<08:59,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37700, Total loss 287.499176, iteration time 0.236069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▍| 37802/40000 [2:23:26<08:41,  4.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37800, Total loss 300.497375, iteration time 0.245306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▍| 37902/40000 [2:23:49<08:10,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37900, Total loss 287.628845, iteration time 0.233866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 38002/40000 [2:24:12<11:57,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38000, Total loss 260.342438, iteration time 0.094210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 38102/40000 [2:24:35<07:29,  4.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38100, Total loss 248.926041, iteration time 0.243790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 38202/40000 [2:24:58<06:58,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38200, Total loss 294.290039, iteration time 0.239795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 38302/40000 [2:25:20<06:33,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38300, Total loss 278.621643, iteration time 0.235316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 38402/40000 [2:25:43<06:13,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38400, Total loss 268.309021, iteration time 0.234066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▋| 38502/40000 [2:26:05<05:49,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38500, Total loss 271.743469, iteration time 0.231547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 38602/40000 [2:26:28<05:22,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38600, Total loss 275.250305, iteration time 0.232060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 38702/40000 [2:26:51<05:02,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38700, Total loss 291.657104, iteration time 0.238033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 38802/40000 [2:27:13<04:37,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38800, Total loss 289.956665, iteration time 0.237730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 38902/40000 [2:27:36<04:14,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38900, Total loss 272.182556, iteration time 0.225770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 39002/40000 [2:27:59<05:53,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39000, Total loss 291.813263, iteration time 0.096154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 39102/40000 [2:28:22<03:28,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39100, Total loss 287.149078, iteration time 0.238046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 39202/40000 [2:28:44<03:05,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39200, Total loss 276.416504, iteration time 0.232572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 39302/40000 [2:29:07<02:40,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39300, Total loss 273.309509, iteration time 0.234007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▊| 39402/40000 [2:29:30<02:19,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39400, Total loss 298.372253, iteration time 0.238801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 39502/40000 [2:29:53<01:56,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39500, Total loss 276.380249, iteration time 0.242182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 39602/40000 [2:30:15<01:33,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39600, Total loss 296.511353, iteration time 0.233811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 39702/40000 [2:30:38<01:09,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39700, Total loss 288.798615, iteration time 0.233227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 39802/40000 [2:31:01<00:46,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39800, Total loss 309.681152, iteration time 0.246232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 39902/40000 [2:31:23<00:22,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39900, Total loss 269.919373, iteration time 0.234306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40000/40000 [2:31:46<00:00,  4.39it/s]\n"
          ]
        }
      ]
    }
  ]
}