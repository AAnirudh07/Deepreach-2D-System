{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Install Dependencies"
      ],
      "metadata": {
        "id": "-dJSa8SGA3qE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO7q9J3U__wn",
        "outputId": "5b610b8e-5f6b-417f-8a2e-62b4c14194bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting configargparse\n",
            "  Downloading ConfigArgParse-1.7-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: configargparse\n",
            "Successfully installed configargparse-1.7\n"
          ]
        }
      ],
      "source": [
        "! pip install configargparse"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch torchvision torchaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR_iiXcpA836",
        "outputId": "e64f5245-ad8b-492b-a543-d97a371efa46"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Imports"
      ],
      "metadata": {
        "id": "87VPetxvCQlj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import time\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "from collections import OrderedDict\n",
        "\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.autograd import grad\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch import nn\n",
        "\n",
        "import wandb\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import scipy.io as spio\n",
        "\n",
        "from tqdm.autonotebook import tqdm\n",
        "from sklearn import svm\n",
        "\n",
        "import configargparse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmFWEDFvCUU5",
        "outputId": "bc8b29b7-e984-48de-c57a-396562ce2e44"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-7866da687f05>:29: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vS_tv_hGREd",
        "outputId": "b9165409-26fb-48bd-a197-97c63fd8975c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Connect to Google Drive"
      ],
      "metadata": {
        "id": "pviCCyEBCXEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\",force_remount=True)\n",
        "os.chdir(\"/content/drive/My Drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4rMTeMoDBUE",
        "outputId": "6a75c574-2374-4c98-fe69-9d584b08f2e6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Utils Code"
      ],
      "metadata": {
        "id": "0Qvuw3VGCaVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# uses model input and real boundary fn\n",
        "class ReachabilityDataset(Dataset):\n",
        "    def __init__(self, dynamics, numpoints, pretrain, pretrain_iters, tMin, tMax, counter_start, counter_end, num_src_samples, num_target_samples):\n",
        "        self.dynamics = dynamics\n",
        "        self.numpoints = numpoints\n",
        "        self.pretrain = pretrain\n",
        "        self.pretrain_counter = 0\n",
        "        self.pretrain_iters = pretrain_iters\n",
        "        self.tMin = tMin\n",
        "        self.tMax = tMax\n",
        "        self.counter = counter_start\n",
        "        self.counter_end = counter_end\n",
        "        self.num_src_samples = num_src_samples\n",
        "        self.num_target_samples = num_target_samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return 1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # uniformly sample domain and include coordinates where source is non-zero\n",
        "        model_states = torch.zeros(self.numpoints, self.dynamics.state_dim).uniform_(-1, 1)\n",
        "        if self.num_target_samples > 0:\n",
        "            target_state_samples = self.dynamics.sample_target_state(self.num_target_samples)\n",
        "            model_states[-self.num_target_samples:] = self.dynamics.coord_to_input(torch.cat((torch.zeros(self.num_target_samples, 1), target_state_samples), dim=-1))[:, 1:self.dynamics.state_dim+1]\n",
        "\n",
        "        if self.pretrain:\n",
        "            # only sample in time around the initial condition\n",
        "            times = torch.full((self.numpoints, 1), self.tMin)\n",
        "        else:\n",
        "            # slowly grow time values from start time\n",
        "            times = self.tMin + torch.zeros(self.numpoints, 1).uniform_(0, (self.tMax-self.tMin) * (self.counter / self.counter_end))\n",
        "            # make sure we always have training samples at the initial time\n",
        "            times[-self.num_src_samples:, 0] = self.tMin\n",
        "        model_coords = torch.cat((times, model_states), dim=1)\n",
        "        if self.dynamics.input_dim > self.dynamics.state_dim + 1: # temporary workaround for having to deal with dynamics classes for parametrized models with extra inputs\n",
        "            model_coords = torch.cat((model_coords, torch.zeros(self.numpoints, self.dynamics.input_dim - self.dynamics.state_dim - 1)), dim=1)\n",
        "\n",
        "        boundary_values = self.dynamics.boundary_fn(self.dynamics.input_to_coord(model_coords)[..., 1:])\n",
        "        if self.dynamics.loss_type == 'brat_hjivi':\n",
        "            reach_values = self.dynamics.reach_fn(self.dynamics.input_to_coord(model_coords)[..., 1:])\n",
        "            avoid_values = self.dynamics.avoid_fn(self.dynamics.input_to_coord(model_coords)[..., 1:])\n",
        "\n",
        "        if self.pretrain:\n",
        "            dirichlet_masks = torch.ones(model_coords.shape[0]) > 0\n",
        "        else:\n",
        "            # only enforce initial conditions around self.tMin\n",
        "            dirichlet_masks = (model_coords[:, 0] == self.tMin)\n",
        "\n",
        "        if self.pretrain:\n",
        "            self.pretrain_counter += 1\n",
        "        elif self.counter < self.counter_end:\n",
        "            self.counter += 1\n",
        "\n",
        "        if self.pretrain and self.pretrain_counter == self.pretrain_iters:\n",
        "            self.pretrain = False\n",
        "\n",
        "        if self.dynamics.loss_type == 'brt_hjivi':\n",
        "            return {'model_coords': model_coords}, {'boundary_values': boundary_values, 'dirichlet_masks': dirichlet_masks}\n",
        "        elif self.dynamics.loss_type == 'brat_hjivi':\n",
        "            return {'model_coords': model_coords}, {'boundary_values': boundary_values, 'reach_values': reach_values, 'avoid_values': avoid_values, 'dirichlet_masks': dirichlet_masks}\n",
        "        else:\n",
        "            raise NotImplementedError"
      ],
      "metadata": {
        "id": "9hX0elicCcHU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: I don't think jacobian is needed here; torch.autograd.grad should be enough, to compute gradients of a scalar value function w.r.t. inputs\n",
        "\n",
        "# batched jacobian\n",
        "# y: [..., N], x: [..., M] -> [..., N, M]\n",
        "def jacobian(y, x):\n",
        "    ''' jacobian of y wrt x '''\n",
        "    jac = torch.zeros(*y.shape, x.shape[-1]).to(y.device)\n",
        "    for i in range(y.shape[-1]):\n",
        "        # calculate dydx over batches for each feature value of y\n",
        "        y_flat = y[...,i].view(-1, 1)\n",
        "        jac[..., i, :] = grad(y_flat, x, torch.ones_like(y_flat), create_graph=True)[0]\n",
        "\n",
        "    status = 0\n",
        "    if torch.any(torch.isnan(jac)):\n",
        "        status = -1\n",
        "\n",
        "    return jac, status"
      ],
      "metadata": {
        "id": "TnNOsIvlClMZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Validator(ABC):\n",
        "    @abstractmethod\n",
        "    def validate(self, coords, values):\n",
        "        raise NotImplementedError\n",
        "\n",
        "class ValueThresholdValidator(Validator):\n",
        "    def __init__(self, v_min, v_max):\n",
        "        self.v_min = v_min\n",
        "        self.v_max = v_max\n",
        "\n",
        "    def validate(self, coords, values):\n",
        "        return (values >= self.v_min)*(values <= self.v_max)\n",
        "\n",
        "class MLPValidator(Validator):\n",
        "    def __init__(self, device, mlp, o_min, o_max, model, dynamics):\n",
        "        self.device = device\n",
        "        self.mlp = mlp\n",
        "        self.o_min = o_min\n",
        "        self.o_max = o_max\n",
        "        self.model = model\n",
        "        self.dynamics = dynamics\n",
        "\n",
        "    def validate(self, coords, values):\n",
        "        model_results = self.model({'coords': self.dynamics.coord_to_input(coords.to(self.device))})\n",
        "        inputs = torch.cat((coords[..., 1:].to(self.device), values[:, None].to(self.device)), dim=-1)\n",
        "        outputs = torch.sigmoid(self.mlp(inputs).squeeze())\n",
        "        return ((outputs >= self.o_min)*(outputs <=self.o_max)).to(device=values.device)\n",
        "\n",
        "class MLPConditionedValidator(Validator):\n",
        "    def __init__(self, device, mlp, o_levels, v_levels, model, dynamics):\n",
        "        self.device = device\n",
        "        self.mlp = mlp\n",
        "        self.o_levels = o_levels\n",
        "        self.v_levels = v_levels\n",
        "        self.model = model\n",
        "        self.dynamics = dynamics\n",
        "        assert len(self.o_levels) == len(self.v_levels) + 1\n",
        "\n",
        "    def validate(self, coords, values):\n",
        "        model_results = self.model({'coords': self.dynamics.coord_to_input(coords.to(self.device))})\n",
        "        inputs = torch.cat((coords[..., 1:].to(self.device), values[:, None].to(self.device)), dim=-1)\n",
        "        outputs = torch.sigmoid(self.mlp(inputs).squeeze(dim=-1)).to(device=values.device)\n",
        "        valids = torch.zeros_like(outputs)\n",
        "        for i in range(len(self.o_levels) - 1):\n",
        "            valids = torch.logical_or(\n",
        "                valids,\n",
        "                (outputs > self.o_levels[i])*(outputs <= self.o_levels[i+1])*(values >= self.v_levels[i][0])*(values <= self.v_levels[i][1])\n",
        "            )\n",
        "        return valids\n",
        "\n",
        "class MultiValidator(Validator):\n",
        "    def __init__(self, validators):\n",
        "        self.validators = validators\n",
        "\n",
        "    def validate(self, coords, values):\n",
        "        result = self.validators[0].validate(coords, values)\n",
        "        for i in range(len(self.validators)-1):\n",
        "            result = result * self.validators[i+1].validate(coords, values)\n",
        "        return result\n",
        "\n",
        "class SampleGenerator(ABC):\n",
        "    @abstractmethod\n",
        "    def sample(self, num_samples):\n",
        "        raise NotImplementedError\n",
        "\n",
        "class SliceSampleGenerator(SampleGenerator):\n",
        "    def __init__(self, dynamics, slices):\n",
        "        self.dynamics = dynamics\n",
        "        self.slices = slices\n",
        "        assert self.dynamics.state_dim == len(slices)\n",
        "\n",
        "    def sample(self, num_samples):\n",
        "        samples = torch.zeros(num_samples, self.dynamics.state_dim)\n",
        "        for dim in range(self.dynamics.state_dim):\n",
        "            if self.slices[dim] is None:\n",
        "                samples[:, dim].uniform_(*self.dynamics.state_test_range()[dim])\n",
        "            else:\n",
        "                samples[:, dim] = self.slices[dim]\n",
        "        return samples\n",
        "\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "# # get the tEarliest in [tMin:tMax:dt] at which the state is still valid\n",
        "# def get_tEarliest(device, model, dynamics, state, tMin, tMax, dt, validator):\n",
        "#     with torch.no_grad():\n",
        "#         tEarliest = torch.full(state.shape[:-1], tMin - 1)\n",
        "#         model_state = dynamics.normalize_state(state)\n",
        "\n",
        "#         times_to_try = torch.arange(tMin, tMax + dt, dt)\n",
        "#         for time_to_try in times_to_try:\n",
        "#             blank_idx = (tEarliest < tMin)\n",
        "#             time = torch.full((*state.shape[:-1], 1), time_to_try)\n",
        "#             model_time = dynamics.normalize_time(time)\n",
        "#             model_coord = torch.cat((model_time, model_state), dim=-1)[blank_idx]\n",
        "#             model_result = model({'coords': model_coord.to(device)})\n",
        "#             value = dynamics.output_to_value(output=model_result['model_out'][..., 0], state=state.to(device)).cpu()\n",
        "#             valid_idx = validator.validate(torch.cat((time, state), dim=-1), value)\n",
        "#             tMasked = tEarliest[blank_idx]\n",
        "#             tMasked[valid_idx] = time_to_try\n",
        "#             tEarliest[blank_idx] = tMasked\n",
        "#             if torch.all(tEarliest >= tMin):\n",
        "#                 break\n",
        "#         blank_idx = (tEarliest < tMin)\n",
        "#         if torch.any(blank_idx):\n",
        "#             print(str(torch.sum(blank_idx)), 'invalid states')\n",
        "#             tEarliest[blank_idx] = tMax\n",
        "#         return tEarliest\n",
        "\n",
        "def scenario_optimization(device, model, policy, dynamics, tMin, tMax, dt, set_type, control_type, scenario_batch_size, sample_batch_size, sample_generator, sample_validator, violation_validator, max_scenarios=None, max_samples=None, max_violations=None, tStart_generator=None):\n",
        "    rem = ((tMax-tMin) / dt)%1\n",
        "    e_tol = 1e-12\n",
        "    assert rem < e_tol or 1 - rem < e_tol, f'{tMax-tMin} is not divisible by {dt}'\n",
        "    assert tMax > tMin\n",
        "    assert set_type in ['BRS', 'BRT']\n",
        "    if set_type == 'BRS':\n",
        "        print('confirm correct calculation of true values of trajectories (batch_scenario_costs)')\n",
        "        raise NotImplementedError\n",
        "    assert control_type in ['value', 'ttr', 'init_ttr']\n",
        "    assert max_scenarios or max_samples or max_violations, 'one of the termination conditions must be used'\n",
        "    if max_scenarios:\n",
        "        assert (max_scenarios / scenario_batch_size)%1 == 0, 'max_scenarios is not divisible by scenario_batch_size'\n",
        "    if max_samples:\n",
        "        assert (max_samples / sample_batch_size)%1 == 0, 'max_samples is not divisible by sample_batch_size'\n",
        "\n",
        "    # accumulate scenarios\n",
        "    times = torch.zeros(0, )\n",
        "    states = torch.zeros(0, dynamics.state_dim)\n",
        "    values = torch.zeros(0, )\n",
        "    costs = torch.zeros(0, )\n",
        "    init_hams = torch.zeros(0, )\n",
        "    mean_hams = torch.zeros(0, )\n",
        "    mean_abs_hams = torch.zeros(0, )\n",
        "    max_abs_hams = torch.zeros(0, )\n",
        "    min_abs_hams = torch.zeros(0, )\n",
        "\n",
        "    num_scenarios = 0\n",
        "    num_samples = 0\n",
        "    num_violations = 0\n",
        "\n",
        "    pbar_pos = 0\n",
        "    if max_scenarios:\n",
        "        scenarios_pbar = tqdm(total=max_scenarios, desc='Scenarios', position=pbar_pos)\n",
        "        pbar_pos += 1\n",
        "    if max_samples:\n",
        "        samples_pbar = tqdm(total=max_samples, desc='Samples', position=pbar_pos)\n",
        "        pbar_pos += 1\n",
        "    if max_violations:\n",
        "        violations_pbar = tqdm(total=max_violations, desc='Violations', position=pbar_pos)\n",
        "        pbar_pos += 1\n",
        "\n",
        "    nums_valid_samples = []\n",
        "    while True:\n",
        "        if (max_scenarios and (num_scenarios >= max_scenarios)) or (max_violations and (num_violations >= max_violations)):\n",
        "            break\n",
        "\n",
        "        batch_scenario_times = torch.zeros(scenario_batch_size, )\n",
        "        batch_scenario_states = torch.zeros(scenario_batch_size, dynamics.state_dim)\n",
        "        batch_scenario_values = torch.zeros(scenario_batch_size, )\n",
        "\n",
        "        num_collected_scenarios = 0\n",
        "        while num_collected_scenarios < scenario_batch_size:\n",
        "            if max_samples and (num_samples >= max_samples):\n",
        "                break\n",
        "            # sample batch\n",
        "            if tStart_generator is not None:\n",
        "                batch_sample_times = tStart_generator(sample_batch_size)\n",
        "                # need to round to nearest dt\n",
        "                batch_sample_times = torch.round(batch_sample_times/dt)*dt\n",
        "            else:\n",
        "                batch_sample_times = torch.full((sample_batch_size, ), tMax)\n",
        "            batch_sample_states = dynamics.equivalent_wrapped_state(sample_generator.sample(sample_batch_size))\n",
        "            batch_sample_coords = torch.cat((batch_sample_times.unsqueeze(-1), batch_sample_states), dim=-1)\n",
        "\n",
        "            # validate batch\n",
        "            with torch.no_grad():\n",
        "                batch_sample_model_results = model({'coords': dynamics.coord_to_input(batch_sample_coords.to(device))})\n",
        "                batch_sample_values = dynamics.io_to_value(batch_sample_model_results['model_in'].detach(), batch_sample_model_results['model_out'].squeeze(dim=-1).detach())\n",
        "            batch_valid_sample_idxs = torch.where(sample_validator.validate(batch_sample_coords, batch_sample_values))[0].detach().cpu()\n",
        "\n",
        "            # store valid samples\n",
        "            num_valid_samples = len(batch_valid_sample_idxs)\n",
        "            start_idx = num_collected_scenarios\n",
        "            end_idx = min(start_idx + num_valid_samples, scenario_batch_size)\n",
        "            batch_scenario_times[start_idx:end_idx] = batch_sample_times[batch_valid_sample_idxs][:end_idx-start_idx]\n",
        "            batch_scenario_states[start_idx:end_idx] = batch_sample_states[batch_valid_sample_idxs][:end_idx-start_idx]\n",
        "            batch_scenario_values[start_idx:end_idx] = batch_sample_values[batch_valid_sample_idxs][:end_idx-start_idx]\n",
        "\n",
        "            # update counters\n",
        "            num_samples += sample_batch_size\n",
        "            if max_samples:\n",
        "                samples_pbar.update(sample_batch_size)\n",
        "            num_collected_scenarios += end_idx - start_idx\n",
        "            nums_valid_samples.append(num_valid_samples)\n",
        "        if max_samples and (num_samples >= max_samples):\n",
        "            break\n",
        "\n",
        "        # propagate scenarios\n",
        "        state_trajs = torch.zeros(scenario_batch_size, int((tMax-tMin)/dt + 1), dynamics.state_dim)\n",
        "        ctrl_trajs = torch.zeros(scenario_batch_size, int((tMax-tMin)/dt), dynamics.control_dim)\n",
        "        dstb_trajs = torch.zeros(scenario_batch_size, int((tMax-tMin)/dt), dynamics.disturbance_dim)\n",
        "        ham_trajs = torch.zeros(scenario_batch_size, int((tMax-tMin)/dt))\n",
        "\n",
        "        state_trajs[:, 0, :] = batch_scenario_states\n",
        "        for k in tqdm(range(int((tMax-tMin)/dt)), desc='Trajectory Propagation', position=pbar_pos, leave=False):\n",
        "            if control_type == 'value':\n",
        "                traj_time = tMax - k*dt\n",
        "                traj_times = torch.full((scenario_batch_size, ), traj_time)\n",
        "            # elif control_type == 'ttr':\n",
        "            #     traj_times = get_tEarliest(model=model, dynamics=dynamics, state=state_trajs[:, k], tMin=tMin, tMax=traj_time, dt=dt, validator=sample_validator)\n",
        "            # elif control_type == 'init_ttr':\n",
        "            #     if k == 0:\n",
        "            #         init_traj_times = get_tEarliest(model=model, dynamics=dynamics, state=state_trajs[:, k], tMin=tMin, tMax=traj_time, dt=dt, validator=sample_validator)\n",
        "            #     traj_times = torch.maximum(init_traj_times - k*dt, torch.tensor(tMin)) # check whether this is the best thing to do for init_ttr\n",
        "            traj_coords = torch.cat((traj_times.unsqueeze(-1), state_trajs[:, k]), dim=-1)\n",
        "            traj_policy_results = policy({'coords': dynamics.coord_to_input(traj_coords.to(device))})\n",
        "            traj_dvs = dynamics.io_to_dv(traj_policy_results['model_in'], traj_policy_results['model_out'].squeeze(dim=-1)).detach()\n",
        "\n",
        "            # TODO: I do not think there is actually any reason to store these trajs? Could save space by removing these.\n",
        "            ctrl_trajs[:, k] = dynamics.optimal_control(traj_coords[:, 1:].to(device), traj_dvs[..., 1:].to(device))\n",
        "            dstb_trajs[:, k] = dynamics.optimal_disturbance(traj_coords[:, 1:].to(device), traj_dvs[..., 1:].to(device))\n",
        "            ham_trajs[:, k] = dynamics.hamiltonian(traj_coords[:, 1:].to(device), traj_dvs[..., 1:].to(device))\n",
        "\n",
        "            if tStart_generator is not None: # freeze states whose start time has not been reached yet\n",
        "                is_frozen = batch_scenario_times < traj_times\n",
        "                is_unfrozen = torch.logical_not(is_frozen)\n",
        "                state_trajs[is_frozen, k+1] = state_trajs[is_frozen, k]\n",
        "                state_trajs[is_unfrozen, k+1] = dynamics.equivalent_wrapped_state(state_trajs[is_unfrozen, k].to(device) + dt*dynamics.dsdt(state_trajs[is_unfrozen, k].to(device), ctrl_trajs[is_unfrozen, k].to(device), dstb_trajs[is_unfrozen, k].to(device))).cpu()\n",
        "            else:\n",
        "                state_trajs[:, k+1] = dynamics.equivalent_wrapped_state(state_trajs[:, k].to(device) + dt*dynamics.dsdt(state_trajs[:, k].to(device), ctrl_trajs[:, k].to(device), dstb_trajs[:, k].to(device)))\n",
        "\n",
        "        # compute batch_scenario_costs\n",
        "        # TODO: need to handle the case of using tStart_generator when extending a trajectory by a frozen initial state will inadvertently affect cost computation (the min lx cost formulation is unaffected, but other cost formulations might care)\n",
        "        if set_type == 'BRT':\n",
        "            batch_scenario_costs = dynamics.cost_fn(state_trajs.to(device))\n",
        "        elif set_type == 'BRS':\n",
        "            if control_type == 'init_ttr': # is this correct for init_ttr?\n",
        "                batch_scenario_costs =  dynamics.boundary_fn(state_trajs.to(device))[:, (init_traj_times - tMin) / dt]\n",
        "            elif control_type == 'value':\n",
        "                batch_scenario_costs =  dynamics.boundary_fn(state_trajs.to(device))[:, -1]\n",
        "            else:\n",
        "                raise NotImplementedError # what is the correct thing to do for ttr?\n",
        "\n",
        "        # compute batch_scenario_init_hams, batch_scenario_mean_hams, batch_scenario_mean_abs_hams, batch_scenario_max_abs_hams, batch_scenario_min_abs_hams\n",
        "        batch_scenario_init_hams = ham_trajs[:, 0]\n",
        "        batch_scenario_mean_hams = torch.mean(ham_trajs, dim=-1)\n",
        "        batch_scenario_mean_abs_hams = torch.mean(torch.abs(ham_trajs), dim=-1)\n",
        "        batch_scenario_max_abs_hams = torch.max(torch.abs(ham_trajs), dim=-1).values\n",
        "        batch_scenario_min_abs_hams = torch.min(torch.abs(ham_trajs), dim=-1).values\n",
        "\n",
        "        # store scenarios\n",
        "        times = torch.cat((times, batch_scenario_times.cpu()), dim=0)\n",
        "        states = torch.cat((states, batch_scenario_states.cpu()), dim=0)\n",
        "        values = torch.cat((values, batch_scenario_values.cpu()), dim=0)\n",
        "        costs = torch.cat((costs, batch_scenario_costs.cpu()), dim=0)\n",
        "        init_hams = torch.cat((init_hams, batch_scenario_init_hams.cpu()), dim=0)\n",
        "        mean_hams = torch.cat((mean_hams, batch_scenario_mean_hams.cpu()), dim=0)\n",
        "        mean_abs_hams = torch.cat((mean_abs_hams, batch_scenario_mean_abs_hams.cpu()), dim=0)\n",
        "        max_abs_hams = torch.cat((max_abs_hams, batch_scenario_max_abs_hams.cpu()), dim=0)\n",
        "        min_abs_hams = torch.cat((min_abs_hams, batch_scenario_min_abs_hams.cpu()), dim=0)\n",
        "\n",
        "        # update counters\n",
        "        num_scenarios += scenario_batch_size\n",
        "        if max_scenarios:\n",
        "            scenarios_pbar.update(scenario_batch_size)\n",
        "        num_new_violations = int(torch.sum(violation_validator.validate(batch_scenario_states, batch_scenario_costs)))\n",
        "        num_violations += num_new_violations\n",
        "        if max_violations:\n",
        "            violations_pbar.update(num_new_violations)\n",
        "\n",
        "    if max_scenarios:\n",
        "        scenarios_pbar.close()\n",
        "    if max_samples:\n",
        "        samples_pbar.close()\n",
        "    if max_violations:\n",
        "        violations_pbar.close()\n",
        "\n",
        "    violations = violation_validator.validate(states, costs)\n",
        "\n",
        "    return {\n",
        "        'times': times,\n",
        "        'states': states,\n",
        "        'values': values,\n",
        "        'costs': costs,\n",
        "        'init_hams': init_hams,\n",
        "        'init_abs_hams': torch.abs(init_hams),\n",
        "        'mean_hams': mean_hams,\n",
        "        'mean_abs_hams': mean_abs_hams,\n",
        "        'max_abs_hams': max_abs_hams,\n",
        "        'min_abs_hams': min_abs_hams,\n",
        "        'violations': violations,\n",
        "        'valid_sample_fraction': torch.mean(torch.tensor(nums_valid_samples, dtype=float))/sample_batch_size,\n",
        "        'violation_rate': 0 if not num_scenarios else num_violations / num_scenarios,\n",
        "        'maxed_scenarios': (max_scenarios is not None) and num_scenarios >= max_scenarios,\n",
        "        'maxed_samples': (max_samples is not None) and num_samples >= max_samples,\n",
        "        'maxed_violations': (max_violations is not None) and num_violations >= max_violations,\n",
        "        'batch_state_trajs': None if (max_samples and (num_samples >= max_samples)) else state_trajs,\n",
        "    }\n",
        "\n",
        "def target_fraction(device, model, dynamics, t, sample_validator, target_validator, num_samples, batch_size):\n",
        "    with torch.no_grad():\n",
        "        states = torch.zeros(0, dynamics.state_dim)\n",
        "        values = torch.zeros(0, )\n",
        "\n",
        "        while len(states) < num_samples:\n",
        "            # sample batch\n",
        "            batch_times = torch.full((batch_size, 1), t)\n",
        "            batch_states = torch.zeros(batch_size, dynamics.state_dim)\n",
        "            for dim in range(dynamics.state_dim):\n",
        "                batch_states[:, dim].uniform_(*dynamics.state_test_range()[dim])\n",
        "            batch_states = dynamics.equivalent_wrapped_state(batch_states)\n",
        "            batch_coords = torch.cat((batch_times, batch_states), dim=-1)\n",
        "\n",
        "            # validate batch\n",
        "            batch_model_results = model({'coords': dynamics.coord_to_input(batch_coords.to(device))})\n",
        "            batch_values = dynamics.io_to_value(batch_model_results['model_in'], batch_model_results['model_out'].squeeze(dim=-1)).detach()\n",
        "            batch_valids = sample_validator.validate(batch_coords, batch_values).detach().cpu()\n",
        "\n",
        "            # store valid portion of batch\n",
        "            states = torch.cat((states, batch_states[batch_valids].cpu()), dim=0)\n",
        "            values = torch.cat((values, batch_values[batch_valids].cpu()), dim=0)\n",
        "\n",
        "        states = states[:num_samples]\n",
        "        values = values[:num_samples]\n",
        "        coords = torch.cat((torch.full((num_samples, 1), t), states), dim=-1)\n",
        "        valids = target_validator.validate(coords.to(device), values.to(device))\n",
        "    return torch.sum(valids) / num_samples\n",
        "\n",
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        s1 = int(2*input_size)\n",
        "        s2 = int(input_size)\n",
        "        s3 = int(input_size)\n",
        "        self.l1 = torch.nn.Linear(input_size, s1)\n",
        "        self.a1 = torch.nn.ReLU()\n",
        "        self.l2 = torch.nn.Linear(s1, s2)\n",
        "        self.a2 = torch.nn.ReLU()\n",
        "        self.l3 = torch.nn.Linear(s2, s3)\n",
        "        self.a3 = torch.nn.ReLU()\n",
        "        self.l4 = torch.nn.Linear(s3, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.l1(x)\n",
        "        x = self.a1(x)\n",
        "        x = self.l2(x)\n",
        "        x = self.a2(x)\n",
        "        x = self.l3(x)\n",
        "        x = self.a3(x)\n",
        "        x = self.l4(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "def sample_values(device, model, dynamics, t, num_samples, batch_size):\n",
        "    with torch.no_grad():\n",
        "        states = torch.zeros(0, dynamics.state_dim)\n",
        "        values = torch.zeros(0, )\n",
        "\n",
        "        while len(states) < num_samples:\n",
        "            # sample batch\n",
        "            batch_times = torch.full((batch_size, 1), t)\n",
        "            batch_states = torch.zeros(batch_size, dynamics.state_dim)\n",
        "            for dim in range(dynamics.state_dim):\n",
        "                batch_states[:, dim].uniform_(*dynamics.state_test_range()[dim])\n",
        "            batch_states = dynamics.equivalent_wrapped_state(batch_states)\n",
        "            batch_coords = torch.cat((batch_times, batch_states), dim=-1)\n",
        "\n",
        "            batch_model_results = model({'coords': dynamics.coord_to_input(batch_coords.to(device))})\n",
        "            batch_values = dynamics.io_to_value(batch_model_results['model_in'], batch_model_results['model_out'].squeeze(dim=-1)).detach()\n",
        "\n",
        "            # store batch\n",
        "            states = torch.cat((states, batch_states.cpu()), dim=0)\n",
        "            values = torch.cat((values, batch_values.cpu()), dim=0)\n",
        "\n",
        "        states = states[:num_samples]\n",
        "        values = values[:num_samples]\n",
        "        coords = torch.cat((torch.full((num_samples, 1), t), states), dim=-1)\n",
        "    return values\n"
      ],
      "metadata": {
        "id": "JT3KyjNnCqHc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# uses real units\n",
        "def init_brt_hjivi_loss(dynamics, minWith, dirichlet_loss_divisor):\n",
        "    def brt_hjivi_loss(state, value, dvdt, dvds, boundary_value, dirichlet_mask, output):\n",
        "        if torch.all(dirichlet_mask):\n",
        "            # pretraining loss\n",
        "            diff_constraint_hom = torch.Tensor([0])\n",
        "        else:\n",
        "            ham = dynamics.hamiltonian(state, dvds)\n",
        "            if minWith == 'zero':\n",
        "                ham = torch.clamp(ham, max=0.0)\n",
        "\n",
        "            diff_constraint_hom = dvdt - ham\n",
        "            if minWith == 'target':\n",
        "                diff_constraint_hom = torch.max(\n",
        "                    diff_constraint_hom, value - boundary_value)\n",
        "        dirichlet = value[dirichlet_mask] - boundary_value[dirichlet_mask]\n",
        "        if dynamics.deepreach_model == 'exact':\n",
        "            if torch.all(dirichlet_mask):\n",
        "                # pretraining\n",
        "                dirichlet = output.squeeze(dim=-1)[dirichlet_mask]-0.0\n",
        "            else:\n",
        "                return {'diff_constraint_hom': torch.abs(diff_constraint_hom).sum()}\n",
        "\n",
        "        return {'dirichlet': torch.abs(dirichlet).sum() / dirichlet_loss_divisor,\n",
        "                'diff_constraint_hom': torch.abs(diff_constraint_hom).sum()}\n",
        "\n",
        "    return brt_hjivi_loss\n",
        "def init_brat_hjivi_loss(dynamics, minWith, dirichlet_loss_divisor):\n",
        "    def brat_hjivi_loss(state, value, dvdt, dvds, boundary_value, reach_value, avoid_value, dirichlet_mask, output):\n",
        "        if torch.all(dirichlet_mask):\n",
        "            # pretraining loss\n",
        "            diff_constraint_hom = torch.Tensor([0])\n",
        "        else:\n",
        "            ham = dynamics.hamiltonian(state, dvds)\n",
        "            if minWith == 'zero':\n",
        "                ham = torch.clamp(ham, max=0.0)\n",
        "\n",
        "            diff_constraint_hom = dvdt - ham\n",
        "            if minWith == 'target':\n",
        "                diff_constraint_hom = torch.min(\n",
        "                    torch.max(diff_constraint_hom, value - reach_value), value + avoid_value)\n",
        "\n",
        "        dirichlet = value[dirichlet_mask] - boundary_value[dirichlet_mask]\n",
        "        if dynamics.deepreach_model == 'exact':\n",
        "            if torch.all(dirichlet_mask):\n",
        "                dirichlet = output.squeeze(dim=-1)[dirichlet_mask]-0.0\n",
        "            else:\n",
        "                return {'diff_constraint_hom': torch.abs(diff_constraint_hom).sum()}\n",
        "        return {'dirichlet': torch.abs(dirichlet).sum() / dirichlet_loss_divisor,\n",
        "                'diff_constraint_hom': torch.abs(diff_constraint_hom).sum()}\n",
        "    return brat_hjivi_loss"
      ],
      "metadata": {
        "id": "ojN0xTCfCx5p"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2020 Vincent Sitzmann\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE.\n",
        "\"\"\"\n",
        "\n",
        "class BatchLinear(nn.Linear):\n",
        "    '''A linear layer'''\n",
        "    __doc__ = nn.Linear.__doc__\n",
        "\n",
        "    def forward(self, input, params=None):\n",
        "        if params is None:\n",
        "            params = OrderedDict(self.named_parameters())\n",
        "\n",
        "        bias = params.get('bias', None)\n",
        "        weight = params['weight']\n",
        "\n",
        "        output = input.matmul(weight.permute(*[i for i in range(len(weight.shape) - 2)], -1, -2))\n",
        "        output += bias.unsqueeze(-2)\n",
        "        return output\n",
        "\n",
        "\n",
        "class Sine(nn.Module):\n",
        "    def __init(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of factor 30\n",
        "        return torch.sin(30 * input)\n",
        "\n",
        "\n",
        "class FCBlock(nn.Module):\n",
        "    '''A fully connected neural network.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, in_features, out_features, num_hidden_layers, hidden_features,\n",
        "                 outermost_linear=False, nonlinearity='relu', weight_init=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.first_layer_init = None\n",
        "\n",
        "        # Dictionary that maps nonlinearity name to the respective function, initialization, and, if applicable,\n",
        "        # special first-layer initialization scheme\n",
        "        nls_and_inits = {'sine':(Sine(), sine_init, first_layer_sine_init),\n",
        "                         'relu':(nn.ReLU(inplace=True), init_weights_normal, None),\n",
        "                         'sigmoid':(nn.Sigmoid(), init_weights_xavier, None),\n",
        "                         'tanh':(nn.Tanh(), init_weights_xavier, None),\n",
        "                         'selu':(nn.SELU(inplace=True), init_weights_selu, None),\n",
        "                         'softplus':(nn.Softplus(), init_weights_normal, None),\n",
        "                         'elu':(nn.ELU(inplace=True), init_weights_elu, None)}\n",
        "\n",
        "        nl, nl_weight_init, first_layer_init = nls_and_inits[nonlinearity]\n",
        "\n",
        "        if weight_init is not None:  # Overwrite weight init if passed\n",
        "            self.weight_init = weight_init\n",
        "        else:\n",
        "            self.weight_init = nl_weight_init\n",
        "\n",
        "        self.net = []\n",
        "        self.net.append(nn.Sequential(\n",
        "            BatchLinear(in_features, hidden_features), nl\n",
        "        ))\n",
        "\n",
        "        for i in range(num_hidden_layers):\n",
        "            self.net.append(nn.Sequential(\n",
        "                BatchLinear(hidden_features, hidden_features), nl\n",
        "            ))\n",
        "\n",
        "        if outermost_linear:\n",
        "            self.net.append(nn.Sequential(BatchLinear(hidden_features, out_features)))\n",
        "        else:\n",
        "            self.net.append(nn.Sequential(\n",
        "                BatchLinear(hidden_features, out_features), nl\n",
        "            ))\n",
        "\n",
        "        self.net = nn.Sequential(*self.net)\n",
        "        if self.weight_init is not None:\n",
        "            self.net.apply(self.weight_init)\n",
        "\n",
        "        if first_layer_init is not None: # Apply special initialization to first layer, if applicable.\n",
        "            self.net[0].apply(first_layer_init)\n",
        "\n",
        "    def forward(self, coords, params=None, **kwargs):\n",
        "        if params is None:\n",
        "            params = OrderedDict(self.named_parameters())\n",
        "\n",
        "        output = self.net(coords)\n",
        "        return output\n",
        "\n",
        "\n",
        "class SingleBVPNet(nn.Module):\n",
        "    '''A canonical representation network for a BVP.'''\n",
        "\n",
        "    def __init__(self, out_features=1, type='sine', in_features=2,\n",
        "                 mode='mlp', hidden_features=256, num_hidden_layers=3, **kwargs):\n",
        "        super().__init__()\n",
        "        self.mode = mode\n",
        "        self.net = FCBlock(in_features=in_features, out_features=out_features, num_hidden_layers=num_hidden_layers,\n",
        "                           hidden_features=hidden_features, outermost_linear=True, nonlinearity=type)\n",
        "        print(self)\n",
        "\n",
        "    def forward(self, model_input, params=None):\n",
        "        if params is None:\n",
        "            params = OrderedDict(self.named_parameters())\n",
        "\n",
        "        # Enables us to compute gradients w.r.t. coordinates\n",
        "        # TODO: should not need to .clone().detach().requires_grad_(True); instead, use .retain_grad() on input in calling script\n",
        "        # otherwise, .detach() removes input from the graph so grad cannot propagate back end-to-end, e.g., percept -> NN -> state estimation (input)\n",
        "        coords_org = model_input['coords'].clone().detach().requires_grad_(True)\n",
        "        coords = coords_org\n",
        "\n",
        "        output = self.net(coords)\n",
        "        return {'model_in': coords_org, 'model_out': output}\n",
        "\n",
        "\n",
        "########################\n",
        "# Initialization methods\n",
        "def init_weights_normal(m):\n",
        "    if type(m) == BatchLinear or type(m) == nn.Linear:\n",
        "        if hasattr(m, 'weight'):\n",
        "            nn.init.kaiming_normal_(m.weight, a=0.0, nonlinearity='relu', mode='fan_in')\n",
        "\n",
        "\n",
        "def init_weights_selu(m):\n",
        "    if type(m) == BatchLinear or type(m) == nn.Linear:\n",
        "        if hasattr(m, 'weight'):\n",
        "            num_input = m.weight.size(-1)\n",
        "            nn.init.normal_(m.weight, std=1 / math.sqrt(num_input))\n",
        "\n",
        "\n",
        "def init_weights_elu(m):\n",
        "    if type(m) == BatchLinear or type(m) == nn.Linear:\n",
        "        if hasattr(m, 'weight'):\n",
        "            num_input = m.weight.size(-1)\n",
        "            nn.init.normal_(m.weight, std=math.sqrt(1.5505188080679277) / math.sqrt(num_input))\n",
        "\n",
        "\n",
        "def init_weights_xavier(m):\n",
        "    if type(m) == BatchLinear or type(m) == nn.Linear:\n",
        "        if hasattr(m, 'weight'):\n",
        "            nn.init.xavier_normal_(m.weight)\n",
        "\n",
        "\n",
        "def sine_init(m):\n",
        "    with torch.no_grad():\n",
        "        if hasattr(m, 'weight'):\n",
        "            num_input = m.weight.size(-1)\n",
        "            # See supplement Sec. 1.5 for discussion of factor 30\n",
        "            m.weight.uniform_(-np.sqrt(6 / num_input) / 30, np.sqrt(6 / num_input) / 30)\n",
        "\n",
        "\n",
        "def first_layer_sine_init(m):\n",
        "    with torch.no_grad():\n",
        "        if hasattr(m, 'weight'):\n",
        "            num_input = m.weight.size(-1)\n",
        "            # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of factor 30\n",
        "            m.weight.uniform_(-1 / num_input, 1 / num_input)\n"
      ],
      "metadata": {
        "id": "_103N1sCCzv1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Dynamics Code"
      ],
      "metadata": {
        "id": "8YL1FjbYDcRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# during training, states will be sampled uniformly by each state dimension from the model-unit -1 to 1 range (for training stability),\n",
        "# which may or may not correspond to proper test ranges\n",
        "# note that coord refers to [time, *state], and input refers to whatever is fed directly to the model (often [time, *state, params])\n",
        "# in the future, code will need to be fixed to correctly handle parameterized models\n",
        "class Dynamics(ABC):\n",
        "    def __init__(self,\n",
        "    loss_type:str, set_mode:str,\n",
        "    state_dim:int, input_dim:int,\n",
        "    control_dim:int, disturbance_dim:int,\n",
        "    state_mean:list, state_var:list,\n",
        "    value_mean:float, value_var:float, value_normto:float,\n",
        "    deepreach_model:str):\n",
        "        self.loss_type = loss_type\n",
        "        self.set_mode = set_mode\n",
        "        self.state_dim = state_dim\n",
        "        self.input_dim = input_dim\n",
        "        self.control_dim = control_dim\n",
        "        self.disturbance_dim = disturbance_dim\n",
        "        self.state_mean = torch.tensor(state_mean)\n",
        "        self.state_var = torch.tensor(state_var)\n",
        "        self.value_mean = value_mean\n",
        "        self.value_var = value_var\n",
        "        self.value_normto = value_normto\n",
        "        self.deepreach_model = deepreach_model\n",
        "        assert self.loss_type in ['brt_hjivi', 'brat_hjivi'], f'loss type {self.loss_type} not recognized'\n",
        "        if self.loss_type == 'brat_hjivi':\n",
        "            assert callable(self.reach_fn) and callable(self.avoid_fn)\n",
        "        assert self.set_mode in ['reach', 'avoid'], f'set mode {self.set_mode} not recognized'\n",
        "        for state_descriptor in [self.state_mean, self.state_var]:\n",
        "            assert len(state_descriptor) == self.state_dim, 'state descriptor dimension does not equal state dimension, ' + str(len(state_descriptor)) + ' != ' + str(self.state_dim)\n",
        "\n",
        "    # ALL METHODS ARE BATCH COMPATIBLE\n",
        "\n",
        "    # MODEL-UNIT CONVERSIONS (TODO: refactor into separate model-unit conversion class?)\n",
        "\n",
        "    # convert model input to real coord\n",
        "    def input_to_coord(self, input):\n",
        "        coord = input.clone()\n",
        "        coord[..., 1:] = (input[..., 1:] * self.state_var.to(device=input.device)) + self.state_mean.to(device=input.device)\n",
        "        return coord\n",
        "\n",
        "    # convert real coord to model input\n",
        "    def coord_to_input(self, coord):\n",
        "        input = coord.clone()\n",
        "        input[..., 1:] = (coord[..., 1:] - self.state_mean.to(device=coord.device)) / self.state_var.to(device=coord.device)\n",
        "        return input\n",
        "\n",
        "    # convert model io to real value\n",
        "    def io_to_value(self, input, output):\n",
        "        if self.deepreach_model==\"diff\":\n",
        "            return (output * self.value_var / self.value_normto) + self.boundary_fn(self.input_to_coord(input)[..., 1:])\n",
        "        elif self.deepreach_model==\"exact\":\n",
        "            return (output * input[..., 0] * self.value_var / self.value_normto) + self.boundary_fn(self.input_to_coord(input)[..., 1:])\n",
        "        else:\n",
        "            return (output * self.value_var / self.value_normto) + self.value_mean\n",
        "\n",
        "    # convert model io to real dv\n",
        "    def io_to_dv(self, input, output):\n",
        "        dodi = jacobian(output.unsqueeze(dim=-1), input)[0].squeeze(dim=-2)\n",
        "\n",
        "        if self.deepreach_model==\"diff\":\n",
        "            dvdt = (self.value_var / self.value_normto) * dodi[..., 0]\n",
        "\n",
        "            dvds_term1 = (self.value_var / self.value_normto / self.state_var.to(device=dodi.device)) * dodi[..., 1:]\n",
        "            state = self.input_to_coord(input)[..., 1:]\n",
        "            dvds_term2 = jacobian(self.boundary_fn(state).unsqueeze(dim=-1), state)[0].squeeze(dim=-2)\n",
        "            dvds = dvds_term1 + dvds_term2\n",
        "        elif self.deepreach_model==\"exact\":\n",
        "            dvdt = (self.value_var / self.value_normto) * \\\n",
        "                (input[..., 0]*dodi[..., 0] + output)\n",
        "\n",
        "            dvds_term1 = (self.value_var / self.value_normto /\n",
        "                          self.state_var.to(device=dodi.device)) * dodi[..., 1:] * input[..., 0].unsqueeze(-1)\n",
        "            state = self.input_to_coord(input)[..., 1:]\n",
        "            dvds_term2 = jacobian(self.boundary_fn(\n",
        "                state).unsqueeze(dim=-1), state)[0].squeeze(dim=-2)\n",
        "            dvds = dvds_term1 + dvds_term2\n",
        "        else:\n",
        "            dvdt = (self.value_var / self.value_normto) * dodi[..., 0]\n",
        "            dvds = (self.value_var / self.value_normto / self.state_var.to(device=dodi.device)) * dodi[..., 1:]\n",
        "\n",
        "        return torch.cat((dvdt.unsqueeze(dim=-1), dvds), dim=-1)\n",
        "\n",
        "    # ALL FOLLOWING METHODS USE REAL UNITS\n",
        "\n",
        "    @abstractmethod\n",
        "    def state_test_range(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def equivalent_wrapped_state(self, state):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def dsdt(self, state, control, disturbance):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def boundary_fn(self, state):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def sample_target_state(self, num_samples):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def cost_fn(self, state_traj):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def hamiltonian(self, state, dvds):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def optimal_control(self, state, dvds):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def optimal_disturbance(self, state, dvds):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def plot_config(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "class ParameterizedVertDrone2D(Dynamics):\n",
        "    def __init__(self, gravity:float, input_multiplier_max:float, input_magnitude_max:float):\n",
        "        self.gravity = gravity                             # g\n",
        "        self.input_multiplier_max = input_multiplier_max   # k_max\n",
        "        self.input_magnitude_max = input_magnitude_max     # u_max\n",
        "        super().__init__(\n",
        "            loss_type='brt_hjivi', set_mode='avoid',\n",
        "            state_dim=3, input_dim=4, control_dim=1, disturbance_dim=0,\n",
        "            state_mean=[0, 1.5, self.input_multiplier_max/2], # v, z, k\n",
        "            state_var=[4, 2, self.input_multiplier_max/2],    # v, z, k\n",
        "            value_mean=0.25,\n",
        "            value_var=0.5,\n",
        "            value_normto=0.02,\n",
        "            deepreach_model=\"exact\",\n",
        "        )\n",
        "\n",
        "    def state_test_range(self):\n",
        "        return [\n",
        "            [-4, 4],                        # v\n",
        "            [-0.5, 3.5],                    # z\n",
        "            [0, self.input_multiplier_max], # k\n",
        "        ]\n",
        "\n",
        "    def equivalent_wrapped_state(self, state):\n",
        "        wrapped_state = torch.clone(state)\n",
        "        return wrapped_state\n",
        "\n",
        "    # ParameterizedVertDrone2D dynamics\n",
        "    # \\dot v = k*u - g\n",
        "    # \\dot z = v\n",
        "    # \\dot k = 0\n",
        "    def dsdt(self, state, control, disturbance):\n",
        "        dsdt = torch.zeros_like(state)\n",
        "        dsdt[..., 0] = state[..., 2]*control[..., 0] - self.gravity\n",
        "        dsdt[..., 1] = state[..., 0]\n",
        "        dsdt[..., 2] = 0\n",
        "        return dsdt\n",
        "\n",
        "    def boundary_fn(self, state):\n",
        "        return -torch.abs(state[..., 1] - 1.5) + 1.5\n",
        "\n",
        "    def sample_target_state(self, num_samples):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def cost_fn(self, state_traj):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def hamiltonian(self, state, dvds):\n",
        "        return state[..., 2]*torch.abs(dvds[..., 0]*self.input_magnitude_max) \\\n",
        "                - dvds[..., 0]*self.gravity \\\n",
        "                + dvds[..., 1]*state[..., 0]\n",
        "\n",
        "    def optimal_control(self, state, dvds):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def optimal_disturbance(self, state, dvds):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def plot_config(self):\n",
        "        return {\n",
        "            'state_slices': [0, 1.5, self.input_multiplier_max/2],\n",
        "            'state_labels': ['v', 'z', 'k'],\n",
        "            'x_axis_idx': 0,\n",
        "            'y_axis_idx': 1,\n",
        "            'z_axis_idx': 2,\n",
        "        }\n",
        "\n",
        "class Air3D(Dynamics):\n",
        "    def __init__(self, collisionR:float, velocity:float, omega_max:float, angle_alpha_factor:float):\n",
        "        self.collisionR = collisionR\n",
        "        self.velocity = velocity\n",
        "        self.omega_max = omega_max\n",
        "        self.angle_alpha_factor = angle_alpha_factor\n",
        "        super().__init__(\n",
        "            loss_type='brt_hjivi', set_mode='avoid',\n",
        "            state_dim=3, input_dim=4, control_dim=1, disturbance_dim=1,\n",
        "            state_mean=[0, 0, 0],\n",
        "            state_var=[1, 1, self.angle_alpha_factor*math.pi],\n",
        "            value_mean=0.25,\n",
        "            value_var=0.5,\n",
        "            value_normto=0.02,\n",
        "            deepreach_model=\"exact\",\n",
        "        )\n",
        "\n",
        "    def state_test_range(self):\n",
        "        return [\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-math.pi, math.pi],\n",
        "        ]\n",
        "\n",
        "    def equivalent_wrapped_state(self, state):\n",
        "        wrapped_state = torch.clone(state)\n",
        "        wrapped_state[..., 2] = (wrapped_state[..., 2] + math.pi) % (2*math.pi) - math.pi\n",
        "        return wrapped_state\n",
        "\n",
        "    # Air3D dynamics\n",
        "    # \\dot x    = -v + v \\cos \\psi + u y\n",
        "    # \\dot y    = v \\sin \\psi - u x\n",
        "    # \\dot \\psi = d - u\n",
        "    def dsdt(self, state, control, disturbance):\n",
        "        dsdt = torch.zeros_like(state)\n",
        "        dsdt[..., 0] = -self.velocity + self.velocity*torch.cos(state[..., 2]) + control[..., 0]*state[..., 1]\n",
        "        dsdt[..., 1] = self.velocity*torch.sin(state[..., 2]) - control[..., 0]*state[..., 0]\n",
        "        dsdt[..., 2] = disturbance[..., 0] - control[..., 0]\n",
        "        return dsdt\n",
        "\n",
        "    def boundary_fn(self, state):\n",
        "        return torch.norm(state[..., :2], dim=-1) - self.collisionR\n",
        "\n",
        "    def sample_target_state(self, num_samples):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def cost_fn(self, state_traj):\n",
        "        return torch.min(self.boundary_fn(state_traj), dim=-1).values\n",
        "\n",
        "    def hamiltonian(self, state, dvds):\n",
        "        ham = self.omega_max * torch.abs(dvds[..., 0] * state[..., 1] - dvds[..., 1] * state[..., 0] - dvds[..., 2])  # Control component\n",
        "        ham = ham - self.omega_max * torch.abs(dvds[..., 2])  # Disturbance component\n",
        "        ham = ham + (self.velocity * (torch.cos(state[..., 2]) - 1.0) * dvds[..., 0]) + (self.velocity * torch.sin(state[..., 2]) * dvds[..., 1])  # Constant component\n",
        "        return ham\n",
        "\n",
        "    def optimal_control(self, state, dvds):\n",
        "        det = dvds[..., 0]*state[..., 1] - dvds[..., 1]*state[..., 0]-dvds[..., 2]\n",
        "        return (self.omega_max * torch.sign(det))[..., None]\n",
        "\n",
        "    def optimal_disturbance(self, state, dvds):\n",
        "        return (-self.omega_max * torch.sign(dvds[..., 2]))[..., None]\n",
        "\n",
        "    def plot_config(self):\n",
        "        return {\n",
        "            'state_slices': [0, 0, 0],\n",
        "            'state_labels': ['x', 'y', 'theta'],\n",
        "            'x_axis_idx': 0,\n",
        "            'y_axis_idx': 1,\n",
        "            'z_axis_idx': 2,\n",
        "        }\n",
        "\n",
        "class Dubins3D(Dynamics):\n",
        "    def __init__(self, goalR:float, velocity:float, omega_max:float, angle_alpha_factor:float, set_mode:str, freeze_model: bool):\n",
        "        self.goalR = goalR\n",
        "        self.velocity = velocity\n",
        "        self.omega_max = omega_max\n",
        "        self.angle_alpha_factor = angle_alpha_factor\n",
        "        self.freeze_model = freeze_model\n",
        "        super().__init__(\n",
        "            loss_type='brt_hjivi', set_mode=set_mode,\n",
        "            state_dim=3, input_dim=4, control_dim=1, disturbance_dim=0,\n",
        "            state_mean=[0, 0, 0],\n",
        "            state_var=[1, 1, self.angle_alpha_factor*math.pi],\n",
        "            value_mean=0.25,\n",
        "            value_var=0.5,\n",
        "            value_normto=0.02,\n",
        "            deepreach_model=\"exact\"\n",
        "        )\n",
        "\n",
        "    def state_test_range(self):\n",
        "        return [\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-math.pi, math.pi],\n",
        "        ]\n",
        "\n",
        "    def equivalent_wrapped_state(self, state):\n",
        "        wrapped_state = torch.clone(state)\n",
        "        wrapped_state[..., 2] = (wrapped_state[..., 2] + math.pi) % (2*math.pi) - math.pi\n",
        "        return wrapped_state\n",
        "\n",
        "    # Dubins3D dynamics\n",
        "    # \\dot x    = v \\cos \\theta\n",
        "    # \\dot y    = v \\sin \\theta\n",
        "    # \\dot \\theta = u\n",
        "    def dsdt(self, state, control, disturbance):\n",
        "        if self.freeze_model:\n",
        "            raise NotImplementedError\n",
        "        dsdt = torch.zeros_like(state)\n",
        "        dsdt[..., 0] = self.velocity*torch.cos(state[..., 2])\n",
        "        dsdt[..., 1] = self.velocity*torch.sin(state[..., 2])\n",
        "        dsdt[..., 2] = control[..., 0]\n",
        "        return dsdt\n",
        "\n",
        "    def boundary_fn(self, state):\n",
        "        return torch.norm(state[..., :2], dim=-1) - self.goalR\n",
        "\n",
        "    def sample_target_state(self, num_samples):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def cost_fn(self, state_traj):\n",
        "        return torch.min(self.boundary_fn(state_traj), dim=-1).values\n",
        "\n",
        "    def hamiltonian(self, state, dvds):\n",
        "        if self.freeze_model:\n",
        "            raise NotImplementedError\n",
        "        if self.set_mode == 'reach':\n",
        "            return self.velocity*(torch.cos(state[..., 2]) * dvds[..., 0] + torch.sin(state[..., 2]) * dvds[..., 1]) - self.omega_max * torch.abs(dvds[..., 2])\n",
        "        elif self.set_mode == 'avoid':\n",
        "            return self.velocity*(torch.cos(state[..., 2]) * dvds[..., 0] + torch.sin(state[..., 2]) * dvds[..., 1]) + self.omega_max * torch.abs(dvds[..., 2])\n",
        "\n",
        "    def optimal_control(self, state, dvds):\n",
        "        if self.set_mode == 'reach':\n",
        "            return (-self.omega_max*torch.sign(dvds[..., 2]))[..., None]\n",
        "        elif self.set_mode == 'avoid':\n",
        "            return (self.omega_max*torch.sign(dvds[..., 2]))[..., None]\n",
        "\n",
        "    def optimal_disturbance(self, state, dvds):\n",
        "        return 0\n",
        "\n",
        "    def plot_config(self):\n",
        "        return {\n",
        "            'state_slices': [0, 0, 0],\n",
        "            'state_labels': ['x', 'y', r'$\\theta$'],\n",
        "            'x_axis_idx': 0,\n",
        "            'y_axis_idx': 1,\n",
        "            'z_axis_idx': 2,\n",
        "        }\n",
        "\n",
        "class Dubins4D(Dynamics):\n",
        "    def __init__(self, bound_mode:str):\n",
        "        self.vMin = 0.2\n",
        "        self.vMax = 14.8\n",
        "        self.collisionR = 1.5\n",
        "        self.bound_mode = bound_mode\n",
        "        assert self.bound_mode in ['v1', 'v2']\n",
        "\n",
        "        xMean = 0\n",
        "        yMean = 0\n",
        "        thetaMean = 0\n",
        "        vMean = 7.5\n",
        "        aMean = 0\n",
        "        oMean = 0\n",
        "\n",
        "        xVar = 10\n",
        "        yVar = 10\n",
        "        thetaVar = 1.2*math.pi\n",
        "        vVar = 7.5\n",
        "        aVar = 10\n",
        "        oVar = 3*math.pi if self.bound_mode == 'v1' else 2.0\n",
        "\n",
        "        super().__init__(\n",
        "            loss_type='brt_hjivi',\n",
        "            state_dim=14, input_dim=15,  control_dim=2, disturbance_dim=0,\n",
        "            state_mean=[xMean, yMean, thetaMean, vMean, xMean, yMean, aMean, aMean, oMean, oMean, aMean, aMean, oMean, oMean],\n",
        "            state_var=[xVar, yVar, thetaVar, vVar, xVar, yVar, aVar, aVar, oVar, oVar, aVar, aVar, oVar, oVar],\n",
        "            value_mean=13,\n",
        "            value_var=14,\n",
        "            value_normto=0.02,\n",
        "            deepreach_model=\"exact\",\n",
        "        )\n",
        "\n",
        "    def state_test_range(self):\n",
        "        return [\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-math.pi, math.pi],\n",
        "            [self.vMin, self.vMax],\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "        ]\n",
        "\n",
        "    def equivalent_wrapped_state(self, state):\n",
        "        wrapped_state = torch.clone(state)\n",
        "        wrapped_state[..., 2] = (wrapped_state[..., 2] + math.pi) % (2*math.pi) - math.pi\n",
        "        return wrapped_state\n",
        "\n",
        "    def boundary_fn(self, state):\n",
        "        return torch.norm(state[..., 0:2] - state[..., 4:6], dim=-1) - self.collisionR\n",
        "\n",
        "    def sample_target_state(self, num_samples):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def cost_fn(self, state_traj):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def dsdt(self, state, control, disturbance):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def hamiltonian(self, state, dvds):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def optimal_control(self, state, dvds):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def optimal_disturbance(self, state, dvds):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def plot_config(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "class NarrowPassage(Dynamics):\n",
        "    def __init__(self, avoid_fn_weight:float, avoid_only:bool):\n",
        "        self.L = 2.0\n",
        "\n",
        "        # # Target positions\n",
        "        self.goalX = [6.0, -6.0]\n",
        "        self.goalY = [-1.4, 1.4]\n",
        "\n",
        "        # State bounds\n",
        "        self.vMin = 0.001\n",
        "        self.vMax = 6.50\n",
        "        self.phiMin = -0.3*math.pi + 0.001\n",
        "        self.phiMax = 0.3*math.pi - 0.001\n",
        "\n",
        "        # Control bounds\n",
        "        self.aMin = -4.0\n",
        "        self.aMax = 2.0\n",
        "        self.psiMin = -3.0*math.pi\n",
        "        self.psiMax = 3.0*math.pi\n",
        "\n",
        "        # Lower and upper curb positions (in the y direction)\n",
        "        self.curb_positions = [-2.8, 2.8]\n",
        "\n",
        "        # Stranded car position\n",
        "        self.stranded_car_pos = [0.0, -1.8]\n",
        "\n",
        "        self.avoid_fn_weight = avoid_fn_weight\n",
        "\n",
        "        self.avoid_only = avoid_only\n",
        "\n",
        "        super().__init__(\n",
        "            loss_type='brt_hjivi' if self.avoid_only else 'brat_hjivi', set_mode='avoid' if self.avoid_only else 'reach',\n",
        "            state_dim=10, input_dim=11, control_dim=4, disturbance_dim=0,\n",
        "            # state = [x1, y1, th1, v1, phi1, x2, y2, th2, v2, phi2]\n",
        "            state_mean=[\n",
        "                0, 0, 0, 3, 0,\n",
        "                0, 0, 0, 3, 0\n",
        "            ],\n",
        "            state_var=[\n",
        "                8.0, 3.8, 1.2*math.pi, 4.0, 1.2*0.3*math.pi,\n",
        "                8.0, 3.8, 1.2*math.pi, 4.0, 1.2*0.3*math.pi,\n",
        "            ],\n",
        "            value_mean=0.25*8.0,\n",
        "            value_var=0.5*8.0,\n",
        "            value_normto=0.02,\n",
        "            deepreach_model=\"exact\",\n",
        "        )\n",
        "\n",
        "    def state_test_range(self):\n",
        "        return [\n",
        "            [-8, 8],\n",
        "            [-3.8, 3.8],\n",
        "            [-math.pi, math.pi],\n",
        "            [-1, 7],\n",
        "            [-0.3*math.pi, 0.3*math.pi],\n",
        "            [-8, 8],\n",
        "            [-3.8, 3.8],\n",
        "            [-math.pi, math.pi],\n",
        "            [-1, 7],\n",
        "            [-0.3*math.pi, 0.3*math.pi],\n",
        "        ]\n",
        "\n",
        "    def equivalent_wrapped_state(self, state):\n",
        "        wrapped_state = torch.clone(state)\n",
        "        wrapped_state[..., 2] = (wrapped_state[..., 2] + math.pi) % (2*math.pi) - math.pi\n",
        "        wrapped_state[..., 4] = (wrapped_state[..., 4] + math.pi) % (2*math.pi) - math.pi\n",
        "        wrapped_state[..., 7] = (wrapped_state[..., 7] + math.pi) % (2*math.pi) - math.pi\n",
        "        wrapped_state[..., 9] = (wrapped_state[..., 9] + math.pi) % (2*math.pi) - math.pi\n",
        "        return wrapped_state\n",
        "\n",
        "    # NarrowPassage dynamics\n",
        "    # \\dot x   = v * cos(th)\n",
        "    # \\dot y   = v * sin(th)\n",
        "    # \\dot th  = v * tan(phi) / L\n",
        "    # \\dot v   = u1\n",
        "    # \\dot phi = u2\n",
        "    # \\dot x   = ...\n",
        "    # \\dot y   = ...\n",
        "    # \\dot th  = ...\n",
        "    # \\dot v   = ...\n",
        "    # \\dot phi = ...\n",
        "    def dsdt(self, state, control, disturbance):\n",
        "        dsdt = torch.zeros_like(state)\n",
        "        dsdt[..., 0] = state[..., 3]*torch.cos(state[..., 2])\n",
        "        dsdt[..., 1] = state[..., 3]*torch.sin(state[..., 2])\n",
        "        dsdt[..., 2] = state[..., 3]*torch.tan(state[..., 4]) / self.L\n",
        "        dsdt[..., 3] = control[..., 0]\n",
        "        dsdt[..., 4] = control[..., 1]\n",
        "        dsdt[..., 5] = state[..., 8]*torch.cos(state[..., 7])\n",
        "        dsdt[..., 6] = state[..., 8]*torch.sin(state[..., 7])\n",
        "        dsdt[..., 7] = state[..., 8]*torch.tan(state[..., 9]) / self.L\n",
        "        dsdt[..., 8] = control[..., 2]\n",
        "        dsdt[..., 9] = control[..., 3]\n",
        "        return dsdt\n",
        "\n",
        "    def reach_fn(self, state):\n",
        "        if self.avoid_only:\n",
        "            raise RuntimeError\n",
        "        # vehicle 1\n",
        "        goal_tensor_R1 = torch.tensor([self.goalX[0], self.goalY[0]], device=state.device)\n",
        "        dist_R1 = torch.norm(state[..., 0:2] - goal_tensor_R1, dim=-1) - self.L\n",
        "        # vehicle 2\n",
        "        goal_tensor_R2 = torch.tensor([self.goalX[1], self.goalY[1]], device=state.device)\n",
        "        dist_R2 = torch.norm(state[..., 5:7] - goal_tensor_R2, dim=-1) - self.L\n",
        "        return torch.maximum(dist_R1, dist_R2)\n",
        "\n",
        "    def avoid_fn(self, state):\n",
        "        # distance from lower curb\n",
        "        dist_lc_R1 = state[..., 1] - self.curb_positions[0] - 0.5*self.L\n",
        "        dist_lc_R2 = state[..., 6] - self.curb_positions[0] - 0.5*self.L\n",
        "        dist_lc = torch.minimum(dist_lc_R1, dist_lc_R2)\n",
        "\n",
        "        # distance from upper curb\n",
        "        dist_uc_R1 = self.curb_positions[1] - state[..., 1] - 0.5*self.L\n",
        "        dist_uc_R2 = self.curb_positions[1] - state[..., 6] - 0.5*self.L\n",
        "        dist_uc = torch.minimum(dist_uc_R1, dist_uc_R2)\n",
        "\n",
        "        # distance from the stranded car\n",
        "        stranded_car_pos = torch.tensor(self.stranded_car_pos, device=state.device)\n",
        "        dist_stranded_R1 = torch.norm(state[..., 0:2] - stranded_car_pos, dim=-1) - self.L\n",
        "        dist_stranded_R2 = torch.norm(state[..., 5:7] - stranded_car_pos, dim=-1) - self.L\n",
        "        dist_stranded = torch.minimum(dist_stranded_R1, dist_stranded_R2)\n",
        "\n",
        "        # distance between the vehicles themselves\n",
        "        dist_R1R2 = torch.norm(state[..., 0:2] - state[..., 5:7], dim=-1) - self.L\n",
        "\n",
        "        return self.avoid_fn_weight * torch.min(torch.min(torch.min(dist_lc, dist_uc), dist_stranded), dist_R1R2)\n",
        "\n",
        "    def boundary_fn(self, state):\n",
        "        if self.avoid_only:\n",
        "            return self.avoid_fn(state)\n",
        "        else:\n",
        "            return torch.maximum(self.reach_fn(state), -self.avoid_fn(state))\n",
        "\n",
        "    def sample_target_state(self, num_samples):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def cost_fn(self, state_traj):\n",
        "        if self.avoid_only:\n",
        "            return torch.min(self.avoid_fn(state_traj), dim=-1).values\n",
        "        else:\n",
        "            # return min_t max{l(x(t)), max_k_up_to_t{-g(x(k))}}, where l(x) is reach_fn, g(x) is avoid_fn\n",
        "            reach_values = self.reach_fn(state_traj)\n",
        "            avoid_values = self.avoid_fn(state_traj)\n",
        "            return torch.min(torch.maximum(reach_values, torch.cummax(-avoid_values, dim=-1).values), dim=-1).values\n",
        "\n",
        "    def hamiltonian(self, state, dvds):\n",
        "        optimal_control = self.optimal_control(state, dvds)\n",
        "        return state[..., 3] * torch.cos(state[..., 2]) * dvds[..., 0] + \\\n",
        "               state[..., 3] * torch.sin(state[..., 2]) * dvds[..., 1] + \\\n",
        "               state[..., 3] * torch.tan(state[..., 4]) * dvds[..., 2] / self.L + \\\n",
        "               optimal_control[..., 0] * dvds[..., 3] + \\\n",
        "               optimal_control[..., 1] * dvds[..., 4] + \\\n",
        "               state[..., 8] * torch.cos(state[..., 7]) * dvds[..., 5] + \\\n",
        "               state[..., 8] * torch.sin(state[..., 7]) * dvds[..., 6] + \\\n",
        "               state[..., 8] * torch.tan(state[..., 9]) * dvds[..., 7] / self.L + \\\n",
        "               optimal_control[..., 2] * dvds[..., 8] + \\\n",
        "               optimal_control[..., 3] * dvds[..., 9]\n",
        "\n",
        "    def optimal_control(self, state, dvds):\n",
        "        a1_min = self.aMin * (state[..., 3] > self.vMin)\n",
        "        a1_max = self.aMax * (state[..., 3] < self.vMax)\n",
        "        psi1_min = self.psiMin * (state[..., 4] > self.phiMin)\n",
        "        psi1_max = self.psiMax * (state[..., 4] < self.phiMax)\n",
        "        a2_min = self.aMin * (state[..., 8] > self.vMin)\n",
        "        a2_max = self.aMax * (state[..., 8] < self.vMax)\n",
        "        psi2_min = self.psiMin * (state[..., 9] > self.phiMin)\n",
        "        psi2_max = self.psiMax * (state[..., 9] < self.phiMax)\n",
        "\n",
        "        if self.avoid_only:\n",
        "            a1 = torch.where(dvds[..., 3] < 0, a1_min, a1_max)\n",
        "            psi1 = torch.where(dvds[..., 4] < 0, psi1_min, psi1_max)\n",
        "            a2 = torch.where(dvds[..., 8] < 0, a2_min, a2_max)\n",
        "            psi2 = torch.where(dvds[..., 9] < 0, psi2_min, psi2_max)\n",
        "\n",
        "        else:\n",
        "            a1 = torch.where(dvds[..., 3] > 0, a1_min, a1_max)\n",
        "            psi1 = torch.where(dvds[..., 4] > 0, psi1_min, psi1_max)\n",
        "            a2 = torch.where(dvds[..., 8] > 0, a2_min, a2_max)\n",
        "            psi2 = torch.where(dvds[..., 9] > 0, psi2_min, psi2_max)\n",
        "\n",
        "        return torch.cat((a1[..., None], psi1[..., None], a2[..., None], psi2[..., None]), dim=-1)\n",
        "\n",
        "    def optimal_disturbance(self, state, dvds):\n",
        "        return 0\n",
        "\n",
        "    def plot_config(self):\n",
        "        return {\n",
        "            'state_slices': [\n",
        "                -6.0, -1.4, 0.0, 6.5, 0.0,\n",
        "                -6.0, 1.4, -math.pi, 0.0, 0.0\n",
        "            ],\n",
        "            'state_labels': [\n",
        "                r'$x_1$', r'$y_1$', r'$\\theta_1$', r'$v_1$', r'$\\phi_1$',\n",
        "                r'$x_2$', r'$y_2$', r'$\\theta_2$', r'$v_2$', r'$\\phi_2$',\n",
        "            ],\n",
        "            'x_axis_idx': 0,\n",
        "            'y_axis_idx': 1,\n",
        "            'z_axis_idx': 2,\n",
        "        }\n",
        "\n",
        "class ReachAvoidRocketLanding(Dynamics):\n",
        "    def __init__(self):\n",
        "        super().__init__(\n",
        "            loss_type='brat_hjivi', set_mode='reach',\n",
        "            state_dim=6, input_dim=7, control_dim=2, disturbance_dim=0,\n",
        "            state_mean=[0.0, 80.0, 0.0, 0.0, 0.0, 0.0],\n",
        "            state_var=[150.0, 70.0, 1.2*math.pi, 200.0, 200.0, 10.0],\n",
        "            value_mean=0.0,\n",
        "            value_var=1.0,\n",
        "            value_normto=0.02,\n",
        "            deepreach_model=\"exact\",\n",
        "        )\n",
        "\n",
        "    def state_test_range(self):\n",
        "        return [\n",
        "            [-150, 150],\n",
        "            [10, 150],\n",
        "            [-math.pi, math.pi],\n",
        "            [-200, 200],\n",
        "            [-200, 200],\n",
        "            [-10, 10],\n",
        "        ]\n",
        "\n",
        "    def equivalent_wrapped_state(self, state):\n",
        "        wrapped_state = torch.clone(state)\n",
        "        wrapped_state[..., 2] = (wrapped_state[..., 2] + math.pi) % (2*math.pi) - math.pi\n",
        "        return wrapped_state\n",
        "\n",
        "    # \\dot x = v_x\n",
        "    # \\dot y = v_y\n",
        "    # \\dot th = w\n",
        "    # \\dot v_x = u1 * cos(th) - u2 sin(th)\n",
        "    # \\dot v_y = u1 * sin(th) + u2 cos(th) - 9.81\n",
        "    # \\dot w = 0.3 * u1\n",
        "    def dsdt(self, state, control, disturbance):\n",
        "        dsdt = torch.zeros_like(state)\n",
        "        dsdt[..., 0] = state[..., 3]\n",
        "        dsdt[..., 1] = state[..., 4]\n",
        "        dsdt[..., 2] = state[..., 5]\n",
        "        dsdt[..., 3] = control[..., 0]*torch.cos(state[..., 2]) - control[..., 1]*torch.sin(state[..., 2])\n",
        "        dsdt[..., 4] = control[..., 0]*torch.sin(state[..., 2]) + control[..., 1]*torch.cos(state[..., 2]) - 9.81\n",
        "        dsdt[..., 5] = 0.3*control[..., 0]\n",
        "        return dsdt\n",
        "\n",
        "    def reach_fn(self, state):\n",
        "        # Only target set in the xy direction\n",
        "        # Target set position in x direction\n",
        "        dist_x = torch.abs(state[..., 0]) - 20.0 #[-20, 150] boundary_fn range\n",
        "\n",
        "        # Target set position in y direction\n",
        "        dist_y = state[..., 1] - 20.0  #[-10, 130] boundary_fn range\n",
        "\n",
        "        # First compute the target function as you normally would but then normalize it later.\n",
        "        max_dist = torch.max(dist_x, dist_y)\n",
        "        return torch.where((max_dist >= 0), max_dist/150.0, max_dist/10.0)\n",
        "\n",
        "    def avoid_fn(self, state):\n",
        "        # distance to floor\n",
        "        dist_y = state[..., 1]\n",
        "\n",
        "        # distance to wall\n",
        "        wall_left = -30\n",
        "        wall_right = -20\n",
        "        wall_bottom = 0\n",
        "        wall_top = 100\n",
        "        dist_left = wall_left - state[..., 0]\n",
        "        dist_right = state[..., 0] - wall_right\n",
        "        dist_bottom = wall_bottom - state[..., 1]\n",
        "        dist_top = state[..., 1] - wall_top\n",
        "        dist_wall_x = torch.max(dist_left, dist_right)\n",
        "        dist_wall_y = torch.max(dist_bottom, dist_top)\n",
        "        dist_wall = torch.norm(torch.cat((torch.max(torch.tensor(0), dist_wall_x).unsqueeze(-1), torch.max(torch.tensor(0), dist_wall_y).unsqueeze(-1)), dim=-1), dim=-1) + torch.min(torch.tensor(0), torch.max(dist_wall_x, dist_wall_y))\n",
        "\n",
        "        return torch.min(dist_y, dist_wall)\n",
        "\n",
        "    def boundary_fn(self, state):\n",
        "        return torch.maximum(self.reach_fn(state), -self.avoid_fn(state))\n",
        "\n",
        "    def sample_target_state(self, num_samples):\n",
        "        target_state_range = self.state_test_range()\n",
        "        target_state_range[0] = [-20, 20] # y in [-20, 20]\n",
        "        target_state_range[1] = [10, 20]  # z in [10, 20]\n",
        "        target_state_range = torch.tensor(target_state_range)\n",
        "        return target_state_range[:, 0] + torch.rand(num_samples, self.state_dim)*(target_state_range[:, 1] - target_state_range[:, 0])\n",
        "\n",
        "    def cost_fn(self, state_traj):\n",
        "        # return min_t max{l(x(t)), max_k_up_to_t{-g(x(k))}}, where l(x) is reach_fn, g(x) is avoid_fn\n",
        "        reach_values = self.reach_fn(state_traj)\n",
        "        avoid_values = self.avoid_fn(state_traj)\n",
        "        return torch.min(torch.maximum(reach_values, torch.cummax(-avoid_values, dim=-1).values), dim=-1).values\n",
        "\n",
        "    def hamiltonian(self, state, dvds):\n",
        "        # Control Hamiltonian\n",
        "        u1_coeff = dvds[..., 3] * torch.cos(state[..., 2]) + dvds[..., 4] * torch.sin(state[..., 2]) + 0.3 * dvds[..., 5]\n",
        "        u2_coeff = -dvds[..., 3] * torch.sin(state[..., 2]) + dvds[..., 4] * torch.cos(state[..., 2])\n",
        "        ham_ctrl = -250.0 * torch.sqrt(u1_coeff * u1_coeff + u2_coeff * u2_coeff)\n",
        "        # Constant Hamiltonian\n",
        "        ham_constant = dvds[..., 0] * state[..., 3] + dvds[..., 1] * state[..., 4] + \\\n",
        "                      dvds[..., 2] * state[..., 5]  - dvds[..., 4] * 9.81\n",
        "        # Compute the Hamiltonian\n",
        "        ham_vehicle = ham_ctrl + ham_constant\n",
        "        return ham_vehicle\n",
        "\n",
        "    def optimal_control(self, state, dvds):\n",
        "        u1_coeff = dvds[..., 3] * torch.cos(state[..., 2]) + dvds[..., 4] * torch.sin(state[..., 2]) + 0.3 * dvds[..., 5]\n",
        "        u2_coeff = -dvds[..., 3] * torch.sin(state[..., 2]) + dvds[..., 4] * torch.cos(state[..., 2])\n",
        "        opt_angle = torch.atan2(u2_coeff, u1_coeff) + math.pi\n",
        "        return torch.cat((250.0 * torch.cos(opt_angle)[..., None], 250.0 * torch.sin(opt_angle)[..., None]), dim=-1)\n",
        "\n",
        "    def optimal_disturbance(self, state, dvds):\n",
        "        return 0\n",
        "\n",
        "    def plot_config(self):\n",
        "        return {\n",
        "            'state_slices': [-100, 120, 0, 150, -5, 0.0],\n",
        "            'state_labels': ['x', 'y', r'$\\theta$', r'$v_x$', r'$v_y$', r'$\\omega'],\n",
        "            'x_axis_idx': 0,\n",
        "            'y_axis_idx': 1,\n",
        "            'z_axis_idx': 4,\n",
        "        }\n",
        "\n",
        "class RocketLanding(Dynamics):\n",
        "    def __init__(self):\n",
        "        super().__init__(\n",
        "            loss_type='brt_hjivi', set_mode='reach',\n",
        "            state_dim=6, input_dim=8, control_dim=2, disturbance_dim=0,\n",
        "            state_mean=[0.0, 80.0, 0.0, 0.0, 0.0, 0.0],\n",
        "            state_var=[150.0, 70.0, 1.2*math.pi, 200.0, 200.0, 10.0],\n",
        "            value_mean=0.0,\n",
        "            value_var=1.0,\n",
        "            value_normto=0.02,\n",
        "            deepreach_model=\"exact\",\n",
        "        )\n",
        "\n",
        "    # convert model input to real coord\n",
        "    def input_to_coord(self, input):\n",
        "        input = input[..., :-1]\n",
        "        coord = input.clone()\n",
        "        coord[..., 1:] = (input[..., 1:] * self.state_var.to(device=input.device)) + self.state_mean.to(device=input.device)\n",
        "        return coord\n",
        "\n",
        "    # convert real coord to model input\n",
        "    def coord_to_input(self, coord):\n",
        "        input = coord.clone()\n",
        "        input[..., 1:] = (coord[..., 1:] - self.state_mean.to(device=coord.device)) / self.state_var.to(device=coord.device)\n",
        "        input = torch.cat((input, torch.zeros((*input.shape[:-1], 1), device=input.device)), dim=-1)\n",
        "        return input\n",
        "\n",
        "    # convert model io to real value\n",
        "    def io_to_value(self, input, output):\n",
        "        if self.deepreach_model==\"diff\":\n",
        "            return (output * self.value_var / self.value_normto) + self.boundary_fn(self.input_to_coord(input)[..., 1:])\n",
        "        else:\n",
        "            return (output * self.value_var / self.value_normto) + self.value_mean\n",
        "\n",
        "    # convert model io to real dv\n",
        "    def io_to_dv(self, input, output):\n",
        "        dodi = jacobian(output.unsqueeze(dim=-1), input)[0].squeeze(dim=-2)[..., :-1]\n",
        "\n",
        "        if self.deepreach_model==\"diff\":\n",
        "            dvdt = (self.value_var / self.value_normto) * dodi[..., 0]\n",
        "\n",
        "            dvds_term1 = (self.value_var / self.value_normto / self.state_var.to(device=dodi.device)) * dodi[..., 1:]\n",
        "            state = self.input_to_coord(input)[..., 1:]\n",
        "            dvds_term2 = jacobian(self.boundary_fn(state).unsqueeze(dim=-1), state)[0].squeeze(dim=-2)\n",
        "            dvds = dvds_term1 + dvds_term2\n",
        "\n",
        "        else:\n",
        "            dvdt = (self.value_var / self.value_normto) * dodi[..., 0]\n",
        "            dvds = (self.value_var / self.value_normto / self.state_var.to(device=dodi.device)) * dodi[..., 1:]\n",
        "\n",
        "        return torch.cat((dvdt.unsqueeze(dim=-1), dvds), dim=-1)\n",
        "\n",
        "\n",
        "    def state_test_range(self):\n",
        "        return [\n",
        "            [-150, 150],\n",
        "            [10, 150],\n",
        "            [-math.pi, math.pi],\n",
        "            [-200, 200],\n",
        "            [-200, 200],\n",
        "            [-10, 10],\n",
        "        ]\n",
        "\n",
        "    def equivalent_wrapped_state(self, state):\n",
        "        wrapped_state = torch.clone(state)\n",
        "        wrapped_state[..., 2] = (wrapped_state[..., 2] + math.pi) % (2*math.pi) - math.pi\n",
        "        return wrapped_state\n",
        "\n",
        "    # \\dot x = v_x\n",
        "    # \\dot y = v_y\n",
        "    # \\dot th = w\n",
        "    # \\dot v_x = u1 * cos(th) - u2 sin(th)\n",
        "    # \\dot v_y = u1 * sin(th) + u2 cos(th) - 9.81\n",
        "    # \\dot w = 0.3 * u1\n",
        "    def dsdt(self, state, control, disturbance):\n",
        "        dsdt = torch.zeros_like(state)\n",
        "        dsdt[..., 0] = state[..., 3]\n",
        "        dsdt[..., 1] = state[..., 4]\n",
        "        dsdt[..., 2] = state[..., 5]\n",
        "        dsdt[..., 3] = control[..., 0]*torch.cos(state[..., 2]) - control[..., 1]*torch.sin(state[..., 2])\n",
        "        dsdt[..., 4] = control[..., 0]*torch.sin(state[..., 2]) + control[..., 1]*torch.cos(state[..., 2]) - 9.81\n",
        "        dsdt[..., 5] = 0.3*control[..., 0]\n",
        "        return dsdt\n",
        "\n",
        "    def boundary_fn(self, state):\n",
        "        # Only target set in the yz direction\n",
        "        # Target set position in y direction\n",
        "        dist_y = torch.abs(state[..., 0]) - 20.0 #[-20, 150] boundary_fn range\n",
        "\n",
        "        # Target set position in z direction\n",
        "        dist_z = state[..., 1] - 20.0  #[-10, 130] boundary_fn range\n",
        "\n",
        "        # First compute the l(x) as you normally would but then normalize it later.\n",
        "        lx = torch.max(dist_y, dist_z)\n",
        "        return torch.where((lx >= 0), lx/150.0, lx/10.0)\n",
        "\n",
        "    def sample_target_state(self, num_samples):\n",
        "        target_state_range = self.state_test_range()\n",
        "        target_state_range[0] = [-20, 20] # y in [-20, 20]\n",
        "        target_state_range[1] = [10, 20]  # z in [10, 20]\n",
        "        target_state_range = torch.tensor(target_state_range)\n",
        "        return target_state_range[:, 0] + torch.rand(num_samples, self.state_dim)*(target_state_range[:, 1] - target_state_range[:, 0])\n",
        "\n",
        "    def cost_fn(self, state_traj):\n",
        "        return torch.min(self.boundary_fn(state_traj), dim=-1).values\n",
        "\n",
        "    def hamiltonian(self, state, dvds):\n",
        "        # Control Hamiltonian\n",
        "        u1_coeff = dvds[..., 3] * torch.cos(state[..., 2]) + dvds[..., 4] * torch.sin(state[..., 2]) + 0.3 * dvds[..., 5]\n",
        "        u2_coeff = -dvds[..., 3] * torch.sin(state[..., 2]) + dvds[..., 4] * torch.cos(state[..., 2])\n",
        "        ham_ctrl = -250.0 * torch.sqrt(u1_coeff * u1_coeff + u2_coeff * u2_coeff)\n",
        "        # Constant Hamiltonian\n",
        "        ham_constant = dvds[..., 0] * state[..., 3] + dvds[..., 1] * state[..., 4] + \\\n",
        "                      dvds[..., 2] * state[..., 5]  - dvds[..., 4] * 9.81\n",
        "        # Compute the Hamiltonian\n",
        "        ham_vehicle = ham_ctrl + ham_constant\n",
        "        return ham_vehicle\n",
        "\n",
        "    def optimal_control(self, state, dvds):\n",
        "        u1_coeff = dvds[..., 3] * torch.cos(state[..., 2]) + dvds[..., 4] * torch.sin(state[..., 2]) + 0.3 * dvds[..., 5]\n",
        "        u2_coeff = -dvds[..., 3] * torch.sin(state[..., 2]) + dvds[..., 4] * torch.cos(state[..., 2])\n",
        "        opt_angle = torch.atan2(u2_coeff, u1_coeff) + math.pi\n",
        "        return torch.cat((250.0 * torch.cos(opt_angle)[..., None], 250.0 * torch.sin(opt_angle)[..., None]), dim=-1)\n",
        "\n",
        "    def optimal_disturbance(self, state, dvds):\n",
        "        return 0\n",
        "\n",
        "    def plot_config(self):\n",
        "        return {\n",
        "            'state_slices': [-100, 120, 0, 150, -5, 0.0],\n",
        "            'state_labels': ['x', 'y', r'$\\theta$', r'$v_x$', r'$v_y$', r'$\\omega'],\n",
        "            'x_axis_idx': 0,\n",
        "            'y_axis_idx': 1,\n",
        "            'z_axis_idx': 4,\n",
        "        }\n",
        "\n",
        "class Quadrotor(Dynamics):\n",
        "    def __init__(self, collisionR:float, thrust_max:float, set_mode:str):\n",
        "        self.thrust_max = thrust_max\n",
        "        self.m=1 #mass\n",
        "        self.arm_l=0.17\n",
        "        self.CT=1\n",
        "        self.CM=0.016\n",
        "        self.Gz=-9.8\n",
        "\n",
        "        self.thrust_max = thrust_max\n",
        "        self.collisionR = collisionR\n",
        "\n",
        "\n",
        "        super().__init__(\n",
        "            loss_type='brt_hjivi', set_mode=set_mode,\n",
        "            state_dim=13, input_dim=14, control_dim=4, disturbance_dim=0,\n",
        "            state_mean=[0 for i in range(13)],\n",
        "            state_var=[1.5, 1.5, 1.5, 1, 1, 1, 1, 10, 10 ,10 ,10 ,10 ,10],\n",
        "            value_mean=(math.sqrt(1.5**2+1.5**2+1.5**2)-2*self.collisionR)/2,\n",
        "            value_var=math.sqrt(1.5**2+1.5**2+1.5**2),\n",
        "            value_normto=0.02,\n",
        "            deepreach_model=\"exact\"\n",
        "        )\n",
        "\n",
        "    def state_test_range(self):\n",
        "        return [\n",
        "            [-1.5, 1.5],\n",
        "            [-1.5, 1.5],\n",
        "            [-1.5, 1.5],\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-1, 1],\n",
        "            [-10, 10],\n",
        "            [-10, 10],\n",
        "            [-10, 10],\n",
        "            [-10, 10],\n",
        "            [-10, 10],\n",
        "            [-10, 10],\n",
        "        ]\n",
        "\n",
        "    def equivalent_wrapped_state(self, state):\n",
        "        wrapped_state = torch.clone(state)\n",
        "        return wrapped_state\n",
        "\n",
        "    # Dubins3D dynamics\n",
        "    # \\dot x    = v \\cos \\theta\n",
        "    # \\dot y    = v \\sin \\theta\n",
        "    # \\dot \\theta = u\n",
        "    def dsdt(self, state, control, disturbance):\n",
        "        qw = state[..., 3] * 1.0\n",
        "        qx = state[..., 4] * 1.0\n",
        "        qy = state[..., 5] * 1.0\n",
        "        qz = state[..., 6] * 1.0\n",
        "        vx = state[..., 7] * 1.0\n",
        "        vy = state[..., 8] * 1.0\n",
        "        vz = state[..., 9] * 1.0\n",
        "        wx = state[..., 10] * 1.0\n",
        "        wy = state[..., 11] * 1.0\n",
        "        wz = state[..., 12] * 1.0\n",
        "        u1 = control[...,0] * 1.0\n",
        "        u2 = control[...,1] * 1.0\n",
        "        u3 = control[...,2] * 1.0\n",
        "        u4 = control[...,3] * 1.0\n",
        "\n",
        "\n",
        "        dsdt = torch.zeros_like(state)\n",
        "        dsdt[..., 0] = vx\n",
        "        dsdt[..., 1] = vy\n",
        "        dsdt[..., 2] = vz\n",
        "        dsdt[..., 3] = -(wx*qx+wy*qy+wz*qz)/2.0\n",
        "        dsdt[..., 4] =  (wx*qw+wz*qy-wy*qz)/2.0\n",
        "        dsdt[..., 5] = (wy*qw-wz*qx+wx*qz)/2.0\n",
        "        dsdt[..., 6] = (wz*qw+wy*qx-wx*qy)/2.0\n",
        "        dsdt[..., 7] = 2*(qw*qy+qx*qz)*self.CT/self.m*(u1+u2+u3+u4)\n",
        "        dsdt[..., 8] =2*(-qw*qx+qy*qz)*self.CT/self.m*(u1+u2+u3+u4)\n",
        "        dsdt[..., 9] =self.Gz+(1-2*torch.pow(qx,2)-2*torch.pow(qy,2))*self.CT/self.m*(u1+u2+u3+u4)\n",
        "        dsdt[..., 10] = 4*math.sqrt(2)*self.CT*(u1-u2-u3+u4)/(3*self.arm_l*self.m)-5*wy*wz/9.0\n",
        "        dsdt[..., 11] = 4*math.sqrt(2)*self.CT*(-u1-u2+u3+u4)/(3*self.arm_l*self.m)+5*wx*wz/9.0\n",
        "        dsdt[..., 12] =12*self.CT*self.CM/(7*self.arm_l**2*self.m)*(u1-u2+u3-u4)\n",
        "        return dsdt\n",
        "\n",
        "    def boundary_fn(self, state):\n",
        "        return torch.norm(state[..., :3], dim=-1) - self.collisionR\n",
        "\n",
        "    def sample_target_state(self, num_samples):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def cost_fn(self, state_traj):\n",
        "        return torch.min(self.boundary_fn(state_traj), dim=-1).values\n",
        "\n",
        "    def hamiltonian(self, state, dvds):\n",
        "        if self.set_mode == 'reach':\n",
        "            raise NotImplementedError\n",
        "\n",
        "        elif self.set_mode == 'avoid':\n",
        "            qw = state[..., 3] * 1.0\n",
        "            qx = state[..., 4] * 1.0\n",
        "            qy = state[..., 5] * 1.0\n",
        "            qz = state[..., 6] * 1.0\n",
        "            vx = state[..., 7] * 1.0\n",
        "            vy = state[..., 8] * 1.0\n",
        "            vz = state[..., 9] * 1.0\n",
        "            wx = state[..., 10] * 1.0\n",
        "            wy = state[..., 11] * 1.0\n",
        "            wz = state[..., 12] * 1.0\n",
        "\n",
        "\n",
        "            C1=2*(qw*qy+qx*qz)*self.CT/self.m\n",
        "            C2=2*(-qw*qx+qy*qz)*self.CT/self.m\n",
        "            C3=(1-2*torch.pow(qx,2)-2*torch.pow(qy,2))*self.CT/self.m\n",
        "            C4=4*math.sqrt(2)*self.CT/(3*self.arm_l*self.m)\n",
        "            C5=4*math.sqrt(2)*self.CT/(3*self.arm_l*self.m)\n",
        "            C6=12*self.CT*self.CM/(7*self.arm_l**2*self.m)\n",
        "\n",
        "            # Compute the hamiltonian for the quadrotor\n",
        "            ham= dvds[..., 0]*vx + dvds[..., 1]*vy+ dvds[..., 2]*vz\n",
        "            ham+= -dvds[..., 3]* (wx*qx+wy*qy+wz*qz)/2.0\n",
        "            ham+= dvds[..., 4]*(wx*qw+wz*qy-wy*qz)/2.0\n",
        "            ham+= dvds[..., 5]*(wy*qw-wz*qx+wx*qz)/2.0\n",
        "            ham+= dvds[..., 6]*(wz*qw+wy*qx-wx*qy)/2.0\n",
        "            ham+= dvds[..., 9]*-9.8\n",
        "            ham+= -dvds[..., 10]*5*wy*wz/9.0+ dvds[..., 11]*5*wx*wz/9.0\n",
        "\n",
        "            ham+=torch.abs(dvds[..., 7]*C1+dvds[..., 8]*C2+dvds[..., 9]*C3\n",
        "                +dvds[..., 10]*C4-dvds[..., 11]*C5+dvds[..., 12]*C6)*self.thrust_max\n",
        "\n",
        "            ham+=torch.abs(dvds[..., 7]*C1+dvds[..., 8]*C2+dvds[..., 9]*C3\n",
        "                -dvds[..., 10]*C4-dvds[..., 11]*C5-dvds[..., 12]*C6)*self.thrust_max\n",
        "\n",
        "            ham+=torch.abs(dvds[..., 7]*C1+dvds[..., 8]*C2+dvds[..., 9]*C3\n",
        "                -dvds[..., 10]*C4+dvds[..., 11]*C5+dvds[..., 12]*C6)*self.thrust_max\n",
        "\n",
        "            ham+=torch.abs(dvds[..., 7]*C1+dvds[..., 8]*C2+dvds[..., 9]*C3\n",
        "                +dvds[..., 10]*C4+dvds[..., 11]*C5-dvds[..., 12]*C6)*self.thrust_max\n",
        "\n",
        "            return ham\n",
        "\n",
        "    def optimal_control(self, state, dvds):\n",
        "        if self.set_mode == 'reach':\n",
        "            raise NotImplementedError\n",
        "        elif self.set_mode == 'avoid':\n",
        "            qw = state[..., 3] * 1.0\n",
        "            qx = state[..., 4] * 1.0\n",
        "            qy = state[..., 5] * 1.0\n",
        "            qz = state[..., 6] * 1.0\n",
        "\n",
        "\n",
        "            C1=2*(qw*qy+qx*qz)*self.CT/self.m\n",
        "            C2=2*(-qw*qx+qy*qz)*self.CT/self.m\n",
        "            C3=(1-2*torch.pow(qx,2)-2*torch.pow(qy,2))*self.CT/self.m\n",
        "            C4=4*math.sqrt(2)*self.CT/(3*self.arm_l*self.m)\n",
        "            C5=4*math.sqrt(2)*self.CT/(3*self.arm_l*self.m)\n",
        "            C6=12*self.CT*self.CM/(7*self.arm_l**2*self.m)\n",
        "\n",
        "\n",
        "            u1=self.thrust_max*torch.sign(dvds[..., 7]*C1+dvds[..., 8]*C2+dvds[..., 9]*C3\n",
        "                +dvds[..., 10]*C4-dvds[..., 11]*C5+dvds[..., 12]*C6)\n",
        "            u2=self.thrust_max*torch.sign(dvds[..., 7]*C1+dvds[..., 8]*C2+dvds[..., 9]*C3\n",
        "                -dvds[..., 10]*C4-dvds[..., 11]*C5-dvds[..., 12]*C6)\n",
        "            u3=self.thrust_max*torch.sign(dvds[..., 7]*C1+dvds[..., 8]*C2+dvds[..., 9]*C3\n",
        "                -dvds[..., 10]*C4+dvds[..., 11]*C5+dvds[..., 12]*C6)\n",
        "            u4=self.thrust_max*torch.sign(dvds[..., 7]*C1+dvds[..., 8]*C2+dvds[..., 9]*C3\n",
        "                +dvds[..., 10]*C4+dvds[..., 11]*C5-dvds[..., 12]*C6)\n",
        "\n",
        "        return torch.cat((u1[..., None], u2[..., None], u3[..., None], u4[..., None]), dim=-1)\n",
        "\n",
        "    def optimal_disturbance(self, state, dvds):\n",
        "        return 0\n",
        "\n",
        "    def plot_config(self):\n",
        "        return {\n",
        "            'state_slices': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "            'state_labels': ['x', 'y', 'z', 'qw', 'qx', 'qy', 'qz', 'vx', 'vy', 'vz', 'wx', 'wy', 'wz'],\n",
        "            'x_axis_idx': 0,\n",
        "            'y_axis_idx': 2,\n",
        "            'z_axis_idx': 7,\n",
        "        }\n",
        "\n",
        "class MultiVehicleCollision(Dynamics):\n",
        "    def __init__(self):\n",
        "        self.angle_alpha_factor = 1.2\n",
        "        self.velocity = 0.6\n",
        "        self.omega_max = 1.1\n",
        "        self.collisionR = 0.25\n",
        "        super().__init__(\n",
        "            loss_type='brt_hjivi', set_mode='avoid',\n",
        "            state_dim=9, input_dim=10, control_dim=3, disturbance_dim=0,\n",
        "            state_mean=[\n",
        "                0, 0,\n",
        "                0, 0,\n",
        "                0, 0,\n",
        "                0, 0, 0,\n",
        "            ],\n",
        "            state_var=[\n",
        "                1, 1,\n",
        "                1, 1,\n",
        "                1, 1,\n",
        "                self.angle_alpha_factor*math.pi, self.angle_alpha_factor*math.pi, self.angle_alpha_factor*math.pi,\n",
        "            ],\n",
        "            value_mean=0.25,\n",
        "            value_var=0.5,\n",
        "            value_normto=0.02,\n",
        "            deepreach_model=\"exact\"\n",
        "        )\n",
        "\n",
        "    def state_test_range(self):\n",
        "        return [\n",
        "            [-1, 1], [-1, 1],\n",
        "            [-1, 1], [-1, 1],\n",
        "            [-1, 1], [-1, 1],\n",
        "            [-math.pi, math.pi], [-math.pi, math.pi], [-math.pi, math.pi],\n",
        "        ]\n",
        "\n",
        "    def equivalent_wrapped_state(self, state):\n",
        "        wrapped_state = torch.clone(state)\n",
        "        wrapped_state[..., 6] = (wrapped_state[..., 6] + math.pi) % (2*math.pi) - math.pi\n",
        "        wrapped_state[..., 7] = (wrapped_state[..., 7] + math.pi) % (2*math.pi) - math.pi\n",
        "        wrapped_state[..., 8] = (wrapped_state[..., 8] + math.pi) % (2*math.pi) - math.pi\n",
        "        return wrapped_state\n",
        "\n",
        "    # dynamics (per car)\n",
        "    # \\dot x    = v \\cos \\theta\n",
        "    # \\dot y    = v \\sin \\theta\n",
        "    # \\dot \\theta = u\n",
        "    def dsdt(self, state, control, disturbance):\n",
        "        dsdt = torch.zeros_like(state)\n",
        "        dsdt[..., 0] = self.velocity*torch.cos(state[..., 6])\n",
        "        dsdt[..., 1] = self.velocity*torch.sin(state[..., 6])\n",
        "        dsdt[..., 2] = self.velocity*torch.cos(state[..., 7])\n",
        "        dsdt[..., 3] = self.velocity*torch.sin(state[..., 7])\n",
        "        dsdt[..., 4] = self.velocity*torch.cos(state[..., 8])\n",
        "        dsdt[..., 5] = self.velocity*torch.sin(state[..., 8])\n",
        "        dsdt[..., 6] = control[..., 0]\n",
        "        dsdt[..., 7] = control[..., 1]\n",
        "        dsdt[..., 8] = control[..., 2]\n",
        "        return dsdt\n",
        "\n",
        "    def boundary_fn(self, state):\n",
        "        boundary_values = torch.norm(state[..., 0:2] - state[..., 2:4], dim=-1) - self.collisionR\n",
        "        for i in range(1, 2):\n",
        "            boundary_values_current = torch.norm(state[..., 0:2] - state[..., 2*(i+1):2*(i+1)+2], dim=-1) - self.collisionR\n",
        "            boundary_values = torch.min(boundary_values, boundary_values_current)\n",
        "        # Collision cost between the evaders themselves\n",
        "        for i in range(2):\n",
        "            for j in range(i+1, 2):\n",
        "                evader1_coords_index = (i+1)*2\n",
        "                evader2_coords_index = (j+1)*2\n",
        "                boundary_values_current = torch.norm(state[..., evader1_coords_index:evader1_coords_index+2] - state[..., evader2_coords_index:evader2_coords_index+2], dim=-1) - self.collisionR\n",
        "                boundary_values = torch.min(boundary_values, boundary_values_current)\n",
        "        return boundary_values\n",
        "\n",
        "    def sample_target_state(self, num_samples):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def cost_fn(self, state_traj):\n",
        "        return torch.min(self.boundary_fn(state_traj), dim=-1).values\n",
        "\n",
        "    def hamiltonian(self, state, dvds):\n",
        "        # Compute the hamiltonian for the ego vehicle\n",
        "        ham = self.velocity*(torch.cos(state[..., 6]) * dvds[..., 0] + torch.sin(state[..., 6]) * dvds[..., 1]) + self.omega_max * torch.abs(dvds[..., 6])\n",
        "        # Hamiltonian effect due to other vehicles\n",
        "        ham += self.velocity*(torch.cos(state[..., 7]) * dvds[..., 2] + torch.sin(state[..., 7]) * dvds[..., 3]) + self.omega_max * torch.abs(dvds[..., 7])\n",
        "        ham += self.velocity*(torch.cos(state[..., 8]) * dvds[..., 4] + torch.sin(state[..., 8]) * dvds[..., 5]) + self.omega_max * torch.abs(dvds[..., 8])\n",
        "        return ham\n",
        "\n",
        "    def optimal_control(self, state, dvds):\n",
        "        return self.omega_max*torch.sign(dvds[..., [6, 7, 8]])\n",
        "\n",
        "    def optimal_disturbance(self, state, dvds):\n",
        "        return 0\n",
        "\n",
        "    def plot_config(self):\n",
        "        return {\n",
        "            'state_slices': [\n",
        "                0, 0,\n",
        "                -0.4, 0,\n",
        "                0.4, 0,\n",
        "                math.pi/2, math.pi/4, 3*math.pi/4,\n",
        "            ],\n",
        "            'state_labels': [\n",
        "                r'$x_1$', r'$y_1$',\n",
        "                r'$x_2$', r'$y_2$',\n",
        "                r'$x_3$', r'$y_3$',\n",
        "                r'$\\theta_1$', r'$\\theta_2$', r'$\\theta_3$',\n",
        "            ],\n",
        "            'x_axis_idx': 0,\n",
        "            'y_axis_idx': 1,\n",
        "            'z_axis_idx': 6,\n",
        "        }\n",
        "\n",
        "###############################################################\n",
        "# Custom Dynamics for 2d Planar Robot\n",
        "###############################################################\n",
        "class PlanarRobot2D(Dynamics):\n",
        "    def __init__(\n",
        "        self,\n",
        "        goalR: float,\n",
        "        velocity: float,\n",
        "        set_mode: str = 'avoid',\n",
        "        freeze_model: bool = False\n",
        "    ):\n",
        "        \"\"\"\n",
        "        2D constant-speed robot dynamics for reach/avoid problems.\n",
        "\n",
        "        Args:\n",
        "            goalR: Radius of the obstacle (avoid) or goal (reach) circle.\n",
        "            velocity: Constant forward speed (m/s).\n",
        "            set_mode: 'reach' or 'avoid'.\n",
        "            freeze_model: If True, dsdt/hamiltonian will raise NotImplementedError.\n",
        "        \"\"\"\n",
        "        self.goalR = goalR\n",
        "        self.velocity = velocity\n",
        "        self.freeze_model = freeze_model\n",
        "\n",
        "        super().__init__(\n",
        "            loss_type='brt_hjivi',\n",
        "            set_mode=set_mode,\n",
        "            state_dim=2, # [p_x, p_y]\n",
        "            input_dim=3, # [p_x, p_y, t]\n",
        "            control_dim=1, # [theta]\n",
        "            disturbance_dim=0,\n",
        "\n",
        "            # Normalize x,y from [-2,2] to [-1,1]\n",
        "            state_mean=[0.0, 0.0],\n",
        "            state_var=[2.0, 2.0],\n",
        "\n",
        "            value_mean=0.0, # value_mean is not used in 'exact' mode\n",
        "            value_var=0.5,\n",
        "            value_normto=0.02,\n",
        "            deepreach_model=\"exact\",\n",
        "        )\n",
        "\n",
        "    def state_test_range(self):\n",
        "        return [\n",
        "            [-2.0, 2.0], # p_x\n",
        "            [-2.0, 2.0], # p_y\n",
        "        ]\n",
        "\n",
        "    def equivalent_wrapped_state(self, state):\n",
        "        return state\n",
        "\n",
        "    def dsdt(self, state, control, disturbance):\n",
        "        # \\dot p_x = v \\cos \\theta\n",
        "        # \\dot p_y = v \\sin \\theta\n",
        "        if self.freeze_model:\n",
        "            raise NotImplementedError\n",
        "        theta = control[..., 0]\n",
        "        ds = torch.zeros_like(state)\n",
        "        ds[..., 0] = self.velocity * torch.cos(theta)\n",
        "        ds[..., 1] = self.velocity * torch.sin(theta)\n",
        "        return ds\n",
        "\n",
        "    def boundary_fn(self, state):\n",
        "        return torch.norm(state, dim=-1) - self.goalR\n",
        "\n",
        "    def sample_target_state(self, num_samples):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def cost_fn(self, state_traj):\n",
        "        raise NotImplementedError\n",
        "        # return torch.min(self.boundary_fn(state_traj), dim=-1).values\n",
        "\n",
        "    def hamiltonian(self, state, dvds):\n",
        "        if self.freeze_model:\n",
        "            raise NotImplementedError\n",
        "        norm = torch.sqrt(dvds[..., 0]**2 + dvds[..., 1]**2)\n",
        "        if self.set_mode == 'reach':\n",
        "            return  - self.velocity * norm\n",
        "        elif self.set_mode == 'avoid':\n",
        "            return  self.velocity * norm\n",
        "\n",
        "    def optimal_control(self, state, dvds):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def optimal_disturbance(self, state, dvds):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def plot_config(self):\n",
        "        return {\n",
        "            \"state_slices\": [0, 0],\n",
        "            \"state_labels\": [\"p_x\", \"p_y\"],\n",
        "            \"x_axis_idx\": 0,\n",
        "            \"y_axis_idx\": 1,\n",
        "            \"z_axis_idx\": -1,\n",
        "        }\n",
        "\n",
        "###############################################################\n"
      ],
      "metadata": {
        "id": "8dauKrtlDfXO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Experiments Code"
      ],
      "metadata": {
        "id": "cZYSaKilD_U3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Experiment(ABC):\n",
        "    def __init__(self, model, dataset, experiment_dir, use_wandb):\n",
        "        self.model = model\n",
        "        self.dataset = dataset\n",
        "        self.experiment_dir = experiment_dir\n",
        "        self.use_wandb = use_wandb\n",
        "\n",
        "    @abstractmethod\n",
        "    def init_special(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def _load_checkpoint(self, epoch):\n",
        "        if epoch == -1:\n",
        "            model_path = os.path.join(self.experiment_dir, 'training', 'checkpoints', 'model_final.pth')\n",
        "            self.model.load_state_dict(torch.load(model_path))\n",
        "        else:\n",
        "            model_path = os.path.join(self.experiment_dir, 'training', 'checkpoints', 'model_epoch_%04d.pth' % epoch)\n",
        "            self.model.load_state_dict(torch.load(model_path)['model'])\n",
        "\n",
        "    def validate(self, device, epoch, save_path, x_resolution, y_resolution, z_resolution, time_resolution):\n",
        "        was_training = self.model.training\n",
        "        self.model.eval()\n",
        "        self.model.requires_grad_(False)\n",
        "\n",
        "        plot_config = self.dataset.dynamics.plot_config()\n",
        "        state_test_range = self.dataset.dynamics.state_test_range()\n",
        "\n",
        "        x_idx = plot_config['x_axis_idx']\n",
        "        y_idx = plot_config['y_axis_idx']\n",
        "        z_idx = plot_config.get('z_axis_idx', -1)\n",
        "\n",
        "        x_min, x_max = state_test_range[x_idx]\n",
        "        y_min, y_max = state_test_range[y_idx]\n",
        "        xs = torch.linspace(x_min, x_max, x_resolution)\n",
        "        ys = torch.linspace(y_min, y_max, y_resolution)\n",
        "        xys = torch.cartesian_prod(xs, ys)\n",
        "\n",
        "        # Determine z slices: if z_idx == -1, use a single dummy slice\n",
        "        if z_idx == -1:\n",
        "            zs = torch.tensor([0.0], dtype=torch.float32)\n",
        "        else:\n",
        "            z_min, z_max = state_test_range[z_idx]\n",
        "            zs = torch.linspace(z_min, z_max, z_resolution)\n",
        "\n",
        "        times = torch.linspace(0, self.dataset.tMax, time_resolution)\n",
        "        fig = plt.figure(figsize=(5*len(times), 5*len(zs)))\n",
        "\n",
        "        # Loop over time and z-slices\n",
        "        for i, t in enumerate(times):\n",
        "            for j, z_val in enumerate(zs):\n",
        "                coords = torch.zeros(x_resolution*y_resolution, self.dataset.dynamics.state_dim + 1)\n",
        "                coords[:, 0] = t\n",
        "                coords[:, 1:] = torch.tensor(plot_config['state_slices'])\n",
        "\n",
        "                coords[:, 1 + x_idx] = xys[:, 0]\n",
        "                coords[:, 1 + y_idx] = xys[:, 1]\n",
        "\n",
        "                # Only fill z if it's a real 3D axis\n",
        "                if z_idx != -1:\n",
        "                    coords[:, 1 + z_idx] = z_val\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    inp = self.dataset.dynamics.coord_to_input(coords.to(device))\n",
        "                    results = self.model({'coords': inp})\n",
        "                    values = self.dataset.dynamics.io_to_value(results['model_in'].detach(), results['model_out'].squeeze(dim=-1).detach())\n",
        "\n",
        "                ax = fig.add_subplot(len(times), len(zs), (j+1) + i*len(zs))\n",
        "                title_z = (f\", {plot_config['state_labels'][z_idx]} = {z_val:.2f}\"\n",
        "                        if z_idx != -1 else \"\")\n",
        "                ax.set_title(f\"t = {t:.2f}{title_z}\")\n",
        "\n",
        "                img = values.cpu().numpy().reshape(x_resolution, y_resolution).T\n",
        "                # binary decision boundary: <=0 in red/blue\n",
        "                mask = (img <= 0).astype(float)\n",
        "                s = ax.imshow(mask, cmap='bwr', origin='lower', extent=(x_min, x_max, y_min, y_max))\n",
        "                fig.colorbar(s, ax=ax)\n",
        "\n",
        "        fig.savefig(save_path)\n",
        "        if self.use_wandb:\n",
        "            wandb.log({\n",
        "                'step': epoch,\n",
        "                'val_plot': wandb.Image(fig),\n",
        "            })\n",
        "        plt.close()\n",
        "\n",
        "        if was_training:\n",
        "            self.model.train()\n",
        "            self.model.requires_grad_(True)\n",
        "\n",
        "    def train(\n",
        "            self, device, batch_size, epochs, lr,\n",
        "            steps_til_summary, epochs_til_checkpoint,\n",
        "            loss_fn, clip_grad, use_lbfgs, adjust_relative_grads,\n",
        "            val_x_resolution, val_y_resolution, val_z_resolution, val_time_resolution,\n",
        "            use_CSL, CSL_lr, CSL_dt, epochs_til_CSL, num_CSL_samples, CSL_loss_frac_cutoff, max_CSL_epochs, CSL_loss_weight, CSL_batch_size,\n",
        "        ):\n",
        "        was_eval = not self.model.training\n",
        "        self.model.train()\n",
        "        self.model.requires_grad_(True)\n",
        "\n",
        "        train_dataloader = DataLoader(self.dataset, shuffle=True, batch_size=batch_size, pin_memory=True, num_workers=0)\n",
        "\n",
        "        optim = torch.optim.Adam(lr=lr, params=self.model.parameters())\n",
        "\n",
        "        # copy settings from Raissi et al. (2019) and here\n",
        "        # https://github.com/maziarraissi/PINNs\n",
        "        if use_lbfgs:\n",
        "            optim = torch.optim.LBFGS(lr=lr, params=self.model.parameters(), max_iter=50000, max_eval=50000,\n",
        "                                    history_size=50, line_search_fn='strong_wolfe')\n",
        "\n",
        "        training_dir = os.path.join(self.experiment_dir, 'training')\n",
        "\n",
        "        summaries_dir = os.path.join(training_dir, 'summaries')\n",
        "        if not os.path.exists(summaries_dir):\n",
        "            os.makedirs(summaries_dir)\n",
        "\n",
        "        checkpoints_dir = os.path.join(training_dir, 'checkpoints')\n",
        "        if not os.path.exists(checkpoints_dir):\n",
        "            os.makedirs(checkpoints_dir)\n",
        "\n",
        "        writer = SummaryWriter(summaries_dir)\n",
        "\n",
        "        total_steps = 0\n",
        "\n",
        "        if adjust_relative_grads:\n",
        "            new_weight = 1\n",
        "\n",
        "        with tqdm(total=len(train_dataloader) * epochs) as pbar:\n",
        "            train_losses = []\n",
        "            last_CSL_epoch = -1\n",
        "            for epoch in range(0, epochs):\n",
        "                if self.dataset.pretrain: # skip CSL\n",
        "                    last_CSL_epoch = epoch\n",
        "                time_interval_length = (self.dataset.counter/self.dataset.counter_end)*(self.dataset.tMax-self.dataset.tMin)\n",
        "                CSL_tMax = self.dataset.tMin + int(time_interval_length/CSL_dt)*CSL_dt\n",
        "\n",
        "                # self-supervised learning\n",
        "                for step, (model_input, gt) in enumerate(train_dataloader):\n",
        "                    start_time = time.time()\n",
        "\n",
        "                    model_input = {key: value.to(device) for key, value in model_input.items()}\n",
        "                    gt = {key: value.to(device) for key, value in gt.items()}\n",
        "\n",
        "                    model_results = self.model({'coords': model_input['model_coords']})\n",
        "\n",
        "                    states = self.dataset.dynamics.input_to_coord(model_results['model_in'].detach())[..., 1:]\n",
        "                    values = self.dataset.dynamics.io_to_value(model_results['model_in'].detach(), model_results['model_out'].squeeze(dim=-1))\n",
        "                    dvs = self.dataset.dynamics.io_to_dv(model_results['model_in'], model_results['model_out'].squeeze(dim=-1))\n",
        "                    boundary_values = gt['boundary_values']\n",
        "                    if self.dataset.dynamics.loss_type == 'brat_hjivi':\n",
        "                        reach_values = gt['reach_values']\n",
        "                        avoid_values = gt['avoid_values']\n",
        "                    dirichlet_masks = gt['dirichlet_masks']\n",
        "\n",
        "                    if self.dataset.dynamics.loss_type == 'brt_hjivi':\n",
        "                        losses = loss_fn(states, values, dvs[..., 0], dvs[..., 1:], boundary_values, dirichlet_masks, model_results['model_out'])\n",
        "                    elif self.dataset.dynamics.loss_type == 'brat_hjivi':\n",
        "                        losses = loss_fn(states, values, dvs[..., 0], dvs[..., 1:], boundary_values, reach_values, avoid_values, dirichlet_masks, model_results['model_out'])\n",
        "                    else:\n",
        "                        raise NotImplementedError\n",
        "\n",
        "                    if use_lbfgs:\n",
        "                        def closure():\n",
        "                            optim.zero_grad()\n",
        "                            train_loss = 0.\n",
        "                            for loss_name, loss in losses.items():\n",
        "                                train_loss += loss.mean()\n",
        "                            train_loss.backward()\n",
        "                            return train_loss\n",
        "                        optim.step(closure)\n",
        "\n",
        "                    # Adjust the relative magnitude of the losses if required\n",
        "                    if self.dataset.dynamics.deepreach_model in ['vanilla', 'diff'] and adjust_relative_grads:\n",
        "                        if losses['diff_constraint_hom'] > 0.01:\n",
        "                            params = OrderedDict(self.model.named_parameters())\n",
        "                            # Gradients with respect to the PDE loss\n",
        "                            optim.zero_grad()\n",
        "                            losses['diff_constraint_hom'].backward(retain_graph=True)\n",
        "                            grads_PDE = []\n",
        "                            for key, param in params.items():\n",
        "                                grads_PDE.append(param.grad.view(-1))\n",
        "                            grads_PDE = torch.cat(grads_PDE)\n",
        "\n",
        "                            # Gradients with respect to the boundary loss\n",
        "                            optim.zero_grad()\n",
        "                            losses['dirichlet'].backward(retain_graph=True)\n",
        "                            grads_dirichlet = []\n",
        "                            for key, param in params.items():\n",
        "                                grads_dirichlet.append(param.grad.view(-1))\n",
        "                            grads_dirichlet = torch.cat(grads_dirichlet)\n",
        "\n",
        "                            # # Plot the gradients\n",
        "                            # import seaborn as sns\n",
        "                            # import matplotlib.pyplot as plt\n",
        "                            # fig = plt.figure(figsize=(5, 5))\n",
        "                            # ax = fig.add_subplot(1, 1, 1)\n",
        "                            # ax.set_yscale('symlog')\n",
        "                            # sns.distplot(grads_PDE.cpu().numpy(), hist=False, kde_kws={\"shade\": False}, norm_hist=True)\n",
        "                            # sns.distplot(grads_dirichlet.cpu().numpy(), hist=False, kde_kws={\"shade\": False}, norm_hist=True)\n",
        "                            # fig.savefig('gradient_visualization.png')\n",
        "\n",
        "                            # fig = plt.figure(figsize=(5, 5))\n",
        "                            # ax = fig.add_subplot(1, 1, 1)\n",
        "                            # ax.set_yscale('symlog')\n",
        "                            # grads_dirichlet_normalized = grads_dirichlet * torch.mean(torch.abs(grads_PDE))/torch.mean(torch.abs(grads_dirichlet))\n",
        "                            # sns.distplot(grads_PDE.cpu().numpy(), hist=False, kde_kws={\"shade\": False}, norm_hist=True)\n",
        "                            # sns.distplot(grads_dirichlet_normalized.cpu().numpy(), hist=False, kde_kws={\"shade\": False}, norm_hist=True)\n",
        "                            # ax.set_xlim([-1000.0, 1000.0])\n",
        "                            # fig.savefig('gradient_visualization_normalized.png')\n",
        "\n",
        "                            # Set the new weight according to the paper\n",
        "                            # num = torch.max(torch.abs(grads_PDE))\n",
        "                            num = torch.mean(torch.abs(grads_PDE))\n",
        "                            den = torch.mean(torch.abs(grads_dirichlet))\n",
        "                            new_weight = 0.9*new_weight + 0.1*num/den\n",
        "                            losses['dirichlet'] = new_weight*losses['dirichlet']\n",
        "                        writer.add_scalar('weight_scaling', new_weight, total_steps)\n",
        "\n",
        "                    # import ipdb; ipdb.set_trace()\n",
        "\n",
        "                    train_loss = 0.\n",
        "                    for loss_name, loss in losses.items():\n",
        "                        single_loss = loss.mean()\n",
        "\n",
        "                        if loss_name == 'dirichlet':\n",
        "                            writer.add_scalar(loss_name, single_loss/new_weight, total_steps)\n",
        "                        else:\n",
        "                            writer.add_scalar(loss_name, single_loss, total_steps)\n",
        "                        train_loss += single_loss\n",
        "\n",
        "                    train_losses.append(train_loss.item())\n",
        "                    writer.add_scalar(\"total_train_loss\", train_loss, total_steps)\n",
        "\n",
        "                    if not total_steps % steps_til_summary:\n",
        "                        torch.save(self.model.state_dict(),\n",
        "                                os.path.join(checkpoints_dir, 'model_current.pth'))\n",
        "                        # summary_fn(model, model_input, gt, model_output, writer, total_steps)\n",
        "\n",
        "                    if not use_lbfgs:\n",
        "                        optim.zero_grad()\n",
        "                        train_loss.backward()\n",
        "\n",
        "                        if clip_grad:\n",
        "                            if isinstance(clip_grad, bool):\n",
        "                                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.)\n",
        "                            else:\n",
        "                                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=clip_grad)\n",
        "\n",
        "                        optim.step()\n",
        "\n",
        "                    pbar.update(1)\n",
        "\n",
        "                    if not total_steps % steps_til_summary:\n",
        "                        tqdm.write(\"Epoch %d, Total loss %0.6f, iteration time %0.6f\" % (epoch, train_loss, time.time() - start_time))\n",
        "                        if self.use_wandb:\n",
        "                            wandb.log({\n",
        "                                'step': epoch,\n",
        "                                'train_loss': train_loss,\n",
        "                                'pde_loss': losses['diff_constraint_hom'],\n",
        "                            })\n",
        "\n",
        "                    total_steps += 1\n",
        "\n",
        "                # cost-supervised learning (CSL) phase\n",
        "                if use_CSL and not self.dataset.pretrain and (epoch-last_CSL_epoch) >= epochs_til_CSL:\n",
        "                    last_CSL_epoch = epoch\n",
        "\n",
        "                    # generate CSL datasets\n",
        "                    self.model.eval()\n",
        "\n",
        "                    CSL_dataset = scenario_optimization(\n",
        "                        device=device, model=self.model, policy=self.model, dynamics=self.dataset.dynamics,\n",
        "                        tMin=self.dataset.tMin, tMax=CSL_tMax, dt=CSL_dt,\n",
        "                        set_type=\"BRT\", control_type=\"value\", # TODO: implement option for BRS too\n",
        "                        scenario_batch_size=min(num_CSL_samples, 100000), sample_batch_size=min(10*num_CSL_samples, 1000000),\n",
        "                        sample_generator=SliceSampleGenerator(dynamics=self.dataset.dynamics, slices=[None]*self.dataset.dynamics.state_dim),\n",
        "                        sample_validator=ValueThresholdValidator(v_min=float('-inf'), v_max=float('inf')),\n",
        "                        violation_validator=ValueThresholdValidator(v_min=0.0, v_max=0.0),\n",
        "                        max_scenarios=num_CSL_samples, tStart_generator=lambda n : torch.zeros(n).uniform_(self.dataset.tMin, CSL_tMax)\n",
        "                    )\n",
        "                    CSL_coords = torch.cat((CSL_dataset['times'].unsqueeze(-1), CSL_dataset['states']), dim=-1)\n",
        "                    CSL_costs = CSL_dataset['costs']\n",
        "\n",
        "                    num_CSL_val_samples = int(0.1*num_CSL_samples)\n",
        "                    CSL_val_dataset = scenario_optimization(\n",
        "                        model=self.model, policy=self.model, dynamics=self.dataset.dynamics,\n",
        "                        tMin=self.dataset.tMin, tMax=CSL_tMax, dt=CSL_dt,\n",
        "                        set_type=\"BRT\", control_type=\"value\", # TODO: implement option for BRS too\n",
        "                        scenario_batch_size=min(num_CSL_val_samples, 100000), sample_batch_size=min(10*num_CSL_val_samples, 1000000),\n",
        "                        sample_generator=SliceSampleGenerator(dynamics=self.dataset.dynamics, slices=[None]*self.dataset.dynamics.state_dim),\n",
        "                        sample_validator=ValueThresholdValidator(v_min=float('-inf'), v_max=float('inf')),\n",
        "                        violation_validator=ValueThresholdValidator(v_min=0.0, v_max=0.0),\n",
        "                        max_scenarios=num_CSL_val_samples, tStart_generator=lambda n : torch.zeros(n).uniform_(self.dataset.tMin, CSL_tMax)\n",
        "                    )\n",
        "                    CSL_val_coords = torch.cat((CSL_val_dataset['times'].unsqueeze(-1), CSL_val_dataset['states']), dim=-1)\n",
        "                    CSL_val_costs = CSL_val_dataset['costs']\n",
        "\n",
        "                    CSL_val_tMax_dataset = scenario_optimization(\n",
        "                        model=self.model, policy=self.model, dynamics=self.dataset.dynamics,\n",
        "                        tMin=self.dataset.tMin, tMax=self.dataset.tMax, dt=CSL_dt,\n",
        "                        set_type=\"BRT\", control_type=\"value\", # TODO: implement option for BRS too\n",
        "                        scenario_batch_size=min(num_CSL_val_samples, 100000), sample_batch_size=min(10*num_CSL_val_samples, 1000000),\n",
        "                        sample_generator=SliceSampleGenerator(dynamics=self.dataset.dynamics, slices=[None]*self.dataset.dynamics.state_dim),\n",
        "                        sample_validator=ValueThresholdValidator(v_min=float('-inf'), v_max=float('inf')),\n",
        "                        violation_validator=ValueThresholdValidator(v_min=0.0, v_max=0.0),\n",
        "                        max_scenarios=num_CSL_val_samples # no tStart_generator, since I want all tMax times\n",
        "                    )\n",
        "                    CSL_val_tMax_coords = torch.cat((CSL_val_tMax_dataset['times'].unsqueeze(-1), CSL_val_tMax_dataset['states']), dim=-1)\n",
        "                    CSL_val_tMax_costs = CSL_val_tMax_dataset['costs']\n",
        "\n",
        "                    self.model.train()\n",
        "\n",
        "                    # CSL optimizer\n",
        "                    CSL_optim = torch.optim.Adam(lr=CSL_lr, params=self.model.parameters())\n",
        "\n",
        "                    # initial CSL val loss\n",
        "                    CSL_val_results = self.model({'coords': self.dataset.dynamics.coord_to_input(CSL_val_coords.to(device))})\n",
        "                    CSL_val_preds = self.dataset.dynamics.io_to_value(CSL_val_results['model_in'], CSL_val_results['model_out'].squeeze(dim=-1))\n",
        "                    CSL_val_errors = CSL_val_preds - CSL_val_costs.to(device)\n",
        "                    CSL_val_loss = torch.mean(torch.pow(CSL_val_errors, 2))\n",
        "                    CSL_initial_val_loss = CSL_val_loss\n",
        "                    if self.use_wandb:\n",
        "                        wandb.log({\n",
        "                            \"step\": epoch,\n",
        "                            \"CSL_val_loss\": CSL_val_loss.item()\n",
        "                        })\n",
        "\n",
        "                    # initial self-supervised learning (SSL) val loss\n",
        "                    # right now, just took code from dataio.py and the SSL training loop above; TODO: refactor all this for cleaner modular code\n",
        "                    CSL_val_states = CSL_val_coords[..., 1:].to(device)\n",
        "                    CSL_val_dvs = self.dataset.dynamics.io_to_dv(CSL_val_results['model_in'], CSL_val_results['model_out'].squeeze(dim=-1))\n",
        "                    CSL_val_boundary_values = self.dataset.dynamics.boundary_fn(CSL_val_states)\n",
        "                    if self.dataset.dynamics.loss_type == 'brat_hjivi':\n",
        "                        CSL_val_reach_values = self.dataset.dynamics.reach_fn(CSL_val_states)\n",
        "                        CSL_val_avoid_values = self.dataset.dynamics.avoid_fn(CSL_val_states)\n",
        "                    CSL_val_dirichlet_masks = CSL_val_coords[:, 0].to(device) == self.dataset.tMin # assumes time unit in dataset (model) is same as real time units\n",
        "                    if self.dataset.dynamics.loss_type == 'brt_hjivi':\n",
        "                        SSL_val_losses = loss_fn(CSL_val_states, CSL_val_preds, CSL_val_dvs[..., 0], CSL_val_dvs[..., 1:], CSL_val_boundary_values, CSL_val_dirichlet_masks)\n",
        "                    elif self.dataset.dynamics.loss_type == 'brat_hjivi':\n",
        "                        SSL_val_losses = loss_fn(CSL_val_states, CSL_val_preds, CSL_val_dvs[..., 0], CSL_val_dvs[..., 1:], CSL_val_boundary_values, CSL_val_reach_values, CSL_val_avoid_values, CSL_val_dirichlet_masks)\n",
        "                    else:\n",
        "                        NotImplementedError\n",
        "                    SSL_val_loss = SSL_val_losses['diff_constraint_hom'].mean() # I assume there is no dirichlet (boundary) loss here, because I do not ever explicitly generate source samples at tMin (i.e. torch.all(CSL_val_dirichlet_masks == False))\n",
        "                    if self.use_wandb:\n",
        "                        wandb.log({\n",
        "                            \"step\": epoch,\n",
        "                            \"SSL_val_loss\": SSL_val_loss.item()\n",
        "                        })\n",
        "\n",
        "                    # CSL training loop\n",
        "                    for CSL_epoch in tqdm(range(max_CSL_epochs)):\n",
        "                        CSL_idxs = torch.randperm(num_CSL_samples)\n",
        "                        for CSL_batch in range(math.ceil(num_CSL_samples/CSL_batch_size)):\n",
        "                            CSL_batch_idxs = CSL_idxs[CSL_batch*CSL_batch_size:(CSL_batch+1)*CSL_batch_size]\n",
        "                            CSL_batch_coords = CSL_coords[CSL_batch_idxs]\n",
        "\n",
        "                            CSL_batch_results = self.model({'coords': self.dataset.dynamics.coord_to_input(CSL_batch_coords.to(device))})\n",
        "                            CSL_batch_preds = self.dataset.dynamics.io_to_value(CSL_batch_results['model_in'], CSL_batch_results['model_out'].squeeze(dim=-1))\n",
        "                            CSL_batch_costs = CSL_costs[CSL_batch_idxs].to(device)\n",
        "                            CSL_batch_errors = CSL_batch_preds - CSL_batch_costs\n",
        "                            CSL_batch_loss = CSL_loss_weight*torch.mean(torch.pow(CSL_batch_errors, 2))\n",
        "\n",
        "                            CSL_batch_states = CSL_batch_coords[..., 1:].to(device)\n",
        "                            CSL_batch_dvs = self.dataset.dynamics.io_to_dv(CSL_batch_results['model_in'], CSL_batch_results['model_out'].squeeze(dim=-1))\n",
        "                            CSL_batch_boundary_values = self.dataset.dynamics.boundary_fn(CSL_batch_states)\n",
        "                            if self.dataset.dynamics.loss_type == 'brat_hjivi':\n",
        "                                CSL_batch_reach_values = self.dataset.dynamics.reach_fn(CSL_batch_states)\n",
        "                                CSL_batch_avoid_values = self.dataset.dynamics.avoid_fn(CSL_batch_states)\n",
        "                            CSL_batch_dirichlet_masks = CSL_batch_coords[:, 0].to(device) == self.dataset.tMin # assumes time unit in dataset (model) is same as real time units\n",
        "                            if self.dataset.dynamics.loss_type == 'brt_hjivi':\n",
        "                                SSL_batch_losses = loss_fn(CSL_batch_states, CSL_batch_preds, CSL_batch_dvs[..., 0], CSL_batch_dvs[..., 1:], CSL_batch_boundary_values, CSL_batch_dirichlet_masks)\n",
        "                            elif self.dataset.dynamics.loss_type == 'brat_hjivi':\n",
        "                                SSL_batch_losses = loss_fn(CSL_batch_states, CSL_batch_preds, CSL_batch_dvs[..., 0], CSL_batch_dvs[..., 1:], CSL_batch_boundary_values, CSL_batch_reach_values, CSL_batch_avoid_values, CSL_batch_dirichlet_masks)\n",
        "                            else:\n",
        "                                NotImplementedError\n",
        "                            SSL_batch_loss = SSL_batch_losses['diff_constraint_hom'].mean() # I assume there is no dirichlet (boundary) loss here, because I do not ever explicitly generate source samples at tMin (i.e. torch.all(CSL_batch_dirichlet_masks == False))\n",
        "\n",
        "                            CSL_optim.zero_grad()\n",
        "                            SSL_batch_loss.backward(retain_graph=True)\n",
        "                            if (not use_lbfgs) and clip_grad: # no adjust_relative_grads, because I assume even with adjustment, the diff_constraint_hom remains unaffected and the only other loss (dirichlet) is zero\n",
        "                                if isinstance(clip_grad, bool):\n",
        "                                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.)\n",
        "                                else:\n",
        "                                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=clip_grad)\n",
        "                            CSL_batch_loss.backward()\n",
        "                            CSL_optim.step()\n",
        "\n",
        "                        # evaluate on CSL_val_dataset\n",
        "                        CSL_val_results = self.model({'coords': self.dataset.dynamics.coord_to_input(CSL_val_coords.to(device))})\n",
        "                        CSL_val_preds = self.dataset.dynamics.io_to_value(CSL_val_results['model_in'], CSL_val_results['model_out'].squeeze(dim=-1))\n",
        "                        CSL_val_errors = CSL_val_preds - CSL_val_costs.to(device)\n",
        "                        CSL_val_loss = torch.mean(torch.pow(CSL_val_errors, 2))\n",
        "\n",
        "                        CSL_val_states = CSL_val_coords[..., 1:].to(device)\n",
        "                        CSL_val_dvs = self.dataset.dynamics.io_to_dv(CSL_val_results['model_in'], CSL_val_results['model_out'].squeeze(dim=-1))\n",
        "                        CSL_val_boundary_values = self.dataset.dynamics.boundary_fn(CSL_val_states)\n",
        "                        if self.dataset.dynamics.loss_type == 'brat_hjivi':\n",
        "                            CSL_val_reach_values = self.dataset.dynamics.reach_fn(CSL_val_states)\n",
        "                            CSL_val_avoid_values = self.dataset.dynamics.avoid_fn(CSL_val_states)\n",
        "                        CSL_val_dirichlet_masks = CSL_val_coords[:, 0].to(device) == self.dataset.tMin # assumes time unit in dataset (model) is same as real time units\n",
        "                        if self.dataset.dynamics.loss_type == 'brt_hjivi':\n",
        "                            SSL_val_losses = loss_fn(CSL_val_states, CSL_val_preds, CSL_val_dvs[..., 0], CSL_val_dvs[..., 1:], CSL_val_boundary_values, CSL_val_dirichlet_masks)\n",
        "                        elif self.dataset.dynamics.loss_type == 'brat_hjivi':\n",
        "                            SSL_val_losses = loss_fn(CSL_val_states, CSL_val_preds, CSL_val_dvs[..., 0], CSL_val_dvs[..., 1:], CSL_val_boundary_values, CSL_val_reach_values, CSL_val_avoid_values, CSL_val_dirichlet_masks)\n",
        "                        else:\n",
        "                            raise NotImplementedError\n",
        "                        SSL_val_loss = SSL_val_losses['diff_constraint_hom'].mean() # I assume there is no dirichlet (boundary) loss here, because I do not ever explicitly generate source samples at tMin (i.e. torch.all(CSL_val_dirichlet_masks == False))\n",
        "\n",
        "                        CSL_val_tMax_results = self.model({'coords': self.dataset.dynamics.coord_to_input(CSL_val_tMax_coords.to(device))})\n",
        "                        CSL_val_tMax_preds = self.dataset.dynamics.io_to_value(CSL_val_tMax_results['model_in'], CSL_val_tMax_results['model_out'].squeeze(dim=-1))\n",
        "                        CSL_val_tMax_errors = CSL_val_tMax_preds - CSL_val_tMax_costs.to(device)\n",
        "                        CSL_val_tMax_loss = torch.mean(torch.pow(CSL_val_tMax_errors, 2))\n",
        "\n",
        "                        # log CSL losses, recovered_safe_set_fracs\n",
        "                        if self.dataset.dynamics.set_mode == 'reach':\n",
        "                            CSL_train_batch_theoretically_recoverable_safe_set_frac = torch.sum(CSL_batch_costs.to(device) < 0) / len(CSL_batch_preds)\n",
        "                            CSL_train_batch_recovered_safe_set_frac = torch.sum(CSL_batch_preds < torch.min(CSL_batch_preds[CSL_batch_costs.to(device) > 0])) / len(CSL_batch_preds)\n",
        "                            CSL_val_theoretically_recoverable_safe_set_frac = torch.sum(CSL_val_costs.to(device) < 0) / len(CSL_val_preds)\n",
        "                            CSL_val_recovered_safe_set_frac = torch.sum(CSL_val_preds < torch.min(CSL_val_preds[CSL_val_costs.to(device) > 0])) / len(CSL_val_preds)\n",
        "                            CSL_val_tMax_theoretically_recoverable_safe_set_frac = torch.sum(CSL_val_tMax_costs.to(device) < 0) / len(CSL_val_tMax_preds)\n",
        "                            CSL_val_tMax_recovered_safe_set_frac = torch.sum(CSL_val_tMax_preds < torch.min(CSL_val_tMax_preds[CSL_val_tMax_costs.to(device) > 0])) / len(CSL_val_tMax_preds)\n",
        "                        elif self.dataset.dynamics.set_mode == 'avoid':\n",
        "                            CSL_train_batch_theoretically_recoverable_safe_set_frac = torch.sum(CSL_batch_costs.to(device) > 0) / len(CSL_batch_preds)\n",
        "                            CSL_train_batch_recovered_safe_set_frac = torch.sum(CSL_batch_preds > torch.max(CSL_batch_preds[CSL_batch_costs.to(device) < 0])) / len(CSL_batch_preds)\n",
        "                            CSL_val_theoretically_recoverable_safe_set_frac = torch.sum(CSL_val_costs.to(device) > 0) / len(CSL_val_preds)\n",
        "                            CSL_val_recovered_safe_set_frac = torch.sum(CSL_val_preds > torch.max(CSL_val_preds[CSL_val_costs.to(device) < 0])) / len(CSL_val_preds)\n",
        "                            CSL_val_tMax_theoretically_recoverable_safe_set_frac = torch.sum(CSL_val_tMax_costs.to(device) > 0) / len(CSL_val_tMax_preds)\n",
        "                            CSL_val_tMax_recovered_safe_set_frac = torch.sum(CSL_val_tMax_preds > torch.max(CSL_val_tMax_preds[CSL_val_tMax_costs.to(device) < 0])) / len(CSL_val_tMax_preds)\n",
        "                        else:\n",
        "                            raise NotImplementedError\n",
        "                        if self.use_wandb:\n",
        "                            wandb.log({\n",
        "                                \"step\": epoch+(CSL_epoch+1)*int(0.5*epochs_til_CSL/max_CSL_epochs),\n",
        "                                \"CSL_train_batch_loss\": CSL_batch_loss.item(),\n",
        "                                \"SSL_train_batch_loss\": SSL_batch_loss.item(),\n",
        "                                \"CSL_val_loss\": CSL_val_loss.item(),\n",
        "                                \"SSL_val_loss\": SSL_val_loss.item(),\n",
        "                                \"CSL_val_tMax_loss\": CSL_val_tMax_loss.item(),\n",
        "                                \"CSL_train_batch_theoretically_recoverable_safe_set_frac\": CSL_train_batch_theoretically_recoverable_safe_set_frac.item(),\n",
        "                                \"CSL_val_theoretically_recoverable_safe_set_frac\": CSL_val_theoretically_recoverable_safe_set_frac.item(),\n",
        "                                \"CSL_val_tMax_theoretically_recoverable_safe_set_frac\": CSL_val_tMax_theoretically_recoverable_safe_set_frac.item(),\n",
        "                                \"CSL_train_batch_recovered_safe_set_frac\": CSL_train_batch_recovered_safe_set_frac.item(),\n",
        "                                \"CSL_val_recovered_safe_set_frac\": CSL_val_recovered_safe_set_frac.item(),\n",
        "                                \"CSL_val_tMax_recovered_safe_set_frac\": CSL_val_tMax_recovered_safe_set_frac.item(),\n",
        "                            })\n",
        "\n",
        "                        if CSL_val_loss < CSL_loss_frac_cutoff*CSL_initial_val_loss:\n",
        "                            break\n",
        "\n",
        "                if not (epoch+1) % epochs_til_checkpoint:\n",
        "                    # Saving the optimizer state is important to produce consistent results\n",
        "                    checkpoint = {\n",
        "                        'epoch': epoch+1,\n",
        "                        'model': self.model.state_dict(),\n",
        "                        'optimizer': optim.state_dict()}\n",
        "                    torch.save(checkpoint,\n",
        "                        os.path.join(checkpoints_dir, 'model_epoch_%04d.pth' % (epoch+1)))\n",
        "                    np.savetxt(os.path.join(checkpoints_dir, 'train_losses_epoch_%04d.txt' % (epoch+1)),\n",
        "                        np.array(train_losses))\n",
        "                    self.validate(\n",
        "                        device=device, epoch=epoch+1, save_path=os.path.join(checkpoints_dir, 'BRS_validation_plot_epoch_%04d.png' % (epoch+1)),\n",
        "                        x_resolution = val_x_resolution, y_resolution = val_y_resolution, z_resolution=val_z_resolution, time_resolution=val_time_resolution)\n",
        "\n",
        "        if was_eval:\n",
        "            self.model.eval()\n",
        "            self.model.requires_grad_(False)\n",
        "\n",
        "    def test(self, device, current_time, last_checkpoint, checkpoint_dt, dt, num_scenarios, num_violations, set_type, control_type, data_step, checkpoint_toload=None):\n",
        "        was_training = self.model.training\n",
        "        self.model.eval()\n",
        "        self.model.requires_grad_(False)\n",
        "\n",
        "        testing_dir = os.path.join(self.experiment_dir, 'testing_%s' % current_time.strftime('%m_%d_%Y_%H_%M'))\n",
        "        if os.path.exists(testing_dir):\n",
        "            overwrite = input(\"The testing directory %s already exists. Overwrite? (y/n)\"%testing_dir)\n",
        "            if not (overwrite == 'y'):\n",
        "                print('Exiting.')\n",
        "                quit()\n",
        "            shutil.rmtree(testing_dir)\n",
        "        os.makedirs(testing_dir)\n",
        "\n",
        "        if checkpoint_toload is None:\n",
        "            print('running cross-checkpoint testing')\n",
        "\n",
        "            for i in tqdm(range(sidelen), desc='Checkpoint'):\n",
        "                self._load_checkpoint(epoch=checkpoints[i])\n",
        "                raise NotImplementedError\n",
        "\n",
        "        else:\n",
        "            print('running specific-checkpoint testing')\n",
        "            self._load_checkpoint(checkpoint_toload)\n",
        "\n",
        "            model = self.model\n",
        "            dataset = self.dataset\n",
        "            dynamics = dataset.dynamics\n",
        "            raise NotImplementedError\n",
        "\n",
        "        if was_training:\n",
        "            self.model.train()\n",
        "            self.model.requires_grad_(True)\n",
        "\n",
        "class DeepReach(Experiment):\n",
        "    def init_special(self):\n",
        "        pass"
      ],
      "metadata": {
        "id": "QMWFvhr8ECTy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Run Experiment"
      ],
      "metadata": {
        "id": "aA4ZpF_vE8wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "PDz8C2x_Q3gE",
        "outputId": "6664a807-40c0-4d5d-8829-cf76b05b5c94"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maanirudh\u001b[0m (\u001b[33maanirudh-n-a\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "sys.argv = [\n",
        "    \"script_name\",  # Placeholder for script name (ignored by argparse)\n",
        "    \"--mode\", \"train\",\n",
        "    \"--experiment_class\", \"DeepReach\",\n",
        "    \"--dynamics_class\", \"PlanarRobot2D\",\n",
        "    \"--experiment_name\", \"brt_goal_025m\",\n",
        "    \"--minWith\", \"target\",\n",
        "    \"--goalR\", \"0.25\",\n",
        "    \"--velocity\", \"1.0\",\n",
        "    \"--set_mode\", \"reach\",\n",
        "    \"--num_epochs\", \"45000\",\n",
        "\n",
        "    \"--wandb_project\", \"reachability-experiments\",\n",
        "    \"--wandb_entity\", \"aanirudh-n-a\",\n",
        "    '--wandb_group', \"Training\",\n",
        "    '--wandb_name', \"brt_goal_025m_run_01\",\n",
        "]"
      ],
      "metadata": {
        "id": "F6Uc01CzFDSb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "from inspect import isclass\n",
        "p = configargparse.ArgumentParser()\n",
        "\n",
        "p.add_argument('-c', '--config_filepath', required=False, is_config_file=True, help='Path to config file.')\n",
        "p.add_argument('--mode', type=str, required=True, choices=['all', 'train', 'test'], help=\"Experiment mode to run (new experiments must choose 'all' or 'train').\")\n",
        "\n",
        "# save/load directory options\n",
        "p.add_argument('--experiments_dir', type=str, default='./runs', help='Where to save the experiment subdirectory.')\n",
        "p.add_argument('--experiment_name', type=str, required=True, help='Name of the experient subdirectory.')\n",
        "p.add_argument('--use_wandb', default=True, action='store_false', help='use wandb for logging')\n",
        "\n",
        "use_wandb = p.parse_known_args()[0].use_wandb\n",
        "if use_wandb:\n",
        "    p.add_argument('--wandb_project', type=str, required=True, help='wandb project')\n",
        "    p.add_argument('--wandb_entity', type=str, required=True, help='wandb entity')\n",
        "    p.add_argument('--wandb_group', type=str, required=True, help='wandb group')\n",
        "    p.add_argument('--wandb_name', type=str, required=True, help='name of wandb run')\n",
        "\n",
        "mode = p.parse_known_args()[0].mode\n",
        "\n",
        "if (mode == 'all') or (mode == 'train'):\n",
        "    p.add_argument('--seed', type=int, default=0, required=False, help='Seed for the experiment.')\n",
        "\n",
        "    # load experiment_class choices dynamically from experiments module\n",
        "    experiment_classes_dict = {\n",
        "        name: clss for name, clss in globals().items()\n",
        "        if isclass(clss) and issubclass(clss, Experiment) and clss is not Experiment\n",
        "    }\n",
        "    # experiment_classes_dict = {name: clss for name, clss in inspect.getmembers(experiments, inspect.isclass) if clss.__bases__[0] == experiments.Experiment}\n",
        "    p.add_argument('--experiment_class', type=str, default='DeepReach', choices=experiment_classes_dict.keys(), help='Experiment class to use.')\n",
        "    # load special experiment_class arguments dynamically from chosen experiment class\n",
        "    experiment_class = DeepReach #experiment_classes_dict[p.parse_known_args()[0].experiment_class]\n",
        "    experiment_params = {name: param for name, param in inspect.signature(experiment_class.init_special).parameters.items() if name != 'self'}\n",
        "    for param in experiment_params.keys():\n",
        "        p.add_argument('--' + param, type=experiment_params[param].annotation, required=True, help='special experiment_class argument')\n",
        "\n",
        "    # simulation data source options\n",
        "    p.add_argument('--device', type=str, default='cuda:0', required=False, help='CUDA Device to use.')\n",
        "    p.add_argument('--numpoints', type=int, default=65000, help='Number of points in simulation data source __getitem__.')\n",
        "    p.add_argument('--pretrain', action='store_true', default=False, required=False, help='Pretrain dirichlet conditions')\n",
        "    p.add_argument('--pretrain_iters', type=int, default=2000, required=False, help='Number of pretrain iterations')\n",
        "    p.add_argument('--tMin', type=float, default=0.0, required=False, help='Start time of the simulation')\n",
        "    p.add_argument('--tMax', type=float, default=1.0, required=False, help='End time of the simulation')\n",
        "    p.add_argument('--counter_start', type=int, default=0, required=False, help='Defines the initial time for the curriculum training')\n",
        "    p.add_argument('--counter_end', type=int, default=-1, required=False, help='Defines the linear step for curriculum training starting from the initial time')\n",
        "    p.add_argument('--num_src_samples', type=int, default=1000, required=False, help='Number of source samples (initial-time samples) at each time step')\n",
        "    p.add_argument('--num_target_samples', type=int, default=0, required=False, help='Number of samples inside the target set')\n",
        "\n",
        "    # model options\n",
        "    p.add_argument('--model', type=str, default='sine', required=False, choices=['sine', 'tanh', 'sigmoid', 'relu'], help='Type of model to evaluate, default is sine.')\n",
        "    p.add_argument('--model_mode', type=str, default='mlp', required=False, choices=['mlp', 'rbf', 'pinn'], help='Whether to use uniform velocity parameter')\n",
        "    p.add_argument('--num_hl', type=int, default=3, required=False, help='The number of hidden layers')\n",
        "    p.add_argument('--num_nl', type=int, default=512, required=False, help='Number of neurons per hidden layer.')\n",
        "    p.add_argument('--deepreach_model', type=str, default='exact', required=False, choices=['exact', 'diff', 'vanilla'], help='deepreach model')\n",
        "\n",
        "    # training options\n",
        "    p.add_argument('--epochs_til_ckpt', type=int, default=1000, help='Time interval in seconds until checkpoint is saved.')\n",
        "    p.add_argument('--steps_til_summary', type=int, default=100, help='Time interval in seconds until tensorboard summary is saved.')\n",
        "    p.add_argument('--batch_size', type=int, default=1, help='Batch size used during training (irrelevant, since len(dataset) == 1).')\n",
        "    p.add_argument('--lr', type=float, default=2e-5, help='learning rate. default=2e-5')\n",
        "    p.add_argument('--num_epochs', type=int, default=100000, help='Number of epochs to train for.')\n",
        "    p.add_argument('--clip_grad', default=0.0, type=float, help='Clip gradient.')\n",
        "    p.add_argument('--use_lbfgs', default=False, type=bool, help='use L-BFGS.')\n",
        "    p.add_argument('--adj_rel_grads', default=True, type=bool, help='adjust the relative magnitude of the losses')\n",
        "    p.add_argument('--dirichlet_loss_divisor', default=1.0, required=False, type=float, help='What to divide the dirichlet loss by for loss reweighting')\n",
        "\n",
        "    # cost-supervised learning (CSL) options\n",
        "    p.add_argument('--use_CSL', default=False, action='store_true', help='use cost-supervised learning (CSL)')\n",
        "    p.add_argument('--CSL_lr', type=float, default=2e-5, help='The learning rate used for CSL')\n",
        "    p.add_argument('--CSL_dt', type=float, default=0.0025, help='The dt used in rolling out trajectories to get cost labels')\n",
        "    p.add_argument('--epochs_til_CSL', type=int, default=10000, help='Number of epochs between CSL phases')\n",
        "    p.add_argument('--num_CSL_samples', type=int, default=1000000, help='Number of cost samples in training dataset for CSL phases')\n",
        "    p.add_argument('--CSL_loss_frac_cutoff', type=float, default=0.1, help='Fraction of initial cost loss on validation dataset to cutoff CSL phases')\n",
        "    p.add_argument('--max_CSL_epochs', type=int, default=100, help='Max number of CSL epochs per phase')\n",
        "    p.add_argument('--CSL_loss_weight', type=float, default=1.0, help='weight of cost loss (relative to PDE loss)')\n",
        "    p.add_argument('--CSL_batch_size', type=int, default=1000, help='Batch size for training in CSL phases')\n",
        "\n",
        "    # validation (during training) options\n",
        "    p.add_argument('--val_x_resolution', type=int, default=200, help='x-axis resolution of validation plot during training')\n",
        "    p.add_argument('--val_y_resolution', type=int, default=200, help='y-axis resolution of validation plot during training')\n",
        "    p.add_argument('--val_z_resolution', type=int, default=5, help='z-axis resolution of validation plot during training')\n",
        "    p.add_argument('--val_time_resolution', type=int, default=3, help='time-axis resolution of validation plot during training')\n",
        "\n",
        "    # loss options\n",
        "    p.add_argument('--minWith', type=str, required=True, choices=['none', 'zero', 'target'], help='BRS vs BRT computation (typically should be using target for BRT)')\n",
        "\n",
        "    # # load dynamics_class choices dynamically from dynamics module\n",
        "    # dynamics_classes_dict = {name: clss for name, clss in inspect.getmembers(dynamics, inspect.isclass) if clss.__bases__[0] == dynamics.Dynamics}\n",
        "    p.add_argument('--dynamics_class', type=str, required=True, choices=[\"PlanarRobot2D\"], help='Dynamics class to use.')\n",
        "    # # load special dynamics_class arguments dynamically from chosen dynamics class\n",
        "    # dynamics_class = dynamics_classes_dict[p.parse_known_args()[0].dynamics_class]\n",
        "    # dynamics_params = {name: param for name, param in inspect.signature(dynamics_class).parameters.items() if name != 'self'}\n",
        "    dynamics_class = PlanarRobot2D\n",
        "    dynamics_params = {\n",
        "        name: param for name, param in inspect.signature(dynamics_class).parameters.items() if name != 'self'\n",
        "    }\n",
        "\n",
        "    for param in dynamics_params.keys():\n",
        "        if dynamics_params[param].annotation is bool:\n",
        "            p.add_argument('--' + param, type=dynamics_params[param].annotation, default=False, help='special dynamics_class argument')\n",
        "        else:\n",
        "            p.add_argument('--' + param, type=dynamics_params[param].annotation, required=True, help='special dynamics_class argument')\n",
        "\n",
        "if (mode == 'all') or (mode == 'test'):\n",
        "    p.add_argument('--dt', type=float, default=0.0025, help='The dt used in testing simulations')\n",
        "    p.add_argument('--checkpoint_toload', type=int, default=None, help=\"The checkpoint to load for testing (-1 for final training checkpoint, None for cross-checkpoint testing\")\n",
        "    p.add_argument('--num_scenarios', type=int, default=100000, help='The number of scenarios sampled in scenario optimization for testing')\n",
        "    p.add_argument('--num_violations', type=int, default=1000, help='The number of violations to sample for in scenario optimization for testing')\n",
        "    p.add_argument('--control_type', type=str, default='value', choices=['value', 'ttr', 'init_ttr'], help='The controller to use in scenario optimization for testing')\n",
        "    p.add_argument('--data_step', type=str, default='run_basic_recovery', choices=['plot_violations', 'run_basic_recovery', 'plot_basic_recovery', 'collect_samples', 'train_binner', 'run_binned_recovery', 'plot_binned_recovery', 'plot_cost_function'], help='The data processing step to run')\n",
        "\n",
        "opt = p.parse_args()\n",
        "\n",
        "# start wandb\n",
        "if use_wandb:\n",
        "    wandb.init(\n",
        "        project = opt.wandb_project,\n",
        "        entity = opt.wandb_entity,\n",
        "        group = opt.wandb_group,\n",
        "        name = opt.wandb_name,\n",
        "    )\n",
        "    wandb.config.update(opt)\n",
        "\n",
        "experiment_dir = os.path.join(opt.experiments_dir, opt.experiment_name)\n",
        "if (mode == 'all') or (mode == 'train'):\n",
        "    # create experiment dir\n",
        "    if os.path.exists(experiment_dir):\n",
        "        overwrite = input(\"The experiment directory %s already exists. Overwrite? (y/n)\"%experiment_dir)\n",
        "        if not (overwrite == 'y'):\n",
        "            print('Exiting.')\n",
        "            quit()\n",
        "        shutil.rmtree(experiment_dir)\n",
        "    os.makedirs(experiment_dir)\n",
        "elif mode == 'test':\n",
        "    # confirm that experiment dir already exists\n",
        "    if not os.path.exists(experiment_dir):\n",
        "        raise RuntimeError('Cannot run test mode: experiment directory not found!')\n",
        "\n",
        "current_time = datetime.now()\n",
        "# log current config\n",
        "with open(os.path.join(experiment_dir, 'config_%s.txt' % current_time.strftime('%m_%d_%Y_%H_%M')), 'w') as f:\n",
        "    for arg, val in vars(opt).items():\n",
        "        f.write(arg + ' = ' + str(val) + '\\n')\n",
        "\n",
        "if (mode == 'all') or (mode == 'train'):\n",
        "    # set counter_end appropriately if needed\n",
        "    if opt.counter_end == -1:\n",
        "        opt.counter_end = opt.num_epochs\n",
        "\n",
        "    # log original options\n",
        "    with open(os.path.join(experiment_dir, 'orig_opt.pickle'), 'wb') as opt_file:\n",
        "        pickle.dump(opt, opt_file)\n",
        "\n",
        "# load original experiment settings\n",
        "with open(os.path.join(experiment_dir, 'orig_opt.pickle'), 'rb') as opt_file:\n",
        "    orig_opt = pickle.load(opt_file)\n",
        "\n",
        "# set the experiment seed\n",
        "torch.manual_seed(orig_opt.seed)\n",
        "random.seed(orig_opt.seed)\n",
        "np.random.seed(orig_opt.seed)\n",
        "\n",
        "dynamics_class = PlanarRobot2D #getattr(dynamics, orig_opt.dynamics_class)\n",
        "dynamics = dynamics_class(**{argname: getattr(orig_opt, argname) for argname in inspect.signature(dynamics_class).parameters.keys() if argname != 'self'})\n",
        "dynamics.deepreach_model=orig_opt.deepreach_model\n",
        "dataset = ReachabilityDataset(\n",
        "    dynamics=dynamics, numpoints=orig_opt.numpoints,\n",
        "    pretrain=orig_opt.pretrain, pretrain_iters=orig_opt.pretrain_iters,\n",
        "    tMin=orig_opt.tMin, tMax=orig_opt.tMax,\n",
        "    counter_start=orig_opt.counter_start, counter_end=orig_opt.counter_end,\n",
        "    num_src_samples=orig_opt.num_src_samples, num_target_samples=orig_opt.num_target_samples)\n",
        "\n",
        "model = SingleBVPNet(in_features=dynamics.input_dim, out_features=1, type=orig_opt.model, mode=orig_opt.model_mode,\n",
        "                             final_layer_factor=1., hidden_features=orig_opt.num_nl, num_hidden_layers=orig_opt.num_hl)\n",
        "model.to(opt.device)\n",
        "\n",
        "experiment_class = DeepReach #getattr(experiments, orig_opt.experiment_class)\n",
        "experiment = experiment_class(model=model, dataset=dataset, experiment_dir=experiment_dir, use_wandb=use_wandb)\n",
        "experiment.init_special(**{argname: getattr(orig_opt, argname) for argname in inspect.signature(experiment_class.init_special).parameters.keys() if argname != 'self'})\n",
        "\n",
        "if (mode == 'all') or (mode == 'train'):\n",
        "    if dynamics.loss_type == 'brt_hjivi':\n",
        "        loss_fn = init_brt_hjivi_loss(dynamics, orig_opt.minWith, orig_opt.dirichlet_loss_divisor)\n",
        "    elif dynamics.loss_type == 'brat_hjivi':\n",
        "        loss_fn = init_brat_hjivi_loss(dynamics, orig_opt.minWith, orig_opt.dirichlet_loss_divisor)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    experiment.train(\n",
        "        device=opt.device, batch_size=orig_opt.batch_size, epochs=orig_opt.num_epochs, lr=orig_opt.lr,\n",
        "        steps_til_summary=orig_opt.steps_til_summary, epochs_til_checkpoint=orig_opt.epochs_til_ckpt,\n",
        "        loss_fn=loss_fn, clip_grad=orig_opt.clip_grad, use_lbfgs=orig_opt.use_lbfgs, adjust_relative_grads=orig_opt.adj_rel_grads,\n",
        "        val_x_resolution=orig_opt.val_x_resolution, val_y_resolution=orig_opt.val_y_resolution, val_z_resolution=orig_opt.val_z_resolution, val_time_resolution=orig_opt.val_time_resolution,\n",
        "        use_CSL=orig_opt.use_CSL, CSL_lr=orig_opt.CSL_lr, CSL_dt=orig_opt.CSL_dt, epochs_til_CSL=orig_opt.epochs_til_CSL, num_CSL_samples=orig_opt.num_CSL_samples, CSL_loss_frac_cutoff=orig_opt.CSL_loss_frac_cutoff, max_CSL_epochs=orig_opt.max_CSL_epochs, CSL_loss_weight=orig_opt.CSL_loss_weight, CSL_batch_size=orig_opt.CSL_batch_size)\n",
        "\n",
        "if (mode == 'all') or (mode == 'test'):\n",
        "    experiment.test(\n",
        "        device=opt.device, current_time=current_time,\n",
        "        last_checkpoint=orig_opt.num_epochs, checkpoint_dt=orig_opt.epochs_til_ckpt,\n",
        "        checkpoint_toload=opt.checkpoint_toload, dt=opt.dt,\n",
        "        num_scenarios=opt.num_scenarios, num_violations=opt.num_violations,\n",
        "        set_type='BRT' if orig_opt.minWith in ['zero', 'target'] else 'BRS', control_type=opt.control_type, data_step=opt.data_step)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uC4PdfSbE-2l",
        "outputId": "4ac2f4d1-e92e-4046-eb26-2c916c59efbe"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/My Drive/wandb/run-20250419_135447-zg4ccqj5</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/aanirudh-n-a/reachability-experiments/runs/zg4ccqj5' target=\"_blank\">brt_goal_025m_run_01</a></strong> to <a href='https://wandb.ai/aanirudh-n-a/reachability-experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/aanirudh-n-a/reachability-experiments' target=\"_blank\">https://wandb.ai/aanirudh-n-a/reachability-experiments</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/aanirudh-n-a/reachability-experiments/runs/zg4ccqj5' target=\"_blank\">https://wandb.ai/aanirudh-n-a/reachability-experiments/runs/zg4ccqj5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SingleBVPNet(\n",
            "  (net): FCBlock(\n",
            "    (net): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): BatchLinear(in_features=3, out_features=512, bias=True)\n",
            "        (1): Sine()\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): BatchLinear(in_features=512, out_features=512, bias=True)\n",
            "        (1): Sine()\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): BatchLinear(in_features=512, out_features=512, bias=True)\n",
            "        (1): Sine()\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (0): BatchLinear(in_features=512, out_features=512, bias=True)\n",
            "        (1): Sine()\n",
            "      )\n",
            "      (4): Sequential(\n",
            "        (0): BatchLinear(in_features=512, out_features=1, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/45000 [00:01<17:38:44,  1.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Total loss 2817.822021, iteration time 1.388211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 102/45000 [00:22<2:43:27,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100, Total loss 507.876862, iteration time 0.223210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 202/45000 [00:44<2:52:59,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 200, Total loss 185.247498, iteration time 0.244905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 302/45000 [01:06<2:51:27,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 300, Total loss 298.409607, iteration time 0.235880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 402/45000 [01:30<2:57:58,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 400, Total loss 383.542908, iteration time 0.246486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 502/45000 [01:53<2:54:47,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Total loss 711.284119, iteration time 0.229558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 602/45000 [02:15<2:51:32,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 600, Total loss 602.290283, iteration time 0.234004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 702/45000 [02:38<2:49:41,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 700, Total loss 735.211182, iteration time 0.236336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 802/45000 [03:00<2:50:35,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 800, Total loss 851.230713, iteration time 0.245440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 902/45000 [03:23<2:49:38,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 900, Total loss 885.404602, iteration time 0.237290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 1002/45000 [03:46<4:35:01,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1000, Total loss 2202.255859, iteration time 0.096160\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 1102/45000 [04:09<2:52:32,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1100, Total loss 1013.609497, iteration time 0.256852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 1202/45000 [04:32<2:50:40,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1200, Total loss 1166.095459, iteration time 0.238873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 1302/45000 [04:55<2:48:35,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1300, Total loss 1409.507080, iteration time 0.232023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 1402/45000 [05:18<2:53:49,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1400, Total loss 1322.895874, iteration time 0.245464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 1502/45000 [05:40<2:47:48,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1500, Total loss 1595.369141, iteration time 0.236311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▎         | 1602/45000 [06:03<2:51:22,  4.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1600, Total loss 1407.250732, iteration time 0.248707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 1702/45000 [06:26<2:48:33,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1700, Total loss 1598.338867, iteration time 0.240109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 1802/45000 [06:49<2:48:23,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1800, Total loss 1573.339478, iteration time 0.237429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 1902/45000 [07:12<2:48:41,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1900, Total loss 1565.680298, iteration time 0.237058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 2002/45000 [07:35<4:00:32,  2.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2000, Total loss 2026.873535, iteration time 0.094524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▍         | 2102/45000 [07:58<2:46:21,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2100, Total loss 1904.078857, iteration time 0.234542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▍         | 2202/45000 [08:21<2:46:52,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2200, Total loss 2016.972412, iteration time 0.235783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 2302/45000 [08:44<2:47:41,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2300, Total loss 1864.442871, iteration time 0.229340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 2402/45000 [09:07<2:44:15,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2400, Total loss 4212.590820, iteration time 0.233178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 2502/45000 [09:29<2:48:22,  4.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2500, Total loss 2308.892090, iteration time 0.254353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 2602/45000 [09:52<2:46:49,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2600, Total loss 2102.637695, iteration time 0.250816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 2702/45000 [10:15<2:45:57,  4.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2700, Total loss 1931.611816, iteration time 0.241401\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 2802/45000 [10:38<2:50:24,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2800, Total loss 2337.413818, iteration time 0.232911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▋         | 2902/45000 [11:01<2:43:34,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2900, Total loss 2459.489990, iteration time 0.236241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 3002/45000 [11:25<3:56:48,  2.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3000, Total loss 1823.517456, iteration time 0.092428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 3102/45000 [11:48<2:43:47,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3100, Total loss 2808.748047, iteration time 0.252592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 3202/45000 [12:11<2:45:22,  4.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3200, Total loss 3031.921631, iteration time 0.257138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 3302/45000 [12:34<2:42:20,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3300, Total loss 2615.085938, iteration time 0.241251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 3402/45000 [12:57<2:42:24,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3400, Total loss 2117.352295, iteration time 0.241671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 3502/45000 [13:20<2:44:30,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3500, Total loss 2350.847900, iteration time 0.245438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 3602/45000 [13:43<2:42:54,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3600, Total loss 1544.615601, iteration time 0.244481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 3702/45000 [14:07<2:43:45,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3700, Total loss 1368.176270, iteration time 0.244787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 3802/45000 [14:30<2:46:04,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3800, Total loss 2216.078613, iteration time 0.249014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▊         | 3902/45000 [14:54<2:43:52,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3900, Total loss 987.698547, iteration time 0.244878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 4002/45000 [15:18<3:56:30,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4000, Total loss 826.748291, iteration time 0.093683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 4102/45000 [15:41<2:43:08,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4100, Total loss 873.955078, iteration time 0.246229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 4202/45000 [16:05<2:46:08,  4.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4200, Total loss 683.044739, iteration time 0.247651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 4302/45000 [16:29<2:43:19,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4300, Total loss 1033.001221, iteration time 0.251342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 4402/45000 [16:52<2:41:20,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4400, Total loss 3393.323730, iteration time 0.243174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 4502/45000 [17:16<2:42:02,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4500, Total loss 921.447632, iteration time 0.245787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 4602/45000 [17:39<2:43:35,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4600, Total loss 548.739136, iteration time 0.245742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 4702/45000 [18:03<2:40:06,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4700, Total loss 1090.715698, iteration time 0.246055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 4802/45000 [18:27<2:40:45,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4800, Total loss 917.823730, iteration time 0.248492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 4902/45000 [18:50<2:40:18,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4900, Total loss 342.309692, iteration time 0.251320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 5002/45000 [19:14<4:06:49,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5000, Total loss 463.711426, iteration time 0.101013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█▏        | 5102/45000 [19:38<2:38:09,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5100, Total loss 799.005859, iteration time 0.241951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 5202/45000 [20:01<2:37:37,  4.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5200, Total loss 911.266602, iteration time 0.243294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 5302/45000 [20:25<2:40:34,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5300, Total loss 1170.175537, iteration time 0.261164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 5402/45000 [20:49<2:37:11,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5400, Total loss 1037.520020, iteration time 0.245930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 5502/45000 [21:12<2:37:10,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5500, Total loss 844.266479, iteration time 0.252408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 5602/45000 [21:36<2:38:14,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5600, Total loss 1098.082031, iteration time 0.247720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 5702/45000 [22:00<2:38:40,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5700, Total loss 528.162109, iteration time 0.248439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 5802/45000 [22:23<2:35:20,  4.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5800, Total loss 332.950043, iteration time 0.244660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 5902/45000 [22:47<2:34:57,  4.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5900, Total loss 652.235535, iteration time 0.244873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 6002/45000 [23:11<3:41:27,  2.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6000, Total loss 530.814453, iteration time 0.095436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▎        | 6102/45000 [23:34<2:35:49,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6100, Total loss 747.520630, iteration time 0.244804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 6202/45000 [23:58<2:35:14,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6200, Total loss 796.821777, iteration time 0.247775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 6302/45000 [24:21<2:33:12,  4.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6300, Total loss 487.250427, iteration time 0.243612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 6402/45000 [24:45<2:33:34,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6400, Total loss 449.239838, iteration time 0.245441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 6502/45000 [25:09<2:34:59,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6500, Total loss 374.452881, iteration time 0.250111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▍        | 6602/45000 [25:32<2:33:39,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6600, Total loss 733.980286, iteration time 0.244485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▍        | 6702/45000 [25:56<2:32:08,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6700, Total loss 556.958130, iteration time 0.243507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 6802/45000 [26:19<2:31:38,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6800, Total loss 772.640869, iteration time 0.242119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 6902/45000 [26:43<2:32:50,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6900, Total loss 573.966431, iteration time 0.247012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 7002/45000 [27:07<3:34:27,  2.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7000, Total loss 997.005737, iteration time 0.093116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 7102/45000 [27:31<2:30:53,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7100, Total loss 941.904480, iteration time 0.247044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 7202/45000 [27:54<2:33:48,  4.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7200, Total loss 606.532227, iteration time 0.250294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 7302/45000 [28:18<2:31:20,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7300, Total loss 731.556030, iteration time 0.247191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▋        | 7402/45000 [28:42<2:32:01,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7400, Total loss 551.788208, iteration time 0.253848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 7502/45000 [29:05<2:29:42,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7500, Total loss 715.811829, iteration time 0.249096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 7602/45000 [29:29<2:30:44,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7600, Total loss 596.209595, iteration time 0.248981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 7702/45000 [29:53<2:28:56,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7700, Total loss 802.969421, iteration time 0.245103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 7802/45000 [30:16<2:28:58,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7800, Total loss 664.283936, iteration time 0.247367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 7902/45000 [30:40<2:30:52,  4.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7900, Total loss 631.057739, iteration time 0.252086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 8002/45000 [31:04<3:33:34,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8000, Total loss 817.972046, iteration time 0.096501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 8102/45000 [31:28<2:28:21,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8100, Total loss 779.764099, iteration time 0.247394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 8202/45000 [31:51<2:26:41,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8200, Total loss 765.567383, iteration time 0.245070\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 8302/45000 [32:15<2:27:42,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8300, Total loss 791.049744, iteration time 0.247134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▊        | 8402/45000 [32:39<2:27:18,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8400, Total loss 520.236633, iteration time 0.250886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 8502/45000 [33:02<2:26:23,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8500, Total loss 699.758118, iteration time 0.245311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 8602/45000 [33:26<2:24:57,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8600, Total loss 681.669678, iteration time 0.248459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 8702/45000 [33:50<2:26:36,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8700, Total loss 673.999756, iteration time 0.241456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 8802/45000 [34:13<2:24:55,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8800, Total loss 764.884460, iteration time 0.248406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 8902/45000 [34:37<2:24:34,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8900, Total loss 673.497803, iteration time 0.247563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 9002/45000 [35:01<3:26:16,  2.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9000, Total loss 658.550537, iteration time 0.093107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 9102/45000 [35:25<2:24:57,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9100, Total loss 688.969116, iteration time 0.246886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 9202/45000 [35:48<2:22:42,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9200, Total loss 652.657288, iteration time 0.246350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 9302/45000 [36:12<2:24:20,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9300, Total loss 742.021851, iteration time 0.249128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 9402/45000 [36:36<2:21:22,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9400, Total loss 669.725403, iteration time 0.242592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 9502/45000 [36:59<2:24:58,  4.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9500, Total loss 637.526306, iteration time 0.249325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██▏       | 9602/45000 [37:23<2:23:56,  4.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9600, Total loss 655.939575, iteration time 0.264344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 9702/45000 [37:47<2:21:47,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9700, Total loss 824.938721, iteration time 0.248415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 9802/45000 [38:10<2:22:13,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9800, Total loss 645.577759, iteration time 0.247441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 9902/45000 [38:34<2:20:13,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9900, Total loss 692.014404, iteration time 0.248538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 10002/45000 [38:58<3:22:04,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10000, Total loss 679.061462, iteration time 0.099638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 10102/45000 [39:22<2:20:19,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10100, Total loss 711.914856, iteration time 0.246793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 10202/45000 [39:46<2:20:58,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10200, Total loss 621.690308, iteration time 0.248328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 10302/45000 [40:09<2:19:35,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10300, Total loss 622.829956, iteration time 0.243291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 10402/45000 [40:33<2:17:44,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10400, Total loss 631.420410, iteration time 0.243499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 10502/45000 [40:57<2:18:34,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10500, Total loss 716.406799, iteration time 0.248992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▎       | 10602/45000 [41:20<2:18:22,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10600, Total loss 705.950134, iteration time 0.251254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 10702/45000 [41:44<2:17:38,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10700, Total loss 607.900269, iteration time 0.247649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 10802/45000 [42:08<2:16:39,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10800, Total loss 560.507080, iteration time 0.247642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 10902/45000 [42:31<2:15:34,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10900, Total loss 247.174072, iteration time 0.244803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 11002/45000 [42:56<4:43:08,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11000, Total loss 442.213989, iteration time 0.099860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 11102/45000 [43:20<2:16:01,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11100, Total loss 183.924011, iteration time 0.248208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 11202/45000 [43:43<2:14:47,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11200, Total loss 300.887634, iteration time 0.244558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 11302/45000 [44:07<2:13:50,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11300, Total loss 292.148010, iteration time 0.241862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 11402/45000 [44:31<2:14:22,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11400, Total loss 2019.467407, iteration time 0.254914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 11502/45000 [44:54<2:13:13,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11500, Total loss 331.886475, iteration time 0.248223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 11602/45000 [45:18<2:13:29,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11600, Total loss 352.261047, iteration time 0.245939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 11702/45000 [45:41<2:14:11,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11700, Total loss 397.842468, iteration time 0.244022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 11802/45000 [46:05<2:11:13,  4.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11800, Total loss 793.717896, iteration time 0.241121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▋       | 11902/45000 [46:28<2:12:40,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11900, Total loss 684.421021, iteration time 0.242883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 12002/45000 [46:52<3:09:30,  2.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12000, Total loss 630.299194, iteration time 0.105369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 12102/45000 [47:16<2:13:17,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12100, Total loss 717.731995, iteration time 0.247389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 12202/45000 [47:40<2:14:15,  4.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12200, Total loss 611.852051, iteration time 0.254199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 12302/45000 [48:03<2:09:46,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12300, Total loss 621.479980, iteration time 0.245750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 12402/45000 [48:27<2:09:46,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12400, Total loss 688.050781, iteration time 0.233485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 12502/45000 [48:50<2:12:09,  4.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12500, Total loss 584.067505, iteration time 0.254250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 12602/45000 [49:14<2:11:34,  4.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12600, Total loss 619.130249, iteration time 0.256915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 12702/45000 [49:38<2:08:45,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12700, Total loss 603.801270, iteration time 0.246539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 12802/45000 [50:01<2:10:48,  4.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12800, Total loss 561.277588, iteration time 0.248618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▊       | 12902/45000 [50:25<2:09:00,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12900, Total loss 605.083130, iteration time 0.247309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 13002/45000 [50:49<3:03:51,  2.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13000, Total loss 622.548462, iteration time 0.092146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 13102/45000 [51:13<2:06:48,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13100, Total loss 569.824951, iteration time 0.242949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 13202/45000 [51:37<2:08:18,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13200, Total loss 450.020966, iteration time 0.246177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 13302/45000 [52:00<2:05:40,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13300, Total loss 646.838257, iteration time 0.241806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 13402/45000 [52:24<2:07:00,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13400, Total loss 599.326355, iteration time 0.246715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 13502/45000 [52:48<2:06:38,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13500, Total loss 650.514648, iteration time 0.247274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 13602/45000 [53:11<2:04:51,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13600, Total loss 584.735107, iteration time 0.240973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 13702/45000 [53:35<2:04:49,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13700, Total loss 633.565430, iteration time 0.242883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 13802/45000 [53:58<2:05:09,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13800, Total loss 641.470886, iteration time 0.246871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 13902/45000 [54:22<2:05:35,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13900, Total loss 656.487671, iteration time 0.249929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 14002/45000 [54:46<2:59:18,  2.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14000, Total loss 651.697754, iteration time 0.095711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███▏      | 14102/45000 [55:10<2:04:41,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14100, Total loss 564.052734, iteration time 0.246474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 14202/45000 [55:34<2:03:22,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14200, Total loss 663.197937, iteration time 0.250516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 14302/45000 [55:57<2:04:59,  4.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14300, Total loss 613.274902, iteration time 0.252460\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 14402/45000 [56:21<2:02:32,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14400, Total loss 562.850952, iteration time 0.246956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 14502/45000 [56:45<2:01:04,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14500, Total loss 535.503113, iteration time 0.249681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 14602/45000 [57:08<2:03:18,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14600, Total loss 814.091980, iteration time 0.243283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 14702/45000 [57:32<2:01:51,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14700, Total loss 463.645508, iteration time 0.251951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 14802/45000 [57:56<2:00:31,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14800, Total loss 586.682129, iteration time 0.249735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 14902/45000 [58:19<2:00:23,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14900, Total loss 578.967041, iteration time 0.246873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 15002/45000 [58:44<3:20:27,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15000, Total loss 668.875671, iteration time 0.107566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▎      | 15102/45000 [59:07<2:00:14,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15100, Total loss 596.176758, iteration time 0.256258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 15202/45000 [59:31<1:58:54,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15200, Total loss 586.781555, iteration time 0.249658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 15302/45000 [59:55<1:57:56,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15300, Total loss 581.680359, iteration time 0.243531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 15402/45000 [1:00:18<1:59:38,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15400, Total loss 571.798645, iteration time 0.254205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 15502/45000 [1:00:42<1:57:16,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15500, Total loss 616.792480, iteration time 0.242976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 15602/45000 [1:01:06<1:58:30,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15600, Total loss 479.115540, iteration time 0.246304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 15702/45000 [1:01:29<1:58:21,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15700, Total loss 683.122803, iteration time 0.249635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 15802/45000 [1:01:53<1:56:40,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15800, Total loss 503.144012, iteration time 0.253201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 15902/45000 [1:02:17<1:57:10,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15900, Total loss 499.883606, iteration time 0.246731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 16002/45000 [1:02:41<2:46:21,  2.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16000, Total loss 494.253937, iteration time 0.094003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 16102/45000 [1:03:05<1:55:44,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16100, Total loss 496.409546, iteration time 0.246126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 16202/45000 [1:03:28<1:56:28,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16200, Total loss 578.552856, iteration time 0.247154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 16302/45000 [1:03:52<1:55:10,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16300, Total loss 621.868286, iteration time 0.248517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▋      | 16402/45000 [1:04:16<1:54:02,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16400, Total loss 659.369629, iteration time 0.244613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 16502/45000 [1:04:39<1:55:26,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16500, Total loss 582.930420, iteration time 0.252254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 16602/45000 [1:05:03<1:53:49,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16600, Total loss 716.932495, iteration time 0.248102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 16702/45000 [1:05:27<1:52:59,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16700, Total loss 544.915405, iteration time 0.242747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 16802/45000 [1:05:50<1:53:05,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16800, Total loss 599.034180, iteration time 0.254563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 16902/45000 [1:06:14<1:53:52,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16900, Total loss 203.700958, iteration time 0.257776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 17002/45000 [1:06:38<2:41:19,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17000, Total loss 192.980835, iteration time 0.095970\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 17102/45000 [1:07:02<1:51:40,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17100, Total loss 155.259003, iteration time 0.246319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 17202/45000 [1:07:25<1:51:37,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17200, Total loss 225.070679, iteration time 0.256849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 17302/45000 [1:07:49<1:52:14,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17300, Total loss 235.705856, iteration time 0.253724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▊      | 17402/45000 [1:08:13<1:50:32,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17400, Total loss 328.401917, iteration time 0.248754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 17502/45000 [1:08:36<1:51:19,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17500, Total loss 508.364471, iteration time 0.252879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 17602/45000 [1:09:00<1:49:11,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17600, Total loss 483.108490, iteration time 0.242688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 17702/45000 [1:09:24<1:51:18,  4.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17700, Total loss 487.615875, iteration time 0.259940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|███▉      | 17802/45000 [1:09:47<1:49:28,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17800, Total loss 457.366455, iteration time 0.247124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|███▉      | 17902/45000 [1:10:11<1:47:47,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17900, Total loss 496.132446, iteration time 0.243291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 18002/45000 [1:10:35<2:35:14,  2.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18000, Total loss 481.852051, iteration time 0.092623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 18102/45000 [1:10:59<1:48:29,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18100, Total loss 475.728027, iteration time 0.237637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 18202/45000 [1:11:22<1:48:34,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18200, Total loss 505.100159, iteration time 0.252031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 18302/45000 [1:11:46<1:46:18,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18300, Total loss 470.606384, iteration time 0.245239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 18402/45000 [1:12:10<1:45:43,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18400, Total loss 514.543091, iteration time 0.246127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 18502/45000 [1:12:33<1:47:13,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18500, Total loss 524.690674, iteration time 0.242842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████▏     | 18602/45000 [1:12:57<1:46:11,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18600, Total loss 494.978027, iteration time 0.255145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 18702/45000 [1:13:21<1:45:29,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18700, Total loss 475.444031, iteration time 0.245775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 18802/45000 [1:13:44<1:44:39,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18800, Total loss 593.666565, iteration time 0.249936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 18902/45000 [1:14:08<1:45:57,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18900, Total loss 363.055542, iteration time 0.257469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 19002/45000 [1:14:32<2:34:45,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19000, Total loss 558.592163, iteration time 0.104513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 19102/45000 [1:14:56<1:42:50,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19100, Total loss 234.927429, iteration time 0.246388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 19202/45000 [1:15:19<1:42:37,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19200, Total loss 181.253769, iteration time 0.244411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 19302/45000 [1:15:43<1:43:28,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19300, Total loss 403.786926, iteration time 0.261271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 19402/45000 [1:16:07<1:43:41,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19400, Total loss 551.350342, iteration time 0.249036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 19502/45000 [1:16:30<1:42:40,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19500, Total loss 689.323242, iteration time 0.248596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▎     | 19602/45000 [1:16:54<1:40:46,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19600, Total loss 515.068726, iteration time 0.247313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 19702/45000 [1:17:17<1:41:52,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19700, Total loss 501.433105, iteration time 0.247279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 19802/45000 [1:17:41<1:42:41,  4.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19800, Total loss 579.688904, iteration time 0.249735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 19902/45000 [1:18:05<1:41:10,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19900, Total loss 483.616913, iteration time 0.258048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 20002/45000 [1:18:29<2:24:45,  2.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20000, Total loss 522.194214, iteration time 0.093621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 20102/45000 [1:18:53<1:38:35,  4.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20100, Total loss 529.729553, iteration time 0.243263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 20202/45000 [1:19:16<1:40:01,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20200, Total loss 526.812012, iteration time 0.245445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 20302/45000 [1:19:40<1:39:20,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20300, Total loss 481.207825, iteration time 0.249904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 20402/45000 [1:20:03<1:38:24,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20400, Total loss 503.411926, iteration time 0.243479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 20502/45000 [1:20:27<1:38:31,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20500, Total loss 570.267334, iteration time 0.252218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 20602/45000 [1:20:50<1:38:13,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20600, Total loss 562.867554, iteration time 0.243407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 20702/45000 [1:21:14<1:37:07,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20700, Total loss 481.237946, iteration time 0.247145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 20802/45000 [1:21:38<1:37:04,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20800, Total loss 490.613342, iteration time 0.246947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▋     | 20902/45000 [1:22:02<1:35:52,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20900, Total loss 507.805481, iteration time 0.249704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 21002/45000 [1:22:26<2:38:05,  2.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21000, Total loss 873.780334, iteration time 0.101306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 21102/45000 [1:22:49<1:35:03,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21100, Total loss 486.255371, iteration time 0.244384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 21202/45000 [1:23:13<1:35:06,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21200, Total loss 449.067322, iteration time 0.248771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 21302/45000 [1:23:37<1:34:50,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21300, Total loss 453.397797, iteration time 0.233396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 21402/45000 [1:24:00<1:36:29,  4.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21400, Total loss 453.796631, iteration time 0.264968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 21502/45000 [1:24:24<1:34:02,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21500, Total loss 478.295288, iteration time 0.246232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 21602/45000 [1:24:48<1:34:25,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21600, Total loss 463.898438, iteration time 0.246248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 21702/45000 [1:25:11<1:33:12,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21700, Total loss 466.306030, iteration time 0.241885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 21802/45000 [1:25:35<1:34:16,  4.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21800, Total loss 429.825348, iteration time 0.254178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▊     | 21902/45000 [1:25:59<1:32:41,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21900, Total loss 410.986877, iteration time 0.247926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 22002/45000 [1:26:23<2:13:01,  2.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22000, Total loss 447.205383, iteration time 0.093291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 22102/45000 [1:26:47<1:31:39,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22100, Total loss 444.178711, iteration time 0.247706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 22202/45000 [1:27:10<1:32:27,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22200, Total loss 948.309814, iteration time 0.253468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|████▉     | 22302/45000 [1:27:34<1:31:11,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22300, Total loss 168.726562, iteration time 0.249382\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|████▉     | 22402/45000 [1:27:58<1:30:46,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22400, Total loss 238.853317, iteration time 0.248334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 22502/45000 [1:28:21<1:30:00,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22500, Total loss 222.483261, iteration time 0.243845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 22602/45000 [1:28:45<1:29:42,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22600, Total loss 200.720245, iteration time 0.248298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 22702/45000 [1:29:09<1:30:21,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22700, Total loss 577.773438, iteration time 0.247090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 22802/45000 [1:29:32<1:28:51,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22800, Total loss 527.036560, iteration time 0.246248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 22902/45000 [1:29:56<1:28:33,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22900, Total loss 522.438110, iteration time 0.247957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 23002/45000 [1:30:20<2:18:06,  2.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23000, Total loss 508.199066, iteration time 0.098222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████▏    | 23102/45000 [1:30:44<1:28:04,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23100, Total loss 523.229004, iteration time 0.243368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 23202/45000 [1:31:07<1:27:43,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23200, Total loss 538.641602, iteration time 0.250944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 23302/45000 [1:31:31<1:26:46,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23300, Total loss 554.481079, iteration time 0.244087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 23402/45000 [1:31:55<1:28:03,  4.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23400, Total loss 492.602173, iteration time 0.255279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 23502/45000 [1:32:18<1:25:26,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23500, Total loss 513.410400, iteration time 0.244305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 23602/45000 [1:32:42<1:25:26,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23600, Total loss 545.403992, iteration time 0.244679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 23702/45000 [1:33:06<1:25:30,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23700, Total loss 518.591614, iteration time 0.246735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 23802/45000 [1:33:29<1:24:48,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23800, Total loss 526.743774, iteration time 0.245797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 23902/45000 [1:33:53<1:24:19,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23900, Total loss 478.955444, iteration time 0.242659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 24002/45000 [1:34:17<2:02:43,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24000, Total loss 490.560272, iteration time 0.099997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▎    | 24102/45000 [1:34:41<1:25:00,  4.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24100, Total loss 474.649475, iteration time 0.252955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 24202/45000 [1:35:04<1:22:36,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24200, Total loss 503.550629, iteration time 0.242425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 24302/45000 [1:35:28<1:23:03,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24300, Total loss 503.586304, iteration time 0.247189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 24402/45000 [1:35:52<1:22:41,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24400, Total loss 479.870056, iteration time 0.244761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 24502/45000 [1:36:15<1:22:40,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24500, Total loss 512.388550, iteration time 0.239679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▍    | 24602/45000 [1:36:39<1:22:42,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24600, Total loss 593.772339, iteration time 0.247602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▍    | 24702/45000 [1:37:03<1:21:42,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24700, Total loss 183.992157, iteration time 0.250158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 24802/45000 [1:37:26<1:21:43,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24800, Total loss 295.411621, iteration time 0.248201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 24902/45000 [1:37:50<1:20:19,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24900, Total loss 253.006149, iteration time 0.244679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 25002/45000 [1:38:15<2:14:27,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25000, Total loss 318.211426, iteration time 0.107419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 25102/45000 [1:38:38<1:19:05,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25100, Total loss 336.772827, iteration time 0.242243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 25202/45000 [1:39:02<1:19:18,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25200, Total loss 346.231476, iteration time 0.243474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 25302/45000 [1:39:25<1:18:11,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25300, Total loss 455.447388, iteration time 0.242535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▋    | 25402/45000 [1:39:49<1:19:03,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25400, Total loss 443.293579, iteration time 0.244083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 25502/45000 [1:40:13<1:18:38,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25500, Total loss 423.952698, iteration time 0.246617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 25602/45000 [1:40:37<1:17:57,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25600, Total loss 449.983795, iteration time 0.247382\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 25702/45000 [1:41:00<1:17:42,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25700, Total loss 432.825562, iteration time 0.248362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 25802/45000 [1:41:24<1:17:45,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25800, Total loss 434.915344, iteration time 0.250797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 25902/45000 [1:41:48<1:16:26,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25900, Total loss 438.868835, iteration time 0.248456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 26002/45000 [1:42:12<1:52:39,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26000, Total loss 439.222290, iteration time 0.092817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 26102/45000 [1:42:36<1:16:01,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26100, Total loss 411.525146, iteration time 0.257856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 26202/45000 [1:42:59<1:15:52,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26200, Total loss 405.269043, iteration time 0.252639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 26302/45000 [1:43:23<1:15:23,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26300, Total loss 465.931152, iteration time 0.247216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▊    | 26402/45000 [1:43:47<1:14:40,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26400, Total loss 329.595398, iteration time 0.248625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 26502/45000 [1:44:10<1:13:44,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26500, Total loss 351.427002, iteration time 0.242983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 26602/45000 [1:44:34<1:13:51,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26600, Total loss 436.481567, iteration time 0.236830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 26702/45000 [1:44:58<1:12:51,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26700, Total loss 437.927063, iteration time 0.244919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|█████▉    | 26802/45000 [1:45:21<1:12:32,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26800, Total loss 442.446716, iteration time 0.245184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|█████▉    | 26902/45000 [1:45:45<1:12:58,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26900, Total loss 453.370361, iteration time 0.247235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 27002/45000 [1:46:09<2:02:05,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27000, Total loss 471.048157, iteration time 0.103575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 27102/45000 [1:46:33<1:11:54,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27100, Total loss 453.768677, iteration time 0.248115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 27202/45000 [1:46:57<1:11:53,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27200, Total loss 441.378601, iteration time 0.247754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 27302/45000 [1:47:20<1:11:27,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27300, Total loss 407.575165, iteration time 0.251972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 27402/45000 [1:47:44<1:10:09,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27400, Total loss 406.625305, iteration time 0.236029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 27502/45000 [1:48:08<1:11:16,  4.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27500, Total loss 438.160461, iteration time 0.262004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████▏   | 27602/45000 [1:48:31<1:09:50,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27600, Total loss 413.508362, iteration time 0.253469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 27702/45000 [1:48:55<1:09:28,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27700, Total loss 380.327393, iteration time 0.247455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 27802/45000 [1:49:18<1:09:08,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27800, Total loss 420.996582, iteration time 0.237811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 27902/45000 [1:49:42<1:09:45,  4.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27900, Total loss 415.880402, iteration time 0.254940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 28002/45000 [1:50:06<1:41:48,  2.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28000, Total loss 411.182953, iteration time 0.092796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 28102/45000 [1:50:30<1:07:29,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28100, Total loss 476.390503, iteration time 0.250924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 28202/45000 [1:50:53<1:07:16,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28200, Total loss 455.864746, iteration time 0.245898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 28302/45000 [1:51:17<1:07:29,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28300, Total loss 414.841827, iteration time 0.244287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 28402/45000 [1:51:41<1:06:23,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28400, Total loss 228.422195, iteration time 0.242428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 28502/45000 [1:52:05<1:07:07,  4.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28500, Total loss 299.716064, iteration time 0.264052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 28602/45000 [1:52:28<1:05:21,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28600, Total loss 600.516602, iteration time 0.242872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 28702/45000 [1:52:52<1:06:14,  4.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28700, Total loss 420.786560, iteration time 0.243416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 28802/45000 [1:53:15<1:05:10,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28800, Total loss 460.772827, iteration time 0.245183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 28902/45000 [1:53:39<1:03:54,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28900, Total loss 426.469513, iteration time 0.250477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 29002/45000 [1:54:04<2:01:35,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29000, Total loss 451.387451, iteration time 0.092912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▍   | 29102/45000 [1:54:27<1:04:04,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29100, Total loss 408.600403, iteration time 0.249754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▍   | 29202/45000 [1:54:51<1:03:45,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29200, Total loss 413.584106, iteration time 0.244377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 29302/45000 [1:55:15<1:02:28,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29300, Total loss 399.904358, iteration time 0.241774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 29402/45000 [1:55:38<1:02:16,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29400, Total loss 419.112549, iteration time 0.242942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 29502/45000 [1:56:02<1:01:46,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29500, Total loss 480.751617, iteration time 0.232753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 29602/45000 [1:56:26<1:01:58,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29600, Total loss 412.607361, iteration time 0.252778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 29702/45000 [1:56:49<1:01:03,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29700, Total loss 420.419037, iteration time 0.245374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 29802/45000 [1:57:13<1:00:47,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29800, Total loss 392.354919, iteration time 0.244047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▋   | 29902/45000 [1:57:36<1:00:09,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29900, Total loss 444.012299, iteration time 0.244888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 30002/45000 [1:58:01<1:41:55,  2.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30000, Total loss 373.166077, iteration time 0.100893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 30102/45000 [1:58:25<59:19,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30100, Total loss 260.860107, iteration time 0.243793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 30202/45000 [1:58:48<59:13,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30200, Total loss 234.421097, iteration time 0.245490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 30302/45000 [1:59:12<58:34,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30300, Total loss 489.282135, iteration time 0.242178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 30402/45000 [1:59:36<59:06,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30400, Total loss 471.390991, iteration time 0.244390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 30502/45000 [1:59:59<57:21,  4.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30500, Total loss 464.022644, iteration time 0.239233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 30602/45000 [2:00:23<58:35,  4.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30600, Total loss 478.479370, iteration time 0.245042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 30702/45000 [2:00:46<57:58,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30700, Total loss 485.228668, iteration time 0.248374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 30802/45000 [2:01:10<57:59,  4.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30800, Total loss 473.680206, iteration time 0.245936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▊   | 30902/45000 [2:01:34<56:03,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30900, Total loss 494.761963, iteration time 0.241891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 31002/45000 [2:01:58<1:23:38,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31000, Total loss 471.269836, iteration time 0.108810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 31102/45000 [2:02:22<56:32,  4.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31100, Total loss 498.266724, iteration time 0.242995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 31202/45000 [2:02:45<54:52,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31200, Total loss 505.332336, iteration time 0.240871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|██████▉   | 31302/45000 [2:03:09<54:59,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31300, Total loss 485.466858, iteration time 0.247277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|██████▉   | 31402/45000 [2:03:32<54:28,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31400, Total loss 446.224060, iteration time 0.242143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 31502/45000 [2:03:56<54:20,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31500, Total loss 441.807800, iteration time 0.237066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 31602/45000 [2:04:20<54:05,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31600, Total loss 484.072754, iteration time 0.258353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 31702/45000 [2:04:43<53:04,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31700, Total loss 535.323486, iteration time 0.242464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 31802/45000 [2:05:07<52:45,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31800, Total loss 523.009277, iteration time 0.242211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 31902/45000 [2:05:31<53:09,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31900, Total loss 467.636292, iteration time 0.255939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 32002/45000 [2:05:55<1:18:15,  2.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32000, Total loss 441.333588, iteration time 0.095571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████▏  | 32102/45000 [2:06:18<51:42,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32100, Total loss 470.744629, iteration time 0.250365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 32202/45000 [2:06:42<50:59,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32200, Total loss 460.910278, iteration time 0.253635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 32302/45000 [2:07:06<51:05,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32300, Total loss 490.825623, iteration time 0.247113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 32402/45000 [2:07:29<50:23,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32400, Total loss 479.397644, iteration time 0.242129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 32502/45000 [2:07:53<50:18,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32500, Total loss 445.228058, iteration time 0.245793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 32602/45000 [2:08:17<49:11,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32600, Total loss 521.301392, iteration time 0.242704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 32702/45000 [2:08:40<49:40,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32700, Total loss 479.869019, iteration time 0.250871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 32802/45000 [2:09:04<48:43,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32800, Total loss 466.484100, iteration time 0.245856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 32902/45000 [2:09:27<48:45,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32900, Total loss 455.205017, iteration time 0.245970\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 33002/45000 [2:09:52<1:11:16,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33000, Total loss 466.448730, iteration time 0.093352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▎  | 33102/45000 [2:10:15<47:58,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33100, Total loss 453.718018, iteration time 0.249635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 33202/45000 [2:10:39<47:20,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33200, Total loss 411.220917, iteration time 0.247168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 33302/45000 [2:11:03<46:58,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33300, Total loss 516.014282, iteration time 0.244847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 33402/45000 [2:11:26<46:11,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33400, Total loss 163.436752, iteration time 0.241115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 33502/45000 [2:11:50<45:44,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33500, Total loss 254.785767, iteration time 0.245167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▍  | 33602/45000 [2:12:14<45:51,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33600, Total loss 387.635315, iteration time 0.243074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▍  | 33702/45000 [2:12:37<45:25,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33700, Total loss 411.912018, iteration time 0.247466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 33802/45000 [2:13:01<44:53,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33800, Total loss 401.922913, iteration time 0.246063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 33902/45000 [2:13:24<44:33,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33900, Total loss 411.756165, iteration time 0.247951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 34002/45000 [2:13:49<1:16:18,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34000, Total loss 396.402832, iteration time 0.106783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 34102/45000 [2:14:13<43:39,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34100, Total loss 387.693390, iteration time 0.243092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 34202/45000 [2:14:36<43:22,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34200, Total loss 398.186981, iteration time 0.246324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 34302/45000 [2:15:00<43:00,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34300, Total loss 403.981873, iteration time 0.247188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▋  | 34402/45000 [2:15:24<43:03,  4.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34400, Total loss 431.140717, iteration time 0.250230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 34502/45000 [2:15:47<41:45,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34500, Total loss 406.160889, iteration time 0.242843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 34602/45000 [2:16:11<41:50,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34600, Total loss 365.365479, iteration time 0.245662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 34702/45000 [2:16:35<41:21,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34700, Total loss 469.955780, iteration time 0.250480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 34802/45000 [2:16:58<41:15,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34800, Total loss 204.191254, iteration time 0.245414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 34902/45000 [2:17:22<40:17,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34900, Total loss 740.657288, iteration time 0.242816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 35002/45000 [2:17:46<58:41,  2.84it/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35000, Total loss 450.522797, iteration time 0.093115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 35102/45000 [2:18:09<39:38,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35100, Total loss 453.302521, iteration time 0.257058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 35202/45000 [2:18:33<39:38,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35200, Total loss 461.051056, iteration time 0.249982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 35302/45000 [2:18:57<38:28,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35300, Total loss 451.662048, iteration time 0.245641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▊  | 35402/45000 [2:19:20<38:28,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35400, Total loss 437.698242, iteration time 0.245164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 35502/45000 [2:19:44<37:55,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35500, Total loss 452.067810, iteration time 0.245004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 35602/45000 [2:20:08<38:00,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35600, Total loss 457.133087, iteration time 0.244407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 35702/45000 [2:20:31<37:23,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35700, Total loss 449.436401, iteration time 0.246321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|███████▉  | 35802/45000 [2:20:55<36:36,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35800, Total loss 454.781250, iteration time 0.247014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|███████▉  | 35902/45000 [2:21:19<36:38,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35900, Total loss 505.169617, iteration time 0.246192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 36002/45000 [2:21:43<1:01:10,  2.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36000, Total loss 435.384399, iteration time 0.107068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 36102/45000 [2:22:07<35:28,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36100, Total loss 433.494873, iteration time 0.247452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 36202/45000 [2:22:30<35:11,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36200, Total loss 442.311737, iteration time 0.248441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 36302/45000 [2:22:54<34:40,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36300, Total loss 554.903320, iteration time 0.247913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 36402/45000 [2:23:17<34:52,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36400, Total loss 433.424805, iteration time 0.253719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 36502/45000 [2:23:41<34:16,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36500, Total loss 402.965698, iteration time 0.245027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████▏ | 36602/45000 [2:24:05<33:20,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36600, Total loss 329.353546, iteration time 0.241132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 36702/45000 [2:24:28<32:53,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36700, Total loss 184.040268, iteration time 0.242404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 36802/45000 [2:24:52<32:50,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36800, Total loss 440.786774, iteration time 0.240581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 36902/45000 [2:25:16<32:44,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36900, Total loss 396.969910, iteration time 0.250759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 37002/45000 [2:25:40<47:24,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37000, Total loss 418.453400, iteration time 0.093390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 37102/45000 [2:26:03<31:51,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37100, Total loss 399.090729, iteration time 0.246268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 37202/45000 [2:26:27<31:23,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37200, Total loss 401.158722, iteration time 0.247261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 37302/45000 [2:26:51<30:59,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37300, Total loss 414.842682, iteration time 0.241402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 37402/45000 [2:27:14<30:30,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37400, Total loss 409.925781, iteration time 0.248221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 37502/45000 [2:27:38<29:46,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37500, Total loss 424.156128, iteration time 0.241678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▎ | 37602/45000 [2:28:02<29:36,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37600, Total loss 381.114258, iteration time 0.246607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 37702/45000 [2:28:25<29:06,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37700, Total loss 432.525421, iteration time 0.250954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 37802/45000 [2:28:49<28:47,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37800, Total loss 397.698853, iteration time 0.249999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 37902/45000 [2:29:13<28:21,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37900, Total loss 436.424988, iteration time 0.243091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 38002/45000 [2:29:37<41:18,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38000, Total loss 393.928284, iteration time 0.093378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▍ | 38102/45000 [2:30:00<28:21,  4.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38100, Total loss 450.897369, iteration time 0.255862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▍ | 38202/45000 [2:30:24<27:22,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38200, Total loss 417.966736, iteration time 0.256317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 38302/45000 [2:30:48<26:53,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38300, Total loss 464.954712, iteration time 0.246804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 38402/45000 [2:31:11<26:30,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38400, Total loss 168.218674, iteration time 0.248977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 38502/45000 [2:31:35<26:18,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38500, Total loss 313.700073, iteration time 0.245253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 38602/45000 [2:31:59<25:32,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38600, Total loss 230.784851, iteration time 0.252563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 38702/45000 [2:32:22<25:14,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38700, Total loss 452.790344, iteration time 0.243861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 38802/45000 [2:32:46<24:56,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38800, Total loss 468.272522, iteration time 0.250388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▋ | 38902/45000 [2:33:10<24:37,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38900, Total loss 443.292633, iteration time 0.247332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 39002/45000 [2:33:34<35:39,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39000, Total loss 462.203644, iteration time 0.095246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 39102/45000 [2:33:57<23:23,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39100, Total loss 467.748566, iteration time 0.243303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 39202/45000 [2:34:21<23:21,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39200, Total loss 449.729065, iteration time 0.257641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 39302/45000 [2:34:45<23:02,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39300, Total loss 459.246735, iteration time 0.251251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 39402/45000 [2:35:08<22:30,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39400, Total loss 443.918671, iteration time 0.248670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 39502/45000 [2:35:32<22:02,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39500, Total loss 436.403198, iteration time 0.246497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 39602/45000 [2:35:56<21:25,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39600, Total loss 418.368347, iteration time 0.242565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 39702/45000 [2:36:19<21:20,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39700, Total loss 450.118896, iteration time 0.250029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 39802/45000 [2:36:43<20:49,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39800, Total loss 435.392181, iteration time 0.252770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▊ | 39902/45000 [2:37:06<20:39,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39900, Total loss 414.777008, iteration time 0.247712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 40002/45000 [2:37:31<29:41,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40000, Total loss 446.970764, iteration time 0.094941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 40102/45000 [2:37:54<19:50,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40100, Total loss 354.984070, iteration time 0.243916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 40202/45000 [2:38:18<19:12,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40200, Total loss 429.324219, iteration time 0.244259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|████████▉ | 40302/45000 [2:38:42<18:46,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40300, Total loss 446.099731, iteration time 0.245935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|████████▉ | 40402/45000 [2:39:05<18:29,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40400, Total loss 443.471985, iteration time 0.247182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 40502/45000 [2:39:29<18:08,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40500, Total loss 394.865479, iteration time 0.245659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 40602/45000 [2:39:53<17:39,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40600, Total loss 498.453613, iteration time 0.245209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 40702/45000 [2:40:16<17:11,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40700, Total loss 541.781616, iteration time 0.246539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 40802/45000 [2:40:40<16:45,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40800, Total loss 555.965027, iteration time 0.243673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 40902/45000 [2:41:03<16:33,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40900, Total loss 681.187500, iteration time 0.251090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 41002/45000 [2:41:28<23:52,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41000, Total loss 244.129211, iteration time 0.092761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████▏| 41102/45000 [2:41:51<15:41,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41100, Total loss 261.176697, iteration time 0.248595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 41202/45000 [2:42:15<15:18,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41200, Total loss 451.173370, iteration time 0.254289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 41302/45000 [2:42:39<14:57,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41300, Total loss 432.475952, iteration time 0.245869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 41402/45000 [2:43:02<14:23,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41400, Total loss 470.025391, iteration time 0.241507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 41502/45000 [2:43:26<14:05,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41500, Total loss 495.757080, iteration time 0.246083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 41602/45000 [2:43:49<13:29,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41600, Total loss 460.266357, iteration time 0.238457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 41702/45000 [2:44:13<13:09,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41700, Total loss 470.053589, iteration time 0.243715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 41802/45000 [2:44:37<12:58,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41800, Total loss 448.055298, iteration time 0.264660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 41902/45000 [2:45:00<12:18,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41900, Total loss 452.630035, iteration time 0.242374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 42002/45000 [2:45:24<17:42,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42000, Total loss 439.442535, iteration time 0.091402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▎| 42102/45000 [2:45:48<11:39,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42100, Total loss 457.396515, iteration time 0.246744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 42202/45000 [2:46:12<11:30,  4.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42200, Total loss 404.833618, iteration time 0.265207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 42302/45000 [2:46:35<10:42,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42300, Total loss 423.963745, iteration time 0.242618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 42402/45000 [2:46:59<10:23,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42400, Total loss 450.493744, iteration time 0.244730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 42502/45000 [2:47:22<10:05,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42500, Total loss 428.768372, iteration time 0.247081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▍| 42602/45000 [2:47:46<09:40,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42600, Total loss 470.765503, iteration time 0.244800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▍| 42702/45000 [2:48:10<09:10,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42700, Total loss 341.230103, iteration time 0.246096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 42802/45000 [2:48:33<08:51,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42800, Total loss 263.724945, iteration time 0.244093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 42902/45000 [2:48:57<08:24,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42900, Total loss 210.982574, iteration time 0.243805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 43002/45000 [2:49:22<14:00,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43000, Total loss 352.012573, iteration time 0.103587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 43102/45000 [2:49:45<07:36,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43100, Total loss 435.273560, iteration time 0.247775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 43202/45000 [2:50:09<07:09,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43200, Total loss 440.343475, iteration time 0.245254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 43302/45000 [2:50:32<06:45,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43300, Total loss 452.701538, iteration time 0.245808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▋| 43402/45000 [2:50:56<06:28,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43400, Total loss 448.390564, iteration time 0.249555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 43502/45000 [2:51:20<05:59,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43500, Total loss 454.249573, iteration time 0.242372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 43602/45000 [2:51:43<05:35,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43600, Total loss 434.853210, iteration time 0.245641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 43702/45000 [2:52:07<05:13,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43700, Total loss 451.464935, iteration time 0.247300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 43802/45000 [2:52:31<04:50,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43800, Total loss 457.556152, iteration time 0.245598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 43902/45000 [2:52:54<04:23,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43900, Total loss 469.504578, iteration time 0.252566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 44002/45000 [2:53:18<05:58,  2.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44000, Total loss 446.835052, iteration time 0.091733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 44102/45000 [2:53:42<03:34,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44100, Total loss 440.485535, iteration time 0.238811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 44202/45000 [2:54:06<03:13,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44200, Total loss 414.898560, iteration time 0.250425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 44302/45000 [2:54:29<02:46,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44300, Total loss 476.491669, iteration time 0.240371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▊| 44402/45000 [2:54:53<02:23,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44400, Total loss 489.915527, iteration time 0.241995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 44502/45000 [2:55:16<01:58,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44500, Total loss 401.431946, iteration time 0.238953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 44602/45000 [2:55:40<01:36,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44600, Total loss 454.419617, iteration time 0.251618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 44702/45000 [2:56:04<01:11,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44700, Total loss 413.478546, iteration time 0.242973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 44802/45000 [2:56:27<00:47,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44800, Total loss 423.471527, iteration time 0.252428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 44902/45000 [2:56:51<00:23,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44900, Total loss 498.365753, iteration time 0.241048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 45000/45000 [2:57:15<00:00,  4.23it/s]\n"
          ]
        }
      ]
    }
  ]
}